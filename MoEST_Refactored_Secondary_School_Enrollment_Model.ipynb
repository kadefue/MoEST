{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kadefue/MoEST/blob/main/MoEST_Refactored_Secondary_School_Enrollment_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsBI_ntH7qr8",
        "outputId": "bc6cd0de-32a7-4f85-867b-9b17577f9c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Found 14 files to load.\n",
            "Loaded: Data-Secondary Enrollment 2016-2025\n",
            "Loaded: Dropout-Secondary  2017-2024\n",
            "Loaded: Data-Secondary Tables and chairs 2016-2025\n",
            "Loaded: Secondary-Re_entry\n",
            "Loaded: Secondary - DISABALITY 2020-2025\n",
            "Loaded: LGAs Urban and Rural Status\n",
            "Loaded: Combined_Secondary_Laboratories_Govt\n",
            "Loaded: Combined_Secondary_Laboratories_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_Govt\n",
            "Loaded: Combined_Secondary_Electricity_All_G_NG\n",
            "Loaded: Combined_Secondary_Electricity_Govt\n",
            "Loaded: Secondary_students_per_subject\n",
            "Loaded: Secondary_enrollment_Gov_2016_2025\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025\n",
            "Merged LGA Status into Dropout-Secondary  2017-2024\n",
            "Merged LGA Status into Data-Secondary Tables and chairs 2016-2025\n",
            "Merged LGA Status into Secondary-Re_entry\n",
            "Merged LGA Status into Secondary - DISABALITY 2020-2025\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_Govt\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_Govt\n",
            "Merged LGA Status into Combined_Secondary_Electricity_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_Electricity_Govt\n",
            "Merged LGA Status into Secondary_students_per_subject\n",
            "Merged LGA Status into Secondary_enrollment_Gov_2016_2025\n",
            "\n",
            "--- Starting Feature Engineering ---\n",
            "Melting 391 subject columns...\n",
            "\n",
            "--- Starting Model Engine ---\n",
            "\n",
            "Training all candidate models on Data <= 2023...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Training Random Forest...\n",
            "Training HistGradientBoosting...\n",
            "Training GradientBoosting...\n",
            "All models trained successfully.\n",
            "\n",
            "--- Evaluation Results (Test Data 2024+) ---\n",
            "Evaluating all models...\n",
            "--- XGB Results ---\n",
            "   > XGB: R2=0.9363, MAE=55.32, RMSE=380.30, Acc=-1987.06%\n",
            "------------------------------\n",
            "Model: XGB | RMSE: 380.30\n",
            "--- LGB Results ---\n",
            "   > LGB: R2=0.9326, MAE=58.04, RMSE=391.20, Acc=-2104.67%\n",
            "------------------------------\n",
            "Model: LGB | RMSE: 391.20\n",
            "--- RF Results ---\n",
            "   > RF: R2=0.9326, MAE=51.10, RMSE=391.34, Acc=-1950.62%\n",
            "------------------------------\n",
            "Model: RF | RMSE: 391.34\n",
            "--- HGB Results ---\n",
            "   > HGB: R2=0.9231, MAE=74.95, RMSE=417.98, Acc=-2130.76%\n",
            "------------------------------\n",
            "Model: HGB | RMSE: 417.98\n",
            "--- GB Results ---\n",
            "   > GB: R2=0.9332, MAE=63.78, RMSE=389.59, Acc=-3085.23%\n",
            "------------------------------\n",
            "Model: GB | RMSE: 389.59\n",
            "\n",
            "BEST MODEL: XGB (RMSE: 380.30)\n",
            "Selection Threshold (RMSE <= 532.42)\n",
            "Qualifying Models: ['XGB', 'LGB', 'RF', 'HGB', 'GB']\n",
            "Strategy: ENSEMBLE (Average of XGB, LGB, RF, HGB, GB)\n",
            "\n",
            "Starting Recursive Forecast (2026-2030) using ['XGB', 'LGB', 'RF', 'HGB', 'GB']...\n",
            " > Forecasted 2026\n",
            " > Forecasted 2027\n",
            " > Forecasted 2028\n",
            " > Forecasted 2029\n",
            " > Forecasted 2030\n",
            "\n",
            "--- Final Forecast Sample ---\n",
            "   YEAR  REGION COUNCIL                         SUBJECT  FORM_NUM  ENROLLMENT\n",
            "0  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         1          14\n",
            "1  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         2          11\n",
            "2  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         3          11\n",
            "3  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         4          10\n",
            "4  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          14\n",
            "5  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          13\n",
            "6  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          11\n",
            "7  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          10\n",
            "8  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          11\n",
            "9  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3           4\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Refactored MoEST Modeling for Secondary School Enrollment\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    GradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 1: Data Loader & Cleaner\n",
        "# =============================================================================\n",
        "\n",
        "class MOESTDataLoader:\n",
        "    \"\"\"\n",
        "    Handles mounting drive, loading CSVs, cleaning headers, handling types,\n",
        "    and managing initial data quality checks.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_directory, exclude_keywords=None):\n",
        "        self.base_directory = base_directory\n",
        "        self.exclude_keywords = exclude_keywords if exclude_keywords else []\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def mount_drive(self):\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "    def get_file_list(self):\n",
        "        all_files = [f for f in os.listdir(self.base_directory) if f.endswith('.csv')]\n",
        "        filtered_files = []\n",
        "        for file_name in all_files:\n",
        "            if not any(keyword.lower() in file_name.lower() for keyword in self.exclude_keywords):\n",
        "                filtered_files.append(file_name)\n",
        "        return filtered_files\n",
        "\n",
        "    def load_data(self):\n",
        "        files = self.get_file_list()\n",
        "        print(f\"Found {len(files)} files to load.\")\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(self.base_directory, file_name)\n",
        "            df_name = file_name.replace('.csv', '')\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                self.dataframes[df_name] = self._initial_clean(df)\n",
        "                print(f\"Loaded: {df_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    def _initial_clean(self, df):\n",
        "        \"\"\"Standardizes headers and cleans numeric columns.\"\"\"\n",
        "        df.columns = [str(col).strip().upper() for col in df.columns]\n",
        "\n",
        "        for col in df.select_dtypes(include='object').columns:\n",
        "            if df[col].astype(str).str.contains(',').any():\n",
        "                cleaned = df[col].astype(str).str.replace(',', '', regex=False)\n",
        "                converted = pd.to_numeric(cleaned, errors='coerce')\n",
        "                if converted.notna().sum() > 0:\n",
        "                    df[col] = converted\n",
        "\n",
        "        unnamed = [c for c in df.columns if 'UNNAMED' in c]\n",
        "        to_drop = [c for c in unnamed if df[c].isnull().mean() > 0.9]\n",
        "        df.drop(columns=to_drop, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "    def get_all_dataframes(self):\n",
        "        return self.dataframes\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 2: Geography & Location Manager\n",
        "# =============================================================================\n",
        "\n",
        "class LocationManager:\n",
        "    \"\"\"\n",
        "    Handles Geocoding, LGA Status merging, and Clustering.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframes, geodata_path):\n",
        "        self.dataframes = dataframes\n",
        "        self.geodata_path = geodata_path\n",
        "        self.geo_data = None\n",
        "        self.lga_status_df = None\n",
        "\n",
        "    def standardize_location_columns(self):\n",
        "        for name, df in self.dataframes.items():\n",
        "            reg_col = next((c for c in df.columns if c in ['REGION', 'REGON']), None)\n",
        "            cou_col = next((c for c in df.columns if c in ['COUNCIL', 'DISTRICT', 'LGA NAME']), None)\n",
        "\n",
        "            if reg_col and cou_col:\n",
        "                df.rename(columns={reg_col: 'REGION', cou_col: 'COUNCIL'}, inplace=True)\n",
        "                df['REGION'] = df['REGION'].astype(str).str.upper()\n",
        "                df['COUNCIL'] = df['COUNCIL'].astype(str).str.upper()\n",
        "\n",
        "    def merge_lga_status(self, lga_df_name='LGAs Urban and Rural Status'):\n",
        "        if lga_df_name not in self.dataframes:\n",
        "            print(\"LGA Status DataFrame not found.\")\n",
        "            return\n",
        "\n",
        "        self.lga_status_df = self.dataframes[lga_df_name].copy()\n",
        "        if 'REMARKS' in self.lga_status_df.columns:\n",
        "            self.lga_status_df.drop(columns=['REMARKS'], inplace=True)\n",
        "        self.lga_status_df.rename(columns={'CLASSIFICATION': 'LGA_STATUS'}, inplace=True)\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if name == lga_df_name: continue\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.lga_status_df, on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged LGA Status into {name}\")\n",
        "        del self.dataframes[lga_df_name]\n",
        "\n",
        "    def process_geocoding(self):\n",
        "        if os.path.exists(self.geodata_path):\n",
        "            print(\"Loading existing geodata...\")\n",
        "            self.geo_data = pd.read_csv(self.geodata_path)\n",
        "        else:\n",
        "            print(\"Generating new geodata...\")\n",
        "            self._fetch_geodata()\n",
        "\n",
        "        self._apply_clustering()\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.geo_data[['REGION', 'COUNCIL', 'GEO_CLUSTER']],\n",
        "                                  on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged Geo Cluster into {name}\")\n",
        "\n",
        "    def _fetch_geodata(self):\n",
        "        locs = []\n",
        "        for df in self.dataframes.values():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                locs.append(df[['REGION', 'COUNCIL']])\n",
        "        unique_locs = pd.concat(locs).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        geolocator = Nominatim(user_agent=\"moest_geo_mapper_v3\")\n",
        "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1.0)\n",
        "\n",
        "        lats, lons = [], []\n",
        "        for idx, row in unique_locs.iterrows():\n",
        "            query = f\"{row['COUNCIL']}, {row['REGION']}, Tanzania\"\n",
        "            try:\n",
        "                loc = geocode(query)\n",
        "                if loc:\n",
        "                    lats.append(loc.latitude)\n",
        "                    lons.append(loc.longitude)\n",
        "                else:\n",
        "                    lats.append(None)\n",
        "                    lons.append(None)\n",
        "            except:\n",
        "                lats.append(None)\n",
        "                lons.append(None)\n",
        "\n",
        "        unique_locs['LATITUDE'] = lats\n",
        "        unique_locs['LONGITUDE'] = lons\n",
        "        self.geo_data = unique_locs.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "        self.geo_data.to_csv(self.geodata_path, index=False)\n",
        "\n",
        "    def _apply_clustering(self):\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        self.geo_data['GEO_CLUSTER'] = kmeans.fit_predict(self.geo_data[['LATITUDE', 'LONGITUDE']])\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 3: Feature Engineer\n",
        "# =============================================================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"\n",
        "    Handles specific transformation logic for Secondary School Subjects.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def melt_subjects(df):\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in df.columns]\n",
        "        subject_cols = [c for c in df.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        print(f\"Melting {len(subject_cols)} subject columns...\")\n",
        "        long_df = df.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "        return long_df\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_infrastructure(main_df, infrastructure_dfs):\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "        df = main_df.copy()\n",
        "\n",
        "        # Tables\n",
        "        tables = infrastructure_dfs.get('tables')\n",
        "        if tables is not None and 'AVAILABLE_TABLES' in tables.columns:\n",
        "            df = df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna({'AVAILABLE_TABLES': 0})\n",
        "\n",
        "        # Labs\n",
        "        labs = infrastructure_dfs.get('labs')\n",
        "        if labs is not None:\n",
        "            lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "            if lab_cols:\n",
        "                labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "                df = df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna({'TOTAL_LABS': 0})\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_lag_features(df):\n",
        "        df = df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2015, 2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_cohort_features(df):\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup_dict = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup_dict).fillna(-1)\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 4: Model Engine (Conditional Ensemble)\n",
        "# =============================================================================\n",
        "\n",
        "class EnrollmentModelEngine:\n",
        "    \"\"\"\n",
        "    Manages Training, Conditional Selection, and Recursive Forecasting.\n",
        "    Implements logic: Use Best Model ONLY unless others are within 60% performance.\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.models = {}\n",
        "        self.encoders = {}\n",
        "        self.features = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_LABS', 'LAG_1', 'LAG_2',\n",
        "            'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "        self.selected_model_keys = [] # Stores keys of models to be used for inference\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.encoders['REG'] = LabelEncoder()\n",
        "        self.encoders['COU'] = LabelEncoder()\n",
        "        self.encoders['SUB'] = LabelEncoder()\n",
        "\n",
        "        self.df['REGION_ENC'] = self.encoders['REG'].fit_transform(self.df['REGION'].astype(str))\n",
        "        self.df['COUNCIL_ENC'] = self.encoders['COU'].fit_transform(self.df['COUNCIL'].astype(str))\n",
        "        self.df['SUBJECT_ENC'] = self.encoders['SUB'].fit_transform(self.df['SUBJECT'].astype(str))\n",
        "\n",
        "    def train_all_models(self, cutoff_year=2023):\n",
        "        \"\"\"Trains all 5 candidate models.\"\"\"\n",
        "        print(f\"\\nTraining all candidate models on Data <= {cutoff_year}...\")\n",
        "        train_df = self.df[self.df['YEAR'] <= cutoff_year]\n",
        "        X = train_df[self.features]\n",
        "        y = train_df['ENROLLMENT']\n",
        "\n",
        "        # 1. XGBoost\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['XGB'] = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1)\n",
        "        self.models['XGB'].fit(X, y)\n",
        "\n",
        "        # 2. LightGBM\n",
        "        print(\"Training LightGBM...\")\n",
        "        self.models['LGB'] = lgb.LGBMRegressor(n_estimators=500, num_leaves=50, min_child_samples=10, learning_rate=0.1, verbose=-1)\n",
        "        self.models['LGB'].fit(X, y)\n",
        "\n",
        "        # 3. Random Forest\n",
        "        print(\"Training Random Forest...\")\n",
        "        self.models['RF'] = RandomForestRegressor(n_estimators=300, max_depth=12, n_jobs=-1, random_state=42)\n",
        "        self.models['RF'].fit(X, y)\n",
        "\n",
        "        # 4. HistGradientBoosting (Scikit-Learn)\n",
        "        print(\"Training HistGradientBoosting...\")\n",
        "        self.models['HGB'] = HistGradientBoostingRegressor(max_iter=500, learning_rate=0.1, max_depth=10)\n",
        "        self.models['HGB'].fit(X, y)\n",
        "\n",
        "        # 5. GradientBoosting (Standard)\n",
        "        # Limiting estimators slightly for speed as GB is sequential and slow\n",
        "        print(\"Training GradientBoosting...\")\n",
        "        self.models['GB'] = GradientBoostingRegressor(n_estimators=300, max_depth=9, learning_rate=0.05)\n",
        "        self.models['GB'].fit(X, y)\n",
        "\n",
        "        print(\"All models trained successfully.\")\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        # Handle division by zero for MAPE\n",
        "        mask = y_true != 0\n",
        "        if mask.sum() > 0:\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "            accuracy = 100 - mape\n",
        "        else:\n",
        "            mape = np.nan\n",
        "            accuracy = np.nan\n",
        "\n",
        "        print(f\"--- {model_name} Results ---\")\n",
        "        print(f\"   > {model_name}: R2={r2:.4f}, MAE={mae:,.2f}, RMSE={rmse:,.2f}, MAPE={mape:,.1f}%, Acc={accuracy:.1f}%\")\n",
        "        print(\"-\" * 30)\n",
        "        return rmse\n",
        "\n",
        "    def evaluate_and_select_strategy(self, test_year_start=2024):\n",
        "        \"\"\"\n",
        "        Evaluates models and applies the 60% rule:\n",
        "        1. Find Best Model (Lowest RMSE).\n",
        "        2. Identify models with RMSE <= Best RMSE * 1.6 (Within 60% of best).\n",
        "        3. If only Best fits criteria -> Use Single Best.\n",
        "        4. If others fit criteria -> Use Ensemble (Average of valid candidates).\n",
        "        \"\"\"\n",
        "        test_df = self.df[self.df['YEAR'] >= test_year_start]\n",
        "        if test_df.empty:\n",
        "            print(\"No test data available. Defaulting to XGB only.\")\n",
        "            self.selected_model_keys = ['XGB']\n",
        "            return\n",
        "\n",
        "        X_test = test_df[self.features]\n",
        "        y_true = test_df['ENROLLMENT']\n",
        "\n",
        "        performance = {}\n",
        "        print(f\"\\n--- Evaluation Results (Test Data {test_year_start}+) ---\")\n",
        "\n",
        "        # Evaluate all\n",
        "        print(\"Evaluating all models...\")\n",
        "        for name, model in self.models.items():\n",
        "            preds = model.predict(X_test)\n",
        "            rmse = self.calculate_metrics(y_true, preds, name)\n",
        "            performance[name] = rmse\n",
        "            print(f\"Model: {name} | RMSE: {rmse:,.2f}\")\n",
        "\n",
        "        # Find Best\n",
        "        best_model_name = min(performance, key=performance.get)\n",
        "        best_rmse = performance[best_model_name]\n",
        "        print(f\"\\nBEST MODEL: {best_model_name} (RMSE: {best_rmse:,.2f})\")\n",
        "\n",
        "        # Apply Threshold Rule (RMSE within 40% of best)\n",
        "        # \"Performance at least 40% of best\" usually means Error is not more than 40% higher.\n",
        "        # Threshold = Best_RMSE + (0.40 * Best_RMSE) = 1.4 * Best_RMSE\n",
        "        threshold = best_rmse * 1.4\n",
        "        candidates = [name for name, score in performance.items() if score <= threshold]\n",
        "\n",
        "        print(f\"Selection Threshold (RMSE <= {threshold:,.2f})\")\n",
        "        print(f\"Qualifying Models: {candidates}\")\n",
        "\n",
        "        # Logic: If others exist besides best -> Ensemble. Else -> Single.\n",
        "        if len(candidates) > 1:\n",
        "            self.selected_model_keys = candidates\n",
        "            print(f\"Strategy: ENSEMBLE (Average of {', '.join(candidates)})\")\n",
        "        else:\n",
        "            self.selected_model_keys = [best_model_name]\n",
        "            print(f\"Strategy: SINGLE BEST MODEL ({best_model_name})\")\n",
        "\n",
        "    def _predict(self, X):\n",
        "        \"\"\"Predicts using the selected strategy.\"\"\"\n",
        "        preds = []\n",
        "        for key in self.selected_model_keys:\n",
        "            preds.append(self.models[key].predict(X))\n",
        "\n",
        "        # Average the predictions of selected models\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    def recursive_forecast(self, start_year, end_year):\n",
        "        print(f\"\\nStarting Recursive Forecast ({start_year}-{end_year}) using {self.selected_model_keys}...\")\n",
        "        future_data = []\n",
        "        current_data = self.df[self.df['YEAR'] == (start_year - 1)].copy()\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            next_df = self._prepare_next_step(current_data, year)\n",
        "\n",
        "            X_future = next_df[self.features]\n",
        "            preds = self._predict(X_future)\n",
        "\n",
        "            next_df['ENROLLMENT'] = np.maximum(0, preds)\n",
        "\n",
        "            future_data.append(next_df)\n",
        "            current_data = next_df.copy()\n",
        "            print(f\" > Forecasted {year}\")\n",
        "\n",
        "        return pd.concat(future_data, ignore_index=True)\n",
        "\n",
        "    def _prepare_next_step(self, prev_df, target_year):\n",
        "        next_df = prev_df.copy()\n",
        "        next_df['YEAR'] = target_year\n",
        "\n",
        "        # Shift Lags\n",
        "        next_df['LAG_2'] = next_df['LAG_1']\n",
        "        next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "\n",
        "        # Update Growth\n",
        "        next_df['YOY_GROWTH'] = (next_df['LAG_1'] - next_df['LAG_2']) / (next_df['LAG_2'] + 1e-5)\n",
        "\n",
        "        # Update Cohort Logic\n",
        "        cohort_lookup = prev_df.set_index(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort(row):\n",
        "            target_form = row['FORM_NUM'] - 1\n",
        "            if target_form < 1: return -1\n",
        "            key = (row['REGION'], row['COUNCIL'], row['SUBJECT'], target_form)\n",
        "            return cohort_lookup.get(key, -1)\n",
        "\n",
        "        next_df['COHORT_LAG'] = next_df.apply(get_cohort, axis=1)\n",
        "        next_df['IS_ELECTION_YEAR'] = 1 if target_year in [2025, 2030] else 0\n",
        "\n",
        "        return next_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # 1. Configuration\n",
        "    BASE_DIR = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEO_FILE = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'Teacher', 'COBET', 'Vocational']\n",
        "\n",
        "    # 2. Load Data\n",
        "    loader = MOESTDataLoader(BASE_DIR, EXCLUDE_KEYWORDS)\n",
        "    loader.mount_drive()\n",
        "    loader.load_data()\n",
        "    all_dfs = loader.get_all_dataframes()\n",
        "\n",
        "    # 3. Location & Clean Up\n",
        "    loc_manager = LocationManager(all_dfs, GEO_FILE)\n",
        "    loc_manager.standardize_location_columns()\n",
        "    loc_manager.merge_lga_status()\n",
        "\n",
        "    # 4. Feature Engineering\n",
        "    print(\"\\n--- Starting Feature Engineering ---\")\n",
        "    df_subject = all_dfs.get(\"Secondary_students_per_subject\")\n",
        "    df_tables = all_dfs.get(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "    df_labs = all_dfs.get(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "\n",
        "    if df_subject is None:\n",
        "        raise ValueError(\"Critical DataFrame 'Secondary_students_per_subject' not found.\")\n",
        "\n",
        "    engineer = FeatureEngineer()\n",
        "    long_df = engineer.melt_subjects(df_subject)\n",
        "    merged_df = engineer.merge_infrastructure(long_df, {'tables': df_tables, 'labs': df_labs})\n",
        "    lagged_df = engineer.create_lag_features(merged_df)\n",
        "    final_df = engineer.create_cohort_features(lagged_df)\n",
        "\n",
        "    # 5. Modeling & Forecasting (Updated Strategy)\n",
        "    print(\"\\n--- Starting Model Engine ---\")\n",
        "    engine = EnrollmentModelEngine(final_df)\n",
        "    engine.preprocess()\n",
        "\n",
        "    # Train (Using data up to 2023 to test on 2024 and 2025)\n",
        "    engine.train_all_models(cutoff_year=2023)\n",
        "\n",
        "    # Evaluate & Select Strategy (Best or Ensemble)\n",
        "    engine.evaluate_and_select_strategy(test_year_start=2024)\n",
        "\n",
        "    # 6. Generate Forecast\n",
        "    # Note: Recursive forecast starts from 2026, using 2025 as the base history\n",
        "    forecast_df = engine.recursive_forecast(2026, 2030)\n",
        "\n",
        "    # 7. Output\n",
        "    print(\"\\n--- Final Forecast Sample ---\")\n",
        "    output_cols = ['YEAR', 'REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'ENROLLMENT']\n",
        "    final_view = forecast_df[output_cols].copy()\n",
        "    final_view['ENROLLMENT'] = final_view['ENROLLMENT'].round(0).astype(int)\n",
        "    print(final_view.head(10))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GakIOlmrpTOS",
        "outputId": "38f3ab73-280f-4798-bed7-8c523e2d7ab8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Found 15 files to load.\n",
            "Loaded: Data-Secondary Enrollment 2016-2025\n",
            "Loaded: Dropout-Secondary  2017-2024\n",
            "Loaded: Data-Secondary Tables and chairs 2016-2025\n",
            "Loaded: Secondary-Re_entry\n",
            "Loaded: Secondary - DISABALITY 2020-2025\n",
            "Loaded: LGAs Urban and Rural Status\n",
            "Loaded: Combined_Secondary_Laboratories_Govt\n",
            "Loaded: Combined_Secondary_Laboratories_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_Govt\n",
            "Loaded: Combined_Secondary_Electricity_All_G_NG\n",
            "Loaded: Combined_Secondary_Electricity_Govt\n",
            "Loaded: Secondary_students_per_subject\n",
            "Loaded: Secondary_enrollment_Gov_2016_2025\n",
            "Loaded: Data-Secondary Enrollment 2016-2025 (1)\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025\n",
            "Merged LGA Status into Dropout-Secondary  2017-2024\n",
            "Merged LGA Status into Data-Secondary Tables and chairs 2016-2025\n",
            "Merged LGA Status into Secondary-Re_entry\n",
            "Merged LGA Status into Secondary - DISABALITY 2020-2025\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_Govt\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_Govt\n",
            "Merged LGA Status into Combined_Secondary_Electricity_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_Electricity_Govt\n",
            "Merged LGA Status into Secondary_students_per_subject\n",
            "Merged LGA Status into Secondary_enrollment_Gov_2016_2025\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025 (1)\n",
            "\n",
            "--- Starting Feature Engineering ---\n",
            "Melting 391 subject columns...\n",
            "\n",
            "--- Starting Model Engine ---\n",
            "\n",
            "Training all candidate models on Data <= 2023...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Training Random Forest...\n",
            "Training HistGradientBoosting...\n",
            "Training GradientBoosting...\n",
            "All models trained successfully.\n",
            "\n",
            "--- Evaluation Results (Test Data 2024+) ---\n",
            "Evaluating all models...\n",
            "--- XGB Results ---\n",
            "   > XGB: R2=0.9266, MAE=59.80, RMSE=408.22, MAPE=2,475.6%, Acc=-2375.6%\n",
            "------------------------------\n",
            "Model: XGB | RMSE: 408.22\n",
            "--- LGB Results ---\n",
            "   > LGB: R2=0.9214, MAE=59.88, RMSE=422.59, MAPE=2,145.6%, Acc=-2045.6%\n",
            "------------------------------\n",
            "Model: LGB | RMSE: 422.59\n",
            "--- RF Results ---\n",
            "   > RF: R2=0.9269, MAE=57.66, RMSE=407.54, MAPE=2,462.1%, Acc=-2362.1%\n",
            "------------------------------\n",
            "Model: RF | RMSE: 407.54\n",
            "--- HGB Results ---\n",
            "   > HGB: R2=0.9046, MAE=87.31, RMSE=465.59, MAPE=2,919.1%, Acc=-2819.1%\n",
            "------------------------------\n",
            "Model: HGB | RMSE: 465.59\n",
            "--- GB Results ---\n",
            "   > GB: R2=0.9307, MAE=53.76, RMSE=396.83, MAPE=2,274.6%, Acc=-2174.6%\n",
            "------------------------------\n",
            "Model: GB | RMSE: 396.83\n",
            "\n",
            "BEST MODEL: GB (RMSE: 396.83)\n",
            "Selection Threshold (RMSE <= 634.93)\n",
            "Qualifying Models: ['XGB', 'LGB', 'RF', 'HGB', 'GB']\n",
            "Strategy: ENSEMBLE (Average of XGB, LGB, RF, HGB, GB)\n",
            "\n",
            "Starting Recursive Forecast (2026-2030) using ['XGB', 'LGB', 'RF', 'HGB', 'GB']...\n",
            " > Forecasted 2026\n",
            " > Forecasted 2027\n",
            " > Forecasted 2028\n",
            " > Forecasted 2029\n",
            " > Forecasted 2030\n",
            "\n",
            "--- Final Forecast Sample ---\n",
            "   YEAR  REGION COUNCIL                         SUBJECT  FORM_NUM  ENROLLMENT\n",
            "0  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         1          53\n",
            "1  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         2          14\n",
            "2  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         3          52\n",
            "3  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         4          46\n",
            "4  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          53\n",
            "5  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          52\n",
            "6  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          14\n",
            "7  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          13\n",
            "8  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          52\n",
            "9  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          13\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Refactored MoEST Modeling for Secondary School Enrollment\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    GradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 1: Data Loader & Cleaner\n",
        "# =============================================================================\n",
        "\n",
        "class MOESTDataLoader:\n",
        "    \"\"\"\n",
        "    Handles mounting drive, loading CSVs, cleaning headers, handling types,\n",
        "    and managing initial data quality checks.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_directory, exclude_keywords=None):\n",
        "        self.base_directory = base_directory\n",
        "        self.exclude_keywords = exclude_keywords if exclude_keywords else []\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def mount_drive(self):\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "    def get_file_list(self):\n",
        "        all_files = [f for f in os.listdir(self.base_directory) if f.endswith('.csv')]\n",
        "        filtered_files = []\n",
        "        for file_name in all_files:\n",
        "            if not any(keyword.lower() in file_name.lower() for keyword in self.exclude_keywords):\n",
        "                filtered_files.append(file_name)\n",
        "        return filtered_files\n",
        "\n",
        "    def load_data(self):\n",
        "        files = self.get_file_list()\n",
        "        print(f\"Found {len(files)} files to load.\")\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(self.base_directory, file_name)\n",
        "            df_name = file_name.replace('.csv', '')\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                self.dataframes[df_name] = self._initial_clean(df)\n",
        "                print(f\"Loaded: {df_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    def _initial_clean(self, df):\n",
        "        \"\"\"Standardizes headers and cleans numeric columns.\"\"\"\n",
        "        df.columns = [str(col).strip().upper() for col in df.columns]\n",
        "\n",
        "        for col in df.select_dtypes(include='object').columns:\n",
        "            if df[col].astype(str).str.contains(',').any():\n",
        "                cleaned = df[col].astype(str).str.replace(',', '', regex=False)\n",
        "                converted = pd.to_numeric(cleaned, errors='coerce')\n",
        "                if converted.notna().sum() > 0:\n",
        "                    df[col] = converted\n",
        "\n",
        "        unnamed = [c for c in df.columns if 'UNNAMED' in c]\n",
        "        to_drop = [c for c in unnamed if df[c].isnull().mean() > 0.9]\n",
        "        df.drop(columns=to_drop, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "    def get_all_dataframes(self):\n",
        "        return self.dataframes\n",
        "\n",
        "    def inject_dataframe(self, name, df):\n",
        "        \"\"\"Allows manual injection of dataframes if needed.\"\"\"\n",
        "        self.dataframes[name] = self._initial_clean(df)\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 2: Geography & Location Manager\n",
        "# =============================================================================\n",
        "\n",
        "class LocationManager:\n",
        "    \"\"\"\n",
        "    Handles Geocoding, LGA Status merging, and Clustering.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframes, geodata_path):\n",
        "        self.dataframes = dataframes\n",
        "        self.geodata_path = geodata_path\n",
        "        self.geo_data = None\n",
        "        self.lga_status_df = None\n",
        "\n",
        "    def standardize_location_columns(self):\n",
        "        for name, df in self.dataframes.items():\n",
        "            reg_col = next((c for c in df.columns if c in ['REGION', 'REGON']), None)\n",
        "            cou_col = next((c for c in df.columns if c in ['COUNCIL', 'DISTRICT', 'LGA NAME']), None)\n",
        "\n",
        "            if reg_col and cou_col:\n",
        "                df.rename(columns={reg_col: 'REGION', cou_col: 'COUNCIL'}, inplace=True)\n",
        "                df['REGION'] = df['REGION'].astype(str).str.upper()\n",
        "                df['COUNCIL'] = df['COUNCIL'].astype(str).str.upper()\n",
        "\n",
        "    def merge_lga_status(self, lga_df_name='LGAs Urban and Rural Status'):\n",
        "        if lga_df_name not in self.dataframes:\n",
        "            print(\"LGA Status DataFrame not found.\")\n",
        "            return\n",
        "\n",
        "        self.lga_status_df = self.dataframes[lga_df_name].copy()\n",
        "        if 'REMARKS' in self.lga_status_df.columns:\n",
        "            self.lga_status_df.drop(columns=['REMARKS'], inplace=True)\n",
        "        self.lga_status_df.rename(columns={'CLASSIFICATION': 'LGA_STATUS'}, inplace=True)\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if name == lga_df_name: continue\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.lga_status_df, on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged LGA Status into {name}\")\n",
        "        del self.dataframes[lga_df_name]\n",
        "\n",
        "    def process_geocoding(self):\n",
        "        if os.path.exists(self.geodata_path):\n",
        "            print(\"Loading existing geodata...\")\n",
        "            self.geo_data = pd.read_csv(self.geodata_path)\n",
        "        else:\n",
        "            print(\"Generating new geodata...\")\n",
        "            self._fetch_geodata()\n",
        "\n",
        "        self._apply_clustering()\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.geo_data[['REGION', 'COUNCIL', 'GEO_CLUSTER']],\n",
        "                                  on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged Geo Cluster into {name}\")\n",
        "\n",
        "    def _fetch_geodata(self):\n",
        "        locs = []\n",
        "        for df in self.dataframes.values():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                locs.append(df[['REGION', 'COUNCIL']])\n",
        "        unique_locs = pd.concat(locs).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        geolocator = Nominatim(user_agent=\"moest_geo_mapper_v3\")\n",
        "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1.0)\n",
        "\n",
        "        lats, lons = [], []\n",
        "        for idx, row in unique_locs.iterrows():\n",
        "            query = f\"{row['COUNCIL']}, {row['REGION']}, Tanzania\"\n",
        "            try:\n",
        "                loc = geocode(query)\n",
        "                if loc:\n",
        "                    lats.append(loc.latitude)\n",
        "                    lons.append(loc.longitude)\n",
        "                else:\n",
        "                    lats.append(None)\n",
        "                    lons.append(None)\n",
        "            except:\n",
        "                lats.append(None)\n",
        "                lons.append(None)\n",
        "\n",
        "        unique_locs['LATITUDE'] = lats\n",
        "        unique_locs['LONGITUDE'] = lons\n",
        "        self.geo_data = unique_locs.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "        self.geo_data.to_csv(self.geodata_path, index=False)\n",
        "\n",
        "    def _apply_clustering(self):\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        self.geo_data['GEO_CLUSTER'] = kmeans.fit_predict(self.geo_data[['LATITUDE', 'LONGITUDE']])\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 3: Feature Engineer\n",
        "# =============================================================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"\n",
        "    Handles specific transformation logic for Secondary School Subjects.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def melt_subjects(df):\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in df.columns]\n",
        "        subject_cols = [c for c in df.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        print(f\"Melting {len(subject_cols)} subject columns...\")\n",
        "        long_df = df.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "        return long_df\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_infrastructure(main_df, auxiliary_dfs):\n",
        "        \"\"\"\n",
        "        Merges Tables, Labs, ICT, Electricity, Dropout, Reentry, Disability.\n",
        "        \"\"\"\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "        df = main_df.copy()\n",
        "\n",
        "        # 1. Tables\n",
        "        tables = auxiliary_dfs.get('tables')\n",
        "        if tables is not None and 'AVAILABLE_TABLES' in tables.columns:\n",
        "            df = df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna({'AVAILABLE_TABLES': 0})\n",
        "\n",
        "        # 2. Labs (Total)\n",
        "        labs = auxiliary_dfs.get('labs')\n",
        "        if labs is not None:\n",
        "            lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "            if lab_cols:\n",
        "                labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "                df = df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna({'TOTAL_LABS': 0})\n",
        "\n",
        "        # 3. ICT (Computers)\n",
        "        ict = auxiliary_dfs.get('ict')\n",
        "        if ict is not None:\n",
        "             # Assuming columns like 'DESKTOP COMPUTERS' or similar exist; summing generic computer columns\n",
        "             comp_cols = [c for c in ict.columns if 'COMPUTER' in c]\n",
        "             if comp_cols:\n",
        "                 ict['TOTAL_COMPUTERS'] = ict[comp_cols].sum(axis=1)\n",
        "                 df = df.merge(ict[keys + ['TOTAL_COMPUTERS']], on=keys, how='left').fillna({'TOTAL_COMPUTERS': 0})\n",
        "\n",
        "        # 4. Electricity\n",
        "        elec = auxiliary_dfs.get('electricity')\n",
        "        if elec is not None:\n",
        "            # Look for grid/tanesco columns\n",
        "            grid_col = next((c for c in elec.columns if 'TANESCO' in c or 'GRID' in c), None)\n",
        "            if grid_col:\n",
        "                df = df.merge(elec[keys + [grid_col]], on=keys, how='left').fillna({grid_col: 0})\n",
        "                df.rename(columns={grid_col: 'ELEC_GRID_PCT'}, inplace=True)\n",
        "\n",
        "        # 5. Re-entry\n",
        "        reentry = auxiliary_dfs.get('reentry')\n",
        "        if reentry is not None:\n",
        "            re_cols = [c for c in reentry.columns if 'RE-ENROLLED' in c]\n",
        "            if re_cols:\n",
        "                reentry['TOTAL_REENTRY'] = reentry[re_cols].sum(axis=1)\n",
        "                df = df.merge(reentry[keys + ['TOTAL_REENTRY']], on=keys, how='left').fillna({'TOTAL_REENTRY': 0})\n",
        "\n",
        "        # 6. Disability\n",
        "        disability = auxiliary_dfs.get('disability')\n",
        "        if disability is not None:\n",
        "            # Sum all disability columns (excluding metadata)\n",
        "            dis_cols = [c for c in disability.columns if c not in keys + ['Unnamed: 0']]\n",
        "            # Filter for numeric columns only to be safe\n",
        "            dis_cols = [c for c in dis_cols if pd.api.types.is_numeric_dtype(disability[c])]\n",
        "            if dis_cols:\n",
        "                disability['TOTAL_DISABLED'] = disability[dis_cols].sum(axis=1)\n",
        "                df = df.merge(disability[keys + ['TOTAL_DISABLED']], on=keys, how='left').fillna({'TOTAL_DISABLED': 0})\n",
        "\n",
        "        # 7. Dropout (Aggregated)\n",
        "        dropout = auxiliary_dfs.get('dropout')\n",
        "        if dropout is not None:\n",
        "            # Sum dropout reasons\n",
        "            drop_cols = [c for c in dropout.columns if c not in keys]\n",
        "            drop_cols = [c for c in drop_cols if pd.api.types.is_numeric_dtype(dropout[c])]\n",
        "            if drop_cols:\n",
        "                dropout['TOTAL_DROPOUT'] = dropout[drop_cols].sum(axis=1)\n",
        "                df = df.merge(dropout[keys + ['TOTAL_DROPOUT']], on=keys, how='left').fillna({'TOTAL_DROPOUT': 0})\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_lag_features(df):\n",
        "        df = df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2015, 2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_cohort_features(df):\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup_dict = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup_dict).fillna(-1)\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 4: Model Engine (Conditional Ensemble)\n",
        "# =============================================================================\n",
        "\n",
        "class EnrollmentModelEngine:\n",
        "    \"\"\"\n",
        "    Manages Training, Conditional Selection, and Recursive Forecasting.\n",
        "    Implements logic: Use Best Model ONLY unless others are within 40% performance.\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.models = {}\n",
        "        self.encoders = {}\n",
        "        self.features = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_LABS', 'TOTAL_COMPUTERS', 'ELEC_GRID_PCT',\n",
        "            'TOTAL_REENTRY', 'TOTAL_DISABLED', 'TOTAL_DROPOUT',\n",
        "            'LAG_1', 'LAG_2', 'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "        # Filter features to ensure they exist in DF\n",
        "        self.features = [f for f in self.features if f in df.columns]\n",
        "        self.selected_model_keys = [] # Stores keys of models to be used for inference\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.encoders['REG'] = LabelEncoder()\n",
        "        self.encoders['COU'] = LabelEncoder()\n",
        "        self.encoders['SUB'] = LabelEncoder()\n",
        "\n",
        "        self.df['REGION_ENC'] = self.encoders['REG'].fit_transform(self.df['REGION'].astype(str))\n",
        "        self.df['COUNCIL_ENC'] = self.encoders['COU'].fit_transform(self.df['COUNCIL'].astype(str))\n",
        "        self.df['SUBJECT_ENC'] = self.encoders['SUB'].fit_transform(self.df['SUBJECT'].astype(str))\n",
        "\n",
        "    def train_all_models(self, cutoff_year=2023):\n",
        "        \"\"\"Trains all 5 candidate models.\"\"\"\n",
        "        print(f\"\\nTraining all candidate models on Data <= {cutoff_year}...\")\n",
        "        train_df = self.df[self.df['YEAR'] <= cutoff_year]\n",
        "        X = train_df[self.features]\n",
        "        y = train_df['ENROLLMENT']\n",
        "\n",
        "        # 1. XGBoost\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['XGB'] = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1)\n",
        "        self.models['XGB'].fit(X, y)\n",
        "\n",
        "        # 2. LightGBM\n",
        "        print(\"Training LightGBM...\")\n",
        "        self.models['LGB'] = lgb.LGBMRegressor(n_estimators=500, num_leaves=50, min_child_samples=10, learning_rate=0.1, verbose=-1)\n",
        "        self.models['LGB'].fit(X, y)\n",
        "\n",
        "        # 3. Random Forest\n",
        "        print(\"Training Random Forest...\")\n",
        "        self.models['RF'] = RandomForestRegressor(n_estimators=300, max_depth=12, n_jobs=-1, random_state=42)\n",
        "        self.models['RF'].fit(X, y)\n",
        "\n",
        "        # 4. HistGradientBoosting (Scikit-Learn)\n",
        "        print(\"Training HistGradientBoosting...\")\n",
        "        self.models['HGB'] = HistGradientBoostingRegressor(max_iter=500, learning_rate=0.1, max_depth=10)\n",
        "        self.models['HGB'].fit(X, y)\n",
        "\n",
        "        # 5. GradientBoosting (Standard)\n",
        "        print(\"Training GradientBoosting...\")\n",
        "        self.models['GB'] = GradientBoostingRegressor(n_estimators=300, max_depth=9, learning_rate=0.05)\n",
        "        self.models['GB'].fit(X, y)\n",
        "\n",
        "        print(\"All models trained successfully.\")\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        mask = y_true != 0\n",
        "        if mask.sum() > 0:\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "            accuracy = 100 - mape\n",
        "        else:\n",
        "            mape = np.nan\n",
        "            accuracy = np.nan\n",
        "\n",
        "        print(f\"--- {model_name} Results ---\")\n",
        "        print(f\"   > {model_name}: R2={r2:.4f}, MAE={mae:,.2f}, RMSE={rmse:,.2f}, MAPE={mape:,.1f}%, Acc={accuracy:.1f}%\")\n",
        "        print(\"-\" * 30)\n",
        "        return rmse\n",
        "\n",
        "    def evaluate_and_select_strategy(self, test_year_start=2024):\n",
        "        test_df = self.df[self.df['YEAR'] >= test_year_start]\n",
        "        if test_df.empty:\n",
        "            print(\"No test data available. Defaulting to XGB only.\")\n",
        "            self.selected_model_keys = ['XGB']\n",
        "            return\n",
        "\n",
        "        X_test = test_df[self.features]\n",
        "        y_true = test_df['ENROLLMENT']\n",
        "\n",
        "        performance = {}\n",
        "        print(f\"\\n--- Evaluation Results (Test Data {test_year_start}+) ---\")\n",
        "\n",
        "        print(\"Evaluating all models...\")\n",
        "        for name, model in self.models.items():\n",
        "            preds = model.predict(X_test)\n",
        "            rmse = self.calculate_metrics(y_true, preds, name)\n",
        "            performance[name] = rmse\n",
        "            print(f\"Model: {name} | RMSE: {rmse:,.2f}\")\n",
        "\n",
        "        best_model_name = min(performance, key=performance.get)\n",
        "        best_rmse = performance[best_model_name]\n",
        "        print(f\"\\nBEST MODEL: {best_model_name} (RMSE: {best_rmse:,.2f})\")\n",
        "\n",
        "        # Threshold: Best RMSE + 60% of Best RMSE\n",
        "        threshold = best_rmse * 1.6\n",
        "        candidates = [name for name, score in performance.items() if score <= threshold]\n",
        "\n",
        "        print(f\"Selection Threshold (RMSE <= {threshold:,.2f})\")\n",
        "        print(f\"Qualifying Models: {candidates}\")\n",
        "\n",
        "        if len(candidates) > 1:\n",
        "            self.selected_model_keys = candidates\n",
        "            print(f\"Strategy: ENSEMBLE (Average of {', '.join(candidates)})\")\n",
        "        else:\n",
        "            self.selected_model_keys = [best_model_name]\n",
        "            print(f\"Strategy: SINGLE BEST MODEL ({best_model_name})\")\n",
        "\n",
        "    def _predict(self, X):\n",
        "        preds = []\n",
        "        for key in self.selected_model_keys:\n",
        "            preds.append(self.models[key].predict(X))\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    def recursive_forecast(self, start_year, end_year):\n",
        "        print(f\"\\nStarting Recursive Forecast ({start_year}-{end_year}) using {self.selected_model_keys}...\")\n",
        "        future_data = []\n",
        "        current_data = self.df[self.df['YEAR'] == (start_year - 1)].copy()\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            next_df = self._prepare_next_step(current_data, year)\n",
        "\n",
        "            X_future = next_df[self.features]\n",
        "            preds = self._predict(X_future)\n",
        "\n",
        "            next_df['ENROLLMENT'] = np.maximum(0, preds)\n",
        "\n",
        "            future_data.append(next_df)\n",
        "            current_data = next_df.copy()\n",
        "            print(f\" > Forecasted {year}\")\n",
        "\n",
        "        return pd.concat(future_data, ignore_index=True)\n",
        "\n",
        "    def _prepare_next_step(self, prev_df, target_year):\n",
        "        next_df = prev_df.copy()\n",
        "        next_df['YEAR'] = target_year\n",
        "\n",
        "        next_df['LAG_2'] = next_df['LAG_1']\n",
        "        next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "\n",
        "        next_df['YOY_GROWTH'] = (next_df['LAG_1'] - next_df['LAG_2']) / (next_df['LAG_2'] + 1e-5)\n",
        "\n",
        "        cohort_lookup = prev_df.set_index(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort(row):\n",
        "            target_form = row['FORM_NUM'] - 1\n",
        "            if target_form < 1: return -1\n",
        "            key = (row['REGION'], row['COUNCIL'], row['SUBJECT'], target_form)\n",
        "            return cohort_lookup.get(key, -1)\n",
        "\n",
        "        next_df['COHORT_LAG'] = next_df.apply(get_cohort, axis=1)\n",
        "        next_df['IS_ELECTION_YEAR'] = 1 if target_year in [2025, 2030] else 0\n",
        "\n",
        "        return next_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # 1. Configuration\n",
        "    BASE_DIR = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEO_FILE = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'Teacher', 'COBET', 'Vocational']\n",
        "\n",
        "    # 2. Load Data\n",
        "    loader = MOESTDataLoader(BASE_DIR, EXCLUDE_KEYWORDS)\n",
        "    loader.mount_drive()\n",
        "    loader.load_data()\n",
        "    all_dfs = loader.get_all_dataframes()\n",
        "\n",
        "    # 3. Location & Clean Up\n",
        "    loc_manager = LocationManager(all_dfs, GEO_FILE)\n",
        "    loc_manager.standardize_location_columns()\n",
        "    loc_manager.merge_lga_status()\n",
        "\n",
        "    # 4. Feature Engineering\n",
        "    print(\"\\n--- Starting Feature Engineering ---\")\n",
        "\n",
        "    # Retrieve all required DataFrames\n",
        "    df_subject = all_dfs.get(\"Secondary_students_per_subject\")\n",
        "    df_tables = all_dfs.get(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "    df_labs = all_dfs.get(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "    df_dropout = all_dfs.get(\"Dropout-Secondary  2017-2024\")\n",
        "    df_reentry = all_dfs.get(\"Secondary-Re_entry\")\n",
        "    df_disability = all_dfs.get(\"Secondary - DISABALITY 2020-2025\")\n",
        "    df_ict = all_dfs.get(\"Combined_Secondary_ICT_All_G_NG\")\n",
        "    df_elec = all_dfs.get(\"Combined_Secondary_Electricity_All_G_NG\")\n",
        "\n",
        "    if df_subject is None:\n",
        "        raise ValueError(\"Critical DataFrame 'Secondary_students_per_subject' not found.\")\n",
        "\n",
        "    # Package auxiliary dfs for cleaner function signature\n",
        "    aux_dfs = {\n",
        "        'tables': df_tables,\n",
        "        'labs': df_labs,\n",
        "        'dropout': df_dropout,\n",
        "        'reentry': df_reentry,\n",
        "        'disability': df_disability,\n",
        "        'ict': df_ict,\n",
        "        'electricity': df_elec\n",
        "    }\n",
        "\n",
        "    engineer = FeatureEngineer()\n",
        "    long_df = engineer.melt_subjects(df_subject)\n",
        "    # Merge all auxiliary data\n",
        "    merged_df = engineer.merge_infrastructure(long_df, aux_dfs)\n",
        "    lagged_df = engineer.create_lag_features(merged_df)\n",
        "    final_df = engineer.create_cohort_features(lagged_df)\n",
        "\n",
        "    # 5. Modeling & Forecasting (Updated Strategy)\n",
        "    print(\"\\n--- Starting Model Engine ---\")\n",
        "    engine = EnrollmentModelEngine(final_df)\n",
        "    engine.preprocess()\n",
        "\n",
        "    # Train (Using data up to 2023 to test on 2024 and 2025)\n",
        "    engine.train_all_models(cutoff_year=2023)\n",
        "\n",
        "    # Evaluate & Select Strategy (Best or Ensemble)\n",
        "    engine.evaluate_and_select_strategy(test_year_start=2024)\n",
        "\n",
        "    # 6. Generate Forecast\n",
        "    # Note: Recursive forecast starts from 2026, using 2025 as the base history\n",
        "    forecast_df = engine.recursive_forecast(2026, 2030)\n",
        "\n",
        "    # 7. Output\n",
        "    print(\"\\n--- Final Forecast Sample ---\")\n",
        "    output_cols = ['YEAR', 'REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'ENROLLMENT']\n",
        "    final_view = forecast_df[output_cols].copy()\n",
        "    final_view['ENROLLMENT'] = final_view['ENROLLMENT'].round(0).astype(int)\n",
        "    print(final_view.head(10))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgWNiRETyixd",
        "outputId": "46c1178b-32de-4748-e2ca-abd5b806f5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Found 15 files to load.\n",
            "Loaded: Data-Secondary Enrollment 2016-2025\n",
            "Loaded: Dropout-Secondary  2017-2024\n",
            "Loaded: Data-Secondary Tables and chairs 2016-2025\n",
            "Loaded: Secondary-Re_entry\n",
            "Loaded: Secondary - DISABALITY 2020-2025\n",
            "Loaded: LGAs Urban and Rural Status\n",
            "Loaded: Combined_Secondary_Laboratories_Govt\n",
            "Loaded: Combined_Secondary_Laboratories_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_Govt\n",
            "Loaded: Combined_Secondary_Electricity_All_G_NG\n",
            "Loaded: Combined_Secondary_Electricity_Govt\n",
            "Loaded: Secondary_students_per_subject\n",
            "Loaded: Secondary_enrollment_Gov_2016_2025\n",
            "Loaded: Data-Secondary Enrollment 2016-2025 (1)\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025\n",
            "Merged LGA Status into Dropout-Secondary  2017-2024\n",
            "Merged LGA Status into Data-Secondary Tables and chairs 2016-2025\n",
            "Merged LGA Status into Secondary-Re_entry\n",
            "Merged LGA Status into Secondary - DISABALITY 2020-2025\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_Govt\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_Govt\n",
            "Merged LGA Status into Combined_Secondary_Electricity_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_Electricity_Govt\n",
            "Merged LGA Status into Secondary_students_per_subject\n",
            "Merged LGA Status into Secondary_enrollment_Gov_2016_2025\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025 (1)\n",
            "\n",
            "--- Starting Feature Engineering ---\n",
            "Melting 391 subject columns...\n",
            "\n",
            "--- Starting Model Engine ---\n",
            "\n",
            "Training all candidate models on Data <= 2023...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Training Random Forest...\n",
            "Training HistGradientBoosting...\n",
            "Training GradientBoosting...\n",
            "All models trained successfully.\n",
            "\n",
            "--- Evaluation Results (Test Data 2024+) ---\n",
            "Evaluating all models...\n",
            "--- XGB Results ---\n",
            "   > XGB: R2=0.9213, MAE=60.92, RMSE=422.94, WMAPE=15.84%, Acc=84.16%\n",
            "------------------------------\n",
            "--- LGB Results ---\n",
            "   > LGB: R2=0.9286, MAE=59.28, RMSE=402.62, WMAPE=15.41%, Acc=84.59%\n",
            "------------------------------\n",
            "\n",
            "BEST MODEL: LGB (RMSE: 402.62)\n",
            "Selection Threshold (RMSE <= 644.19)\n",
            "Qualifying Models: ['XGB', 'LGB']\n",
            "Strategy: ENSEMBLE (Average of XGB, LGB)\n",
            "\n",
            "Starting Recursive Forecast (2026-2030) using ['XGB', 'LGB']...\n",
            " > Forecasted 2026\n",
            " > Forecasted 2027\n",
            " > Forecasted 2028\n",
            " > Forecasted 2029\n",
            " > Forecasted 2030\n",
            "\n",
            "--- Final Forecast Sample ---\n",
            "   YEAR  REGION COUNCIL                         SUBJECT  FORM_NUM  ENROLLMENT\n",
            "0  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         1          66\n",
            "1  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         2           7\n",
            "2  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         3          57\n",
            "3  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         4          51\n",
            "4  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          66\n",
            "5  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          60\n",
            "6  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2           7\n",
            "7  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          12\n",
            "8  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          54\n",
            "9  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          11\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Refactored MoEST Modeling for Secondary School Enrollment\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    GradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 1: Data Loader & Cleaner\n",
        "# =============================================================================\n",
        "\n",
        "class MOESTDataLoader:\n",
        "    \"\"\"\n",
        "    Handles mounting drive, loading CSVs, cleaning headers, handling types,\n",
        "    and managing initial data quality checks.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_directory, exclude_keywords=None):\n",
        "        self.base_directory = base_directory\n",
        "        self.exclude_keywords = exclude_keywords if exclude_keywords else []\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def mount_drive(self):\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "    def get_file_list(self):\n",
        "        all_files = [f for f in os.listdir(self.base_directory) if f.endswith('.csv')]\n",
        "        filtered_files = []\n",
        "        for file_name in all_files:\n",
        "            if not any(keyword.lower() in file_name.lower() for keyword in self.exclude_keywords):\n",
        "                filtered_files.append(file_name)\n",
        "        return filtered_files\n",
        "\n",
        "    def load_data(self):\n",
        "        files = self.get_file_list()\n",
        "        print(f\"Found {len(files)} files to load.\")\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(self.base_directory, file_name)\n",
        "            df_name = file_name.replace('.csv', '')\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                self.dataframes[df_name] = self._initial_clean(df)\n",
        "                print(f\"Loaded: {df_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    def _initial_clean(self, df):\n",
        "        \"\"\"Standardizes headers and cleans numeric columns.\"\"\"\n",
        "        df.columns = [str(col).strip().upper() for col in df.columns]\n",
        "\n",
        "        for col in df.select_dtypes(include='object').columns:\n",
        "            if df[col].astype(str).str.contains(',').any():\n",
        "                cleaned = df[col].astype(str).str.replace(',', '', regex=False)\n",
        "                converted = pd.to_numeric(cleaned, errors='coerce')\n",
        "                if converted.notna().sum() > 0:\n",
        "                    df[col] = converted\n",
        "\n",
        "        unnamed = [c for c in df.columns if 'UNNAMED' in c]\n",
        "        to_drop = [c for c in unnamed if df[c].isnull().mean() > 0.9]\n",
        "        df.drop(columns=to_drop, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "    def get_all_dataframes(self):\n",
        "        return self.dataframes\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 2: Geography & Location Manager\n",
        "# =============================================================================\n",
        "\n",
        "class LocationManager:\n",
        "    \"\"\"\n",
        "    Handles Geocoding, LGA Status merging, and Clustering.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframes, geodata_path):\n",
        "        self.dataframes = dataframes\n",
        "        self.geodata_path = geodata_path\n",
        "        self.geo_data = None\n",
        "        self.lga_status_df = None\n",
        "\n",
        "    def standardize_location_columns(self):\n",
        "        for name, df in self.dataframes.items():\n",
        "            reg_col = next((c for c in df.columns if c in ['REGION', 'REGON']), None)\n",
        "            cou_col = next((c for c in df.columns if c in ['COUNCIL', 'DISTRICT', 'LGA NAME']), None)\n",
        "\n",
        "            if reg_col and cou_col:\n",
        "                df.rename(columns={reg_col: 'REGION', cou_col: 'COUNCIL'}, inplace=True)\n",
        "                df['REGION'] = df['REGION'].astype(str).str.upper()\n",
        "                df['COUNCIL'] = df['COUNCIL'].astype(str).str.upper()\n",
        "\n",
        "    def merge_lga_status(self, lga_df_name='LGAs Urban and Rural Status'):\n",
        "        if lga_df_name not in self.dataframes:\n",
        "            print(\"LGA Status DataFrame not found.\")\n",
        "            return\n",
        "\n",
        "        self.lga_status_df = self.dataframes[lga_df_name].copy()\n",
        "        if 'REMARKS' in self.lga_status_df.columns:\n",
        "            self.lga_status_df.drop(columns=['REMARKS'], inplace=True)\n",
        "        self.lga_status_df.rename(columns={'CLASSIFICATION': 'LGA_STATUS'}, inplace=True)\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if name == lga_df_name: continue\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.lga_status_df, on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged LGA Status into {name}\")\n",
        "        del self.dataframes[lga_df_name]\n",
        "\n",
        "    def process_geocoding(self):\n",
        "        if os.path.exists(self.geodata_path):\n",
        "            print(\"Loading existing geodata...\")\n",
        "            self.geo_data = pd.read_csv(self.geodata_path)\n",
        "        else:\n",
        "            print(\"Generating new geodata...\")\n",
        "            self._fetch_geodata()\n",
        "\n",
        "        self._apply_clustering()\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.geo_data[['REGION', 'COUNCIL', 'GEO_CLUSTER']],\n",
        "                                  on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged Geo Cluster into {name}\")\n",
        "\n",
        "    def _fetch_geodata(self):\n",
        "        locs = []\n",
        "        for df in self.dataframes.values():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                locs.append(df[['REGION', 'COUNCIL']])\n",
        "        unique_locs = pd.concat(locs).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        geolocator = Nominatim(user_agent=\"moest_geo_mapper_v3\")\n",
        "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1.0)\n",
        "\n",
        "        lats, lons = [], []\n",
        "        for idx, row in unique_locs.iterrows():\n",
        "            query = f\"{row['COUNCIL']}, {row['REGION']}, Tanzania\"\n",
        "            try:\n",
        "                loc = geocode(query)\n",
        "                if loc:\n",
        "                    lats.append(loc.latitude)\n",
        "                    lons.append(loc.longitude)\n",
        "                else:\n",
        "                    lats.append(None)\n",
        "                    lons.append(None)\n",
        "            except:\n",
        "                lats.append(None)\n",
        "                lons.append(None)\n",
        "\n",
        "        unique_locs['LATITUDE'] = lats\n",
        "        unique_locs['LONGITUDE'] = lons\n",
        "        self.geo_data = unique_locs.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "        self.geo_data.to_csv(self.geodata_path, index=False)\n",
        "\n",
        "    def _apply_clustering(self):\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        self.geo_data['GEO_CLUSTER'] = kmeans.fit_predict(self.geo_data[['LATITUDE', 'LONGITUDE']])\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 3: Feature Engineer\n",
        "# =============================================================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"\n",
        "    Handles specific transformation logic for Secondary School Subjects.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def melt_subjects(df):\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in df.columns]\n",
        "        subject_cols = [c for c in df.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        print(f\"Melting {len(subject_cols)} subject columns...\")\n",
        "        long_df = df.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "        return long_df\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_infrastructure(main_df, auxiliary_dfs):\n",
        "        \"\"\"\n",
        "        Merges Tables, Labs, ICT, Electricity, Dropout, Reentry, Disability.\n",
        "        \"\"\"\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "        df = main_df.copy()\n",
        "\n",
        "        # 1. Tables\n",
        "        tables = auxiliary_dfs.get('tables')\n",
        "        if tables is not None and 'AVAILABLE_TABLES' in tables.columns:\n",
        "            df = df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna({'AVAILABLE_TABLES': 0})\n",
        "\n",
        "        # 2. Labs (Total)\n",
        "        labs = auxiliary_dfs.get('labs')\n",
        "        if labs is not None:\n",
        "            lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "            if lab_cols:\n",
        "                labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "                df = df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna({'TOTAL_LABS': 0})\n",
        "\n",
        "        # 3. ICT (Computers)\n",
        "        ict = auxiliary_dfs.get('ict')\n",
        "        if ict is not None:\n",
        "             comp_cols = [c for c in ict.columns if 'COMPUTER' in c]\n",
        "             if comp_cols:\n",
        "                 ict['TOTAL_COMPUTERS'] = ict[comp_cols].sum(axis=1)\n",
        "                 df = df.merge(ict[keys + ['TOTAL_COMPUTERS']], on=keys, how='left').fillna({'TOTAL_COMPUTERS': 0})\n",
        "\n",
        "        # 4. Electricity\n",
        "        elec = auxiliary_dfs.get('electricity')\n",
        "        if elec is not None:\n",
        "            grid_col = next((c for c in elec.columns if 'TANESCO' in c or 'GRID' in c), None)\n",
        "            if grid_col:\n",
        "                df = df.merge(elec[keys + [grid_col]], on=keys, how='left').fillna({grid_col: 0})\n",
        "                df.rename(columns={grid_col: 'ELEC_GRID_PCT'}, inplace=True)\n",
        "\n",
        "        # 5. Re-entry\n",
        "        reentry = auxiliary_dfs.get('reentry')\n",
        "        if reentry is not None:\n",
        "            re_cols = [c for c in reentry.columns if 'RE-ENROLLED' in c]\n",
        "            if re_cols:\n",
        "                reentry['TOTAL_REENTRY'] = reentry[re_cols].sum(axis=1)\n",
        "                df = df.merge(reentry[keys + ['TOTAL_REENTRY']], on=keys, how='left').fillna({'TOTAL_REENTRY': 0})\n",
        "\n",
        "        # 6. Disability\n",
        "        disability = auxiliary_dfs.get('disability')\n",
        "        if disability is not None:\n",
        "            dis_cols = [c for c in disability.columns if c not in keys + ['Unnamed: 0']]\n",
        "            dis_cols = [c for c in dis_cols if pd.api.types.is_numeric_dtype(disability[c])]\n",
        "            if dis_cols:\n",
        "                disability['TOTAL_DISABLED'] = disability[dis_cols].sum(axis=1)\n",
        "                df = df.merge(disability[keys + ['TOTAL_DISABLED']], on=keys, how='left').fillna({'TOTAL_DISABLED': 0})\n",
        "\n",
        "        # 7. Dropout (Specific Columns: Truancy, Pregnancy, Indiscipline)\n",
        "        dropout = auxiliary_dfs.get('dropout')\n",
        "        if dropout is not None:\n",
        "            # Check for specific columns\n",
        "            target_cols = ['TRUANCY', 'PREGNANCY', 'INDISCIPLINE']\n",
        "            existing_cols = [c for c in target_cols if c in dropout.columns]\n",
        "\n",
        "            if existing_cols:\n",
        "                df = df.merge(dropout[keys + existing_cols], on=keys, how='left')\n",
        "                # Fill NaNs for these columns\n",
        "                for c in existing_cols:\n",
        "                    df[c] = df[c].fillna(0)\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_lag_features(df):\n",
        "        df = df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2015, 2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_cohort_features(df):\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup_dict = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup_dict).fillna(-1)\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 4: Model Engine (Conditional Ensemble)\n",
        "# =============================================================================\n",
        "\n",
        "class EnrollmentModelEngine:\n",
        "    \"\"\"\n",
        "    Manages Training, Conditional Selection, and Recursive Forecasting.\n",
        "    Implements logic: Use Best Model ONLY unless others are within 60% performance.\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.models = {}\n",
        "        self.encoders = {}\n",
        "\n",
        "        # --- FULL FEATURE LIST AS REQUESTED ---\n",
        "        self.features = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_REENTRY', 'TOTAL_DISABLED',\n",
        "            'TOTAL_COMPUTERS', 'ELEC_GRID_PCT', 'TOTAL_LABS',\n",
        "            'TRUANCY', 'PREGNANCY', 'INDISCIPLINE',\n",
        "            'LAG_1', 'LAG_2', 'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "\n",
        "        # Filter features to ensure they exist in DF (safety check)\n",
        "        self.features = [f for f in self.features if f in df.columns]\n",
        "        self.selected_model_keys = []\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.encoders['REG'] = LabelEncoder()\n",
        "        self.encoders['COU'] = LabelEncoder()\n",
        "        self.encoders['SUB'] = LabelEncoder()\n",
        "\n",
        "        self.df['REGION_ENC'] = self.encoders['REG'].fit_transform(self.df['REGION'].astype(str))\n",
        "        self.df['COUNCIL_ENC'] = self.encoders['COU'].fit_transform(self.df['COUNCIL'].astype(str))\n",
        "        self.df['SUBJECT_ENC'] = self.encoders['SUB'].fit_transform(self.df['SUBJECT'].astype(str))\n",
        "\n",
        "    def train_all_models(self, cutoff_year=2023):\n",
        "        print(f\"\\nTraining all candidate models on Data <= {cutoff_year}...\")\n",
        "        train_df = self.df[self.df['YEAR'] <= cutoff_year]\n",
        "        X = train_df[self.features]\n",
        "        y = train_df['ENROLLMENT']\n",
        "\n",
        "        # 1. XGBoost\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['XGB'] = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1)\n",
        "        self.models['XGB'].fit(X, y)\n",
        "\n",
        "        # 2. LightGBM\n",
        "        print(\"Training LightGBM...\")\n",
        "        self.models['LGB'] = lgb.LGBMRegressor(n_estimators=500, num_leaves=50, min_child_samples=10, learning_rate=0.1, verbose=-1)\n",
        "        self.models['LGB'].fit(X, y)\n",
        "\n",
        "        # 3. Random Forest\n",
        "        print(\"Training Random Forest...\")\n",
        "        #self.models['RF'] = RandomForestRegressor(n_estimators=300, max_depth=12, n_jobs=-1, random_state=42)\n",
        "        #self.models['RF'].fit(X, y)\n",
        "\n",
        "        # 4. HistGradientBoosting\n",
        "        print(\"Training HistGradientBoosting...\")\n",
        "        #self.models['HGB'] = HistGradientBoostingRegressor(max_iter=500, learning_rate=0.1, max_depth=10)\n",
        "        #self.models['HGB'].fit(X, y)\n",
        "\n",
        "        # 5. GradientBoosting\n",
        "        print(\"Training GradientBoosting...\")\n",
        "        #self.models['GB'] = GradientBoostingRegressor(n_estimators=300, max_depth=9, learning_rate=0.05)\n",
        "        #self.models['GB'].fit(X, y)\n",
        "\n",
        "        print(\"All models trained successfully.\")\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        # --- IMPROVED METRIC: WMAPE (Weighted Mean Absolute Percentage Error) ---\n",
        "        # Standard MAPE explodes with zero/small values. WMAPE is sum(abs_error)/sum(actual).\n",
        "        total_actual = np.sum(y_true)\n",
        "        if total_actual > 0:\n",
        "            wmape = np.sum(np.abs(y_true - y_pred)) / total_actual * 100\n",
        "            accuracy = 100 - wmape\n",
        "        else:\n",
        "            wmape = np.nan\n",
        "            accuracy = 0.0\n",
        "\n",
        "        print(f\"--- {model_name} Results ---\")\n",
        "        print(f\"   > {model_name}: R2={r2:.4f}, MAE={mae:,.2f}, RMSE={rmse:,.2f}, WMAPE={wmape:.2f}%, Acc={accuracy:.2f}%\")\n",
        "        print(\"-\" * 30)\n",
        "        return rmse\n",
        "\n",
        "    def evaluate_and_select_strategy(self, test_year_start=2024):\n",
        "        test_df = self.df[self.df['YEAR'] >= test_year_start]\n",
        "        if test_df.empty:\n",
        "            print(\"No test data available. Defaulting to XGB only.\")\n",
        "            self.selected_model_keys = ['XGB']\n",
        "            return\n",
        "\n",
        "        X_test = test_df[self.features]\n",
        "        y_true = test_df['ENROLLMENT']\n",
        "\n",
        "        performance = {}\n",
        "        print(f\"\\n--- Evaluation Results (Test Data {test_year_start}+) ---\")\n",
        "\n",
        "        print(\"Evaluating all models...\")\n",
        "        for name, model in self.models.items():\n",
        "            preds = model.predict(X_test)\n",
        "            rmse = self.calculate_metrics(y_true, preds, name)\n",
        "            performance[name] = rmse\n",
        "            # Redundant print removed to keep output clean\n",
        "\n",
        "        best_model_name = min(performance, key=performance.get)\n",
        "        best_rmse = performance[best_model_name]\n",
        "        print(f\"\\nBEST MODEL: {best_model_name} (RMSE: {best_rmse:,.2f})\")\n",
        "\n",
        "        # Threshold: Best RMSE + 60% of Best RMSE\n",
        "        threshold = best_rmse * 1.6\n",
        "        candidates = [name for name, score in performance.items() if score <= threshold]\n",
        "\n",
        "        print(f\"Selection Threshold (RMSE <= {threshold:,.2f})\")\n",
        "        print(f\"Qualifying Models: {candidates}\")\n",
        "\n",
        "        if len(candidates) > 1:\n",
        "            self.selected_model_keys = candidates\n",
        "            print(f\"Strategy: ENSEMBLE (Average of {', '.join(candidates)})\")\n",
        "        else:\n",
        "            self.selected_model_keys = [best_model_name]\n",
        "            print(f\"Strategy: SINGLE BEST MODEL ({best_model_name})\")\n",
        "\n",
        "    def _predict(self, X):\n",
        "        preds = []\n",
        "        for key in self.selected_model_keys:\n",
        "            preds.append(self.models[key].predict(X))\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    def recursive_forecast(self, start_year, end_year):\n",
        "        print(f\"\\nStarting Recursive Forecast ({start_year}-{end_year}) using {self.selected_model_keys}...\")\n",
        "        future_data = []\n",
        "        current_data = self.df[self.df['YEAR'] == (start_year - 1)].copy()\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            next_df = self._prepare_next_step(current_data, year)\n",
        "\n",
        "            X_future = next_df[self.features]\n",
        "            preds = self._predict(X_future)\n",
        "\n",
        "            next_df['ENROLLMENT'] = np.maximum(0, preds)\n",
        "\n",
        "            future_data.append(next_df)\n",
        "            current_data = next_df.copy()\n",
        "            print(f\" > Forecasted {year}\")\n",
        "\n",
        "        return pd.concat(future_data, ignore_index=True)\n",
        "\n",
        "    def _prepare_next_step(self, prev_df, target_year):\n",
        "        # By copying prev_df, we \"forward fill\" all infrastructure/demographic columns\n",
        "        # (REENTRY, DISABLED, TRUANCY, PREGNANCY, INDISCIPLINE etc.) from the previous year.\n",
        "        next_df = prev_df.copy()\n",
        "        next_df['YEAR'] = target_year\n",
        "\n",
        "        # Shift Time Series Lags\n",
        "        next_df['LAG_2'] = next_df['LAG_1']\n",
        "        next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "\n",
        "        # Update Growth\n",
        "        next_df['YOY_GROWTH'] = (next_df['LAG_1'] - next_df['LAG_2']) / (next_df['LAG_2'] + 1e-5)\n",
        "\n",
        "        # Update Cohort Logic\n",
        "        cohort_lookup = prev_df.set_index(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort(row):\n",
        "            target_form = row['FORM_NUM'] - 1\n",
        "            if target_form < 1: return -1\n",
        "            key = (row['REGION'], row['COUNCIL'], row['SUBJECT'], target_form)\n",
        "            return cohort_lookup.get(key, -1)\n",
        "\n",
        "        next_df['COHORT_LAG'] = next_df.apply(get_cohort, axis=1)\n",
        "        next_df['IS_ELECTION_YEAR'] = 1 if target_year in [2025, 2030] else 0\n",
        "\n",
        "        return next_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # 1. Configuration\n",
        "    BASE_DIR = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEO_FILE = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'Teacher', 'COBET', 'Vocational']\n",
        "\n",
        "    # 2. Load Data\n",
        "    loader = MOESTDataLoader(BASE_DIR, EXCLUDE_KEYWORDS)\n",
        "    loader.mount_drive()\n",
        "    loader.load_data()\n",
        "    all_dfs = loader.get_all_dataframes()\n",
        "\n",
        "    # 3. Location & Clean Up\n",
        "    loc_manager = LocationManager(all_dfs, GEO_FILE)\n",
        "    loc_manager.standardize_location_columns()\n",
        "    loc_manager.merge_lga_status()\n",
        "\n",
        "    # 4. Feature Engineering\n",
        "    print(\"\\n--- Starting Feature Engineering ---\")\n",
        "\n",
        "    # Retrieve all required DataFrames\n",
        "    df_subject = all_dfs.get(\"Secondary_students_per_subject\")\n",
        "    df_tables = all_dfs.get(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "    df_labs = all_dfs.get(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "    df_dropout = all_dfs.get(\"Dropout-Secondary  2017-2024\")\n",
        "    df_reentry = all_dfs.get(\"Secondary-Re_entry\")\n",
        "    df_disability = all_dfs.get(\"Secondary - DISABALITY 2020-2025\")\n",
        "    df_ict = all_dfs.get(\"Combined_Secondary_ICT_All_G_NG\")\n",
        "    df_elec = all_dfs.get(\"Combined_Secondary_Electricity_All_G_NG\")\n",
        "\n",
        "    if df_subject is None:\n",
        "        raise ValueError(\"Critical DataFrame 'Secondary_students_per_subject' not found.\")\n",
        "\n",
        "    aux_dfs = {\n",
        "        'tables': df_tables,\n",
        "        'labs': df_labs,\n",
        "        'dropout': df_dropout,\n",
        "        'reentry': df_reentry,\n",
        "        'disability': df_disability,\n",
        "        'ict': df_ict,\n",
        "        'electricity': df_elec\n",
        "    }\n",
        "\n",
        "    engineer = FeatureEngineer()\n",
        "    long_df = engineer.melt_subjects(df_subject)\n",
        "    # Merge all auxiliary data\n",
        "    merged_df = engineer.merge_infrastructure(long_df, aux_dfs)\n",
        "    lagged_df = engineer.create_lag_features(merged_df)\n",
        "    final_df = engineer.create_cohort_features(lagged_df)\n",
        "\n",
        "    # 5. Modeling & Forecasting (Updated Strategy)\n",
        "    print(\"\\n--- Starting Model Engine ---\")\n",
        "    engine = EnrollmentModelEngine(final_df)\n",
        "    engine.preprocess()\n",
        "\n",
        "    # Train\n",
        "    engine.train_all_models(cutoff_year=2023)\n",
        "\n",
        "    # Evaluate & Select Strategy\n",
        "    engine.evaluate_and_select_strategy(test_year_start=2024)\n",
        "\n",
        "    # 6. Generate Forecast\n",
        "    forecast_df = engine.recursive_forecast(2026, 2030)\n",
        "\n",
        "    # 7. Output\n",
        "    print(\"\\n--- Final Forecast Sample ---\")\n",
        "    output_cols = ['YEAR', 'REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'ENROLLMENT']\n",
        "    final_view = forecast_df[output_cols].copy()\n",
        "    final_view['ENROLLMENT'] = final_view['ENROLLMENT'].round(0).astype(int)\n",
        "    print(final_view.head(10))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Refactored MoEST Modeling for Secondary School Enrollment\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    GradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 1: Data Loader & Cleaner\n",
        "# =============================================================================\n",
        "\n",
        "class MOESTDataLoader:\n",
        "    \"\"\"\n",
        "    Handles mounting drive, loading CSVs, cleaning headers, handling types,\n",
        "    and managing initial data quality checks.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_directory, exclude_keywords=None):\n",
        "        self.base_directory = base_directory\n",
        "        self.exclude_keywords = exclude_keywords if exclude_keywords else []\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def mount_drive(self):\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "    def get_file_list(self):\n",
        "        all_files = [f for f in os.listdir(self.base_directory) if f.endswith('.csv')]\n",
        "        filtered_files = []\n",
        "        for file_name in all_files:\n",
        "            if not any(keyword.lower() in file_name.lower() for keyword in self.exclude_keywords):\n",
        "                filtered_files.append(file_name)\n",
        "        return filtered_files\n",
        "\n",
        "    def load_data(self):\n",
        "        files = self.get_file_list()\n",
        "        print(f\"Found {len(files)} files to load.\")\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(self.base_directory, file_name)\n",
        "            df_name = file_name.replace('.csv', '')\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                self.dataframes[df_name] = self._initial_clean(df)\n",
        "                print(f\"Loaded: {df_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    def _initial_clean(self, df):\n",
        "        \"\"\"Standardizes headers and cleans numeric columns.\"\"\"\n",
        "        df.columns = [str(col).strip().upper() for col in df.columns]\n",
        "\n",
        "        for col in df.select_dtypes(include='object').columns:\n",
        "            if df[col].astype(str).str.contains(',').any():\n",
        "                cleaned = df[col].astype(str).str.replace(',', '', regex=False)\n",
        "                converted = pd.to_numeric(cleaned, errors='coerce')\n",
        "                if converted.notna().sum() > 0:\n",
        "                    df[col] = converted\n",
        "\n",
        "        unnamed = [c for c in df.columns if 'UNNAMED' in c]\n",
        "        to_drop = [c for c in unnamed if df[c].isnull().mean() > 0.9]\n",
        "        df.drop(columns=to_drop, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "    def get_all_dataframes(self):\n",
        "        return self.dataframes\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 2: Geography & Location Manager\n",
        "# =============================================================================\n",
        "\n",
        "class LocationManager:\n",
        "    \"\"\"\n",
        "    Handles Geocoding, LGA Status merging, and Clustering.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframes, geodata_path):\n",
        "        self.dataframes = dataframes\n",
        "        self.geodata_path = geodata_path\n",
        "        self.geo_data = None\n",
        "        self.lga_status_df = None\n",
        "\n",
        "    def standardize_location_columns(self):\n",
        "        for name, df in self.dataframes.items():\n",
        "            reg_col = next((c for c in df.columns if c in ['REGION', 'REGON']), None)\n",
        "            cou_col = next((c for c in df.columns if c in ['COUNCIL', 'DISTRICT', 'LGA NAME']), None)\n",
        "\n",
        "            if reg_col and cou_col:\n",
        "                df.rename(columns={reg_col: 'REGION', cou_col: 'COUNCIL'}, inplace=True)\n",
        "                df['REGION'] = df['REGION'].astype(str).str.upper()\n",
        "                df['COUNCIL'] = df['COUNCIL'].astype(str).str.upper()\n",
        "\n",
        "    def merge_lga_status(self, lga_df_name='LGAs Urban and Rural Status'):\n",
        "        if lga_df_name not in self.dataframes:\n",
        "            print(\"LGA Status DataFrame not found.\")\n",
        "            return\n",
        "\n",
        "        self.lga_status_df = self.dataframes[lga_df_name].copy()\n",
        "        if 'REMARKS' in self.lga_status_df.columns:\n",
        "            self.lga_status_df.drop(columns=['REMARKS'], inplace=True)\n",
        "        self.lga_status_df.rename(columns={'CLASSIFICATION': 'LGA_STATUS'}, inplace=True)\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if name == lga_df_name: continue\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.lga_status_df, on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged LGA Status into {name}\")\n",
        "        del self.dataframes[lga_df_name]\n",
        "\n",
        "    def process_geocoding(self):\n",
        "        if os.path.exists(self.geodata_path):\n",
        "            print(\"Loading existing geodata...\")\n",
        "            self.geo_data = pd.read_csv(self.geodata_path)\n",
        "        else:\n",
        "            print(\"Generating new geodata...\")\n",
        "            self._fetch_geodata()\n",
        "\n",
        "        self._apply_clustering()\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.geo_data[['REGION', 'COUNCIL', 'GEO_CLUSTER']],\n",
        "                                  on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged Geo Cluster into {name}\")\n",
        "\n",
        "    def _fetch_geodata(self):\n",
        "        locs = []\n",
        "        for df in self.dataframes.values():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                locs.append(df[['REGION', 'COUNCIL']])\n",
        "        unique_locs = pd.concat(locs).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        geolocator = Nominatim(user_agent=\"moest_geo_mapper_v3\")\n",
        "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1.0)\n",
        "\n",
        "        lats, lons = [], []\n",
        "        for idx, row in unique_locs.iterrows():\n",
        "            query = f\"{row['COUNCIL']}, {row['REGION']}, Tanzania\"\n",
        "            try:\n",
        "                loc = geocode(query)\n",
        "                if loc:\n",
        "                    lats.append(loc.latitude)\n",
        "                    lons.append(loc.longitude)\n",
        "                else:\n",
        "                    lats.append(None)\n",
        "                    lons.append(None)\n",
        "            except:\n",
        "                lats.append(None)\n",
        "                lons.append(None)\n",
        "\n",
        "        unique_locs['LATITUDE'] = lats\n",
        "        unique_locs['LONGITUDE'] = lons\n",
        "        self.geo_data = unique_locs.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "        self.geo_data.to_csv(self.geodata_path, index=False)\n",
        "\n",
        "    def _apply_clustering(self):\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        self.geo_data['GEO_CLUSTER'] = kmeans.fit_predict(self.geo_data[['LATITUDE', 'LONGITUDE']])\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 3: Feature Engineer\n",
        "# =============================================================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"\n",
        "    Handles specific transformation logic for Secondary School Subjects.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def melt_subjects(df):\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in df.columns]\n",
        "        subject_cols = [c for c in df.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        print(f\"Melting {len(subject_cols)} subject columns...\")\n",
        "        long_df = df.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "        return long_df\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_infrastructure(main_df, auxiliary_dfs):\n",
        "        \"\"\"\n",
        "        Merges Tables, Labs, ICT, Electricity, Dropout, Reentry, Disability.\n",
        "        \"\"\"\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "        df = main_df.copy()\n",
        "\n",
        "        # 1. Tables\n",
        "        tables = auxiliary_dfs.get('tables')\n",
        "        if tables is not None and 'AVAILABLE_TABLES' in tables.columns:\n",
        "            df = df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna({'AVAILABLE_TABLES': 0})\n",
        "\n",
        "        # 2. Labs (Total)\n",
        "        labs = auxiliary_dfs.get('labs')\n",
        "        if labs is not None:\n",
        "            lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "            if lab_cols:\n",
        "                labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "                df = df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna({'TOTAL_LABS': 0})\n",
        "\n",
        "        # 3. ICT (Computers)\n",
        "        ict = auxiliary_dfs.get('ict')\n",
        "        if ict is not None:\n",
        "             comp_cols = [c for c in ict.columns if 'COMPUTER' in c]\n",
        "             if comp_cols:\n",
        "                 ict['TOTAL_COMPUTERS'] = ict[comp_cols].sum(axis=1)\n",
        "                 df = df.merge(ict[keys + ['TOTAL_COMPUTERS']], on=keys, how='left').fillna({'TOTAL_COMPUTERS': 0})\n",
        "\n",
        "        # 4. Electricity\n",
        "        elec = auxiliary_dfs.get('electricity')\n",
        "        if elec is not None:\n",
        "            grid_col = next((c for c in elec.columns if 'TANESCO' in c or 'GRID' in c), None)\n",
        "            if grid_col:\n",
        "                df = df.merge(elec[keys + [grid_col]], on=keys, how='left').fillna({grid_col: 0})\n",
        "                df.rename(columns={grid_col: 'ELEC_GRID_PCT'}, inplace=True)\n",
        "\n",
        "        # 5. Re-entry\n",
        "        reentry = auxiliary_dfs.get('reentry')\n",
        "        if reentry is not None:\n",
        "            re_cols = [c for c in reentry.columns if 'RE-ENROLLED' in c]\n",
        "            if re_cols:\n",
        "                reentry['TOTAL_REENTRY'] = reentry[re_cols].sum(axis=1)\n",
        "                df = df.merge(reentry[keys + ['TOTAL_REENTRY']], on=keys, how='left').fillna({'TOTAL_REENTRY': 0})\n",
        "\n",
        "        # 6. Disability\n",
        "        disability = auxiliary_dfs.get('disability')\n",
        "        if disability is not None:\n",
        "            dis_cols = [c for c in disability.columns if c not in keys + ['Unnamed: 0']]\n",
        "            dis_cols = [c for c in dis_cols if pd.api.types.is_numeric_dtype(disability[c])]\n",
        "            if dis_cols:\n",
        "                disability['TOTAL_DISABLED'] = disability[dis_cols].sum(axis=1)\n",
        "                df = df.merge(disability[keys + ['TOTAL_DISABLED']], on=keys, how='left').fillna({'TOTAL_DISABLED': 0})\n",
        "\n",
        "        # 7. Dropout (Specific Columns: Truancy, Pregnancy, Indiscipline)\n",
        "        dropout = auxiliary_dfs.get('dropout')\n",
        "        if dropout is not None:\n",
        "            # Check for specific columns\n",
        "            target_cols = ['TRUANCY', 'PREGNANCY', 'INDISCIPLINE']\n",
        "            existing_cols = [c for c in target_cols if c in dropout.columns]\n",
        "\n",
        "            if existing_cols:\n",
        "                df = df.merge(dropout[keys + existing_cols], on=keys, how='left')\n",
        "                # Fill NaNs for these columns\n",
        "                for c in existing_cols:\n",
        "                    df[c] = df[c].fillna(0)\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_lag_features(df):\n",
        "        df = df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2015, 2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_cohort_features(df):\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup_dict = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup_dict).fillna(-1)\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 4: Model Engine (Conditional Ensemble)\n",
        "# =============================================================================\n",
        "\n",
        "class EnrollmentModelEngine:\n",
        "    \"\"\"\n",
        "    Manages Training, Conditional Selection, and Recursive Forecasting.\n",
        "    Implements logic: Use Best Model ONLY unless others are within 60% performance.\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.models = {}\n",
        "        self.encoders = {}\n",
        "\n",
        "        # --- FULL FEATURE LIST AS REQUESTED ---\n",
        "        self.features = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_REENTRY', 'TOTAL_DISABLED',\n",
        "            'TOTAL_COMPUTERS', 'ELEC_GRID_PCT', 'TOTAL_LABS',\n",
        "            'TRUANCY', 'PREGNANCY', 'INDISCIPLINE',\n",
        "            'LAG_1', 'LAG_2', 'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "\n",
        "        # Filter features to ensure they exist in DF (safety check)\n",
        "        self.features = [f for f in self.features if f in df.columns]\n",
        "        self.selected_model_keys = []\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.encoders['REG'] = LabelEncoder()\n",
        "        self.encoders['COU'] = LabelEncoder()\n",
        "        self.encoders['SUB'] = LabelEncoder()\n",
        "\n",
        "        self.df['REGION_ENC'] = self.encoders['REG'].fit_transform(self.df['REGION'].astype(str))\n",
        "        self.df['COUNCIL_ENC'] = self.encoders['COU'].fit_transform(self.df['COUNCIL'].astype(str))\n",
        "        self.df['SUBJECT_ENC'] = self.encoders['SUB'].fit_transform(self.df['SUBJECT'].astype(str))\n",
        "\n",
        "    def train_all_models(self, cutoff_year=2023):\n",
        "        print(f\"\\nTraining all candidate models on Data <= {cutoff_year}...\")\n",
        "        train_df = self.df[self.df['YEAR'] <= cutoff_year]\n",
        "        X = train_df[self.features]\n",
        "        y = train_df['ENROLLMENT']\n",
        "\n",
        "        # 1. XGBoost\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['XGB'] = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1)\n",
        "        self.models['XGB'].fit(X, y)\n",
        "\n",
        "        # 2. LightGBM\n",
        "        print(\"Training LightGBM...\")\n",
        "        self.models['LGB'] = lgb.LGBMRegressor(n_estimators=500, num_leaves=50, min_child_samples=10, learning_rate=0.1, verbose=-1)\n",
        "        self.models['LGB'].fit(X, y)\n",
        "\n",
        "        # 3. Random Forest\n",
        "        print(\"Training Random Forest...\")\n",
        "        self.models['RF'] = RandomForestRegressor(n_estimators=300, max_depth=12, n_jobs=-1, random_state=42)\n",
        "        self.models['RF'].fit(X, y)\n",
        "\n",
        "        # 4. HistGradientBoosting\n",
        "        print(\"Training HistGradientBoosting...\")\n",
        "        self.models['HGB'] = HistGradientBoostingRegressor(max_iter=500, learning_rate=0.1, max_depth=10)\n",
        "        self.models['HGB'].fit(X, y)\n",
        "\n",
        "        # 5. GradientBoosting\n",
        "        print(\"Training GradientBoosting...\")\n",
        "        self.models['GB'] = GradientBoostingRegressor(n_estimators=300, max_depth=9, learning_rate=0.05)\n",
        "        self.models['GB'].fit(X, y)\n",
        "\n",
        "        print(\"All models trained successfully.\")\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        # --- IMPROVED METRIC: WMAPE (Weighted Mean Absolute Percentage Error) ---\n",
        "        # Standard MAPE explodes with zero/small values. WMAPE is sum(abs_error)/sum(actual).\n",
        "        total_actual = np.sum(y_true)\n",
        "        if total_actual > 0:\n",
        "            wmape = np.sum(np.abs(y_true - y_pred)) / total_actual * 100\n",
        "            accuracy = 100 - wmape\n",
        "        else:\n",
        "            wmape = np.nan\n",
        "            accuracy = 0.0\n",
        "\n",
        "        print(f\"--- {model_name} Results ---\")\n",
        "        print(f\"   > {model_name}: R2={r2:.4f}, MAE={mae:,.2f}, RMSE={rmse:,.2f}, WMAPE={wmape:.2f}%, Acc={accuracy:.2f}%\")\n",
        "        print(\"-\" * 30)\n",
        "        return rmse\n",
        "\n",
        "    def evaluate_and_select_strategy(self, test_year_start=2024):\n",
        "        test_df = self.df[self.df['YEAR'] >= test_year_start]\n",
        "        if test_df.empty:\n",
        "            print(\"No test data available. Defaulting to XGB only.\")\n",
        "            self.selected_model_keys = ['XGB']\n",
        "            return\n",
        "\n",
        "        X_test = test_df[self.features]\n",
        "        y_true = test_df['ENROLLMENT']\n",
        "\n",
        "        performance = {}\n",
        "        print(f\"\\n--- Evaluation Results (Test Data {test_year_start}+) ---\")\n",
        "\n",
        "        print(\"Evaluating all models...\")\n",
        "        for name, model in self.models.items():\n",
        "            preds = model.predict(X_test)\n",
        "            rmse = self.calculate_metrics(y_true, preds, name)\n",
        "            performance[name] = rmse\n",
        "            # Redundant print removed to keep output clean\n",
        "\n",
        "        best_model_name = min(performance, key=performance.get)\n",
        "        best_rmse = performance[best_model_name]\n",
        "        print(f\"\\nBEST MODEL: {best_model_name} (RMSE: {best_rmse:,.2f})\")\n",
        "\n",
        "        # Threshold: Best RMSE + 60% of Best RMSE\n",
        "        threshold = best_rmse * 1.6\n",
        "        candidates = [name for name, score in performance.items() if score <= threshold]\n",
        "\n",
        "        print(f\"Selection Threshold (RMSE <= {threshold:,.2f})\")\n",
        "        print(f\"Qualifying Models: {candidates}\")\n",
        "\n",
        "        if len(candidates) > 1:\n",
        "            self.selected_model_keys = candidates\n",
        "            print(f\"Strategy: ENSEMBLE (Average of {', '.join(candidates)})\")\n",
        "        else:\n",
        "            self.selected_model_keys = [best_model_name]\n",
        "            print(f\"Strategy: SINGLE BEST MODEL ({best_model_name})\")\n",
        "\n",
        "    def _predict(self, X):\n",
        "        preds = []\n",
        "        for key in self.selected_model_keys:\n",
        "            preds.append(self.models[key].predict(X))\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    def recursive_forecast(self, start_year, end_year):\n",
        "        print(f\"\\nStarting Recursive Forecast ({start_year}-{end_year}) using {self.selected_model_keys}...\")\n",
        "        future_data = []\n",
        "        current_data = self.df[self.df['YEAR'] == (start_year - 1)].copy()\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            next_df = self._prepare_next_step(current_data, year)\n",
        "\n",
        "            X_future = next_df[self.features]\n",
        "            preds = self._predict(X_future)\n",
        "\n",
        "            next_df['ENROLLMENT'] = np.maximum(0, preds)\n",
        "\n",
        "            future_data.append(next_df)\n",
        "            current_data = next_df.copy()\n",
        "            print(f\" > Forecasted {year}\")\n",
        "\n",
        "        return pd.concat(future_data, ignore_index=True)\n",
        "\n",
        "    def _prepare_next_step(self, prev_df, target_year):\n",
        "        # By copying prev_df, we \"forward fill\" all infrastructure/demographic columns\n",
        "        # (REENTRY, DISABLED, TRUANCY, PREGNANCY, INDISCIPLINE etc.) from the previous year.\n",
        "        next_df = prev_df.copy()\n",
        "        next_df['YEAR'] = target_year\n",
        "\n",
        "        # Shift Time Series Lags\n",
        "        next_df['LAG_2'] = next_df['LAG_1']\n",
        "        next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "\n",
        "        # Update Growth\n",
        "        next_df['YOY_GROWTH'] = (next_df['LAG_1'] - next_df['LAG_2']) / (next_df['LAG_2'] + 1e-5)\n",
        "\n",
        "        # Update Cohort Logic\n",
        "        cohort_lookup = prev_df.set_index(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort(row):\n",
        "            target_form = row['FORM_NUM'] - 1\n",
        "            if target_form < 1: return -1\n",
        "            key = (row['REGION'], row['COUNCIL'], row['SUBJECT'], target_form)\n",
        "            return cohort_lookup.get(key, -1)\n",
        "\n",
        "        next_df['COHORT_LAG'] = next_df.apply(get_cohort, axis=1)\n",
        "        next_df['IS_ELECTION_YEAR'] = 1 if target_year in [2025, 2030] else 0\n",
        "\n",
        "        return next_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # 1. Configuration\n",
        "    BASE_DIR = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEO_FILE = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'Teacher', 'COBET', 'Vocational']\n",
        "\n",
        "    # 2. Load Data\n",
        "    loader = MOESTDataLoader(BASE_DIR, EXCLUDE_KEYWORDS)\n",
        "    loader.mount_drive()\n",
        "    loader.load_data()\n",
        "    all_dfs = loader.get_all_dataframes()\n",
        "\n",
        "    # 3. Location & Clean Up\n",
        "    loc_manager = LocationManager(all_dfs, GEO_FILE)\n",
        "    loc_manager.standardize_location_columns()\n",
        "    loc_manager.merge_lga_status()\n",
        "\n",
        "    # 4. Feature Engineering\n",
        "    print(\"\\n--- Starting Feature Engineering ---\")\n",
        "\n",
        "    # Retrieve all required DataFrames\n",
        "    df_subject = all_dfs.get(\"Secondary_students_per_subject\")\n",
        "    df_tables = all_dfs.get(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "    df_labs = all_dfs.get(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "    df_dropout = all_dfs.get(\"Dropout-Secondary  2017-2024\")\n",
        "    df_reentry = all_dfs.get(\"Secondary-Re_entry\")\n",
        "    df_disability = all_dfs.get(\"Secondary - DISABALITY 2020-2025\")\n",
        "    df_ict = all_dfs.get(\"Combined_Secondary_ICT_All_G_NG\")\n",
        "    df_elec = all_dfs.get(\"Combined_Secondary_Electricity_All_G_NG\")\n",
        "\n",
        "    if df_subject is None:\n",
        "        raise ValueError(\"Critical DataFrame 'Secondary_students_per_subject' not found.\")\n",
        "\n",
        "    aux_dfs = {\n",
        "        'tables': df_tables,\n",
        "        'labs': df_labs,\n",
        "        'dropout': df_dropout,\n",
        "        'reentry': df_reentry,\n",
        "        'disability': df_disability,\n",
        "        'ict': df_ict,\n",
        "        'electricity': df_elec\n",
        "    }\n",
        "\n",
        "    engineer = FeatureEngineer()\n",
        "    long_df = engineer.melt_subjects(df_subject)\n",
        "    # Merge all auxiliary data\n",
        "    merged_df = engineer.merge_infrastructure(long_df, aux_dfs)\n",
        "    lagged_df = engineer.create_lag_features(merged_df)\n",
        "    final_df = engineer.create_cohort_features(lagged_df)\n",
        "\n",
        "    # 5. Modeling & Forecasting (Updated Strategy)\n",
        "    print(\"\\n--- Starting Model Engine ---\")\n",
        "    engine = EnrollmentModelEngine(final_df)\n",
        "    engine.preprocess()\n",
        "\n",
        "    # Train\n",
        "    engine.train_all_models(cutoff_year=2023)\n",
        "\n",
        "    # Evaluate & Select Strategy\n",
        "    engine.evaluate_and_select_strategy(test_year_start=2024)\n",
        "\n",
        "    # 6. Generate Forecast\n",
        "    forecast_df = engine.recursive_forecast(2026, 2030)\n",
        "\n",
        "    # 7. Output\n",
        "    print(\"\\n--- Final Forecast Sample ---\")\n",
        "    output_cols = ['YEAR', 'REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'ENROLLMENT']\n",
        "    final_view = forecast_df[output_cols].copy()\n",
        "    final_view['ENROLLMENT'] = final_view['ENROLLMENT'].round(0).astype(int)\n",
        "    print(final_view.head(10))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBfsZgFjdWIS",
        "outputId": "6561caf9-50f4-4fa5-9ae6-2b646a23e62e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Found 15 files to load.\n",
            "Loaded: Data-Secondary Enrollment 2016-2025\n",
            "Loaded: Dropout-Secondary  2017-2024\n",
            "Loaded: Data-Secondary Tables and chairs 2016-2025\n",
            "Loaded: Secondary-Re_entry\n",
            "Loaded: Secondary - DISABALITY 2020-2025\n",
            "Loaded: LGAs Urban and Rural Status\n",
            "Loaded: Combined_Secondary_Laboratories_Govt\n",
            "Loaded: Combined_Secondary_Laboratories_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_Govt\n",
            "Loaded: Combined_Secondary_Electricity_All_G_NG\n",
            "Loaded: Combined_Secondary_Electricity_Govt\n",
            "Loaded: Secondary_students_per_subject\n",
            "Loaded: Secondary_enrollment_Gov_2016_2025\n",
            "Loaded: Data-Secondary Enrollment 2016-2025 (1)\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025\n",
            "Merged LGA Status into Dropout-Secondary  2017-2024\n",
            "Merged LGA Status into Data-Secondary Tables and chairs 2016-2025\n",
            "Merged LGA Status into Secondary-Re_entry\n",
            "Merged LGA Status into Secondary - DISABALITY 2020-2025\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_Govt\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_Govt\n",
            "Merged LGA Status into Combined_Secondary_Electricity_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_Electricity_Govt\n",
            "Merged LGA Status into Secondary_students_per_subject\n",
            "Merged LGA Status into Secondary_enrollment_Gov_2016_2025\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025 (1)\n",
            "\n",
            "--- Starting Feature Engineering ---\n",
            "Melting 391 subject columns...\n",
            "\n",
            "--- Starting Model Engine ---\n",
            "\n",
            "Training all candidate models on Data <= 2023...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Training Random Forest...\n",
            "Training HistGradientBoosting...\n",
            "Training GradientBoosting...\n",
            "All models trained successfully.\n",
            "\n",
            "--- Evaluation Results (Test Data 2024+) ---\n",
            "Evaluating all models...\n",
            "--- XGB Results ---\n",
            "   > XGB: R2=0.9213, MAE=60.92, RMSE=422.94, WMAPE=15.84%, Acc=84.16%\n",
            "------------------------------\n",
            "--- LGB Results ---\n",
            "   > LGB: R2=0.9286, MAE=59.28, RMSE=402.62, WMAPE=15.41%, Acc=84.59%\n",
            "------------------------------\n",
            "--- RF Results ---\n",
            "   > RF: R2=0.9266, MAE=62.01, RMSE=408.42, WMAPE=16.12%, Acc=83.88%\n",
            "------------------------------\n",
            "--- HGB Results ---\n",
            "   > HGB: R2=0.9059, MAE=87.42, RMSE=462.31, WMAPE=22.72%, Acc=77.28%\n",
            "------------------------------\n",
            "--- GB Results ---\n",
            "   > GB: R2=0.9292, MAE=56.79, RMSE=401.10, WMAPE=14.76%, Acc=85.24%\n",
            "------------------------------\n",
            "\n",
            "BEST MODEL: GB (RMSE: 401.10)\n",
            "Selection Threshold (RMSE <= 641.77)\n",
            "Qualifying Models: ['XGB', 'LGB', 'RF', 'HGB', 'GB']\n",
            "Strategy: ENSEMBLE (Average of XGB, LGB, RF, HGB, GB)\n",
            "\n",
            "Starting Recursive Forecast (2026-2030) using ['XGB', 'LGB', 'RF', 'HGB', 'GB']...\n",
            " > Forecasted 2026\n",
            " > Forecasted 2027\n",
            " > Forecasted 2028\n",
            " > Forecasted 2029\n",
            " > Forecasted 2030\n",
            "\n",
            "--- Final Forecast Sample ---\n",
            "   YEAR  REGION COUNCIL                         SUBJECT  FORM_NUM  ENROLLMENT\n",
            "0  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         1          57\n",
            "1  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         2          15\n",
            "2  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         3          50\n",
            "3  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         4          46\n",
            "4  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          57\n",
            "5  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1          53\n",
            "6  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          15\n",
            "7  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         2          12\n",
            "8  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          49\n",
            "9  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         3          12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Refactored MoEST Modeling for Secondary School Per Subjects\n",
        "Object-Oriented Implementation\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    RandomForestRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "\n",
        "# Note: In a pure script environment, Colab specific commands\n",
        "# like drive.mount or !pip should ideally be external setup steps.\n",
        "# They are included here in comments or wrapped methods to preserve logic.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Holds configuration paths and constants.\"\"\"\n",
        "    BASE_DIRECTORY = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEODATA_FILENAME = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "\n",
        "    # Column mapping constants used throughout the pipeline\n",
        "    EXPECTED_COLS = {\n",
        "        'Year': ['Year', 'YEAR', 'Academic Year'],\n",
        "        'Region': ['Region', 'REGION', 'REGON'],\n",
        "        'Council': ['Council', 'COUNCIL', 'DISTRICT', 'LGA NAME']\n",
        "    }\n",
        "\n",
        "    # Files to exclude during loading\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'COBET', 'Vocational', 'Enrollment']\n",
        "\n",
        "class DataHandler:\n",
        "    \"\"\"Handles loading, initial cleaning, and merging of datasets.\"\"\"\n",
        "\n",
        "    def __init__(self, base_dir):\n",
        "        self.base_dir = base_dir\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Scans directory and loads CSVs not matching exclude keywords.\"\"\"\n",
        "        try:\n",
        "            # Equivalent to !ls in python\n",
        "            all_files_in_dir = os.listdir(self.base_dir)\n",
        "            all_files = [f for f in all_files_in_dir if f.endswith('.csv')]\n",
        "\n",
        "            filtered_files = []\n",
        "            for file_name in all_files:\n",
        "                if not any(keyword.lower() in file_name.lower() for keyword in Config.EXCLUDE_KEYWORDS):\n",
        "                    filtered_files.append(file_name)\n",
        "\n",
        "            print(\"Filtered files:\", filtered_files)\n",
        "\n",
        "            for file_name in filtered_files:\n",
        "                file_path = os.path.join(self.base_dir, file_name)\n",
        "                df_name = file_name.replace('.csv', '')\n",
        "                try:\n",
        "                    self.dataframes[df_name] = pd.read_csv(file_path)\n",
        "                    print(f\"Loaded {df_name} successfully.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {file_name}: {e}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Directory not found: {self.base_dir}\")\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Performs numeric conversion and drops empty columns.\"\"\"\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            print(f\"\\n--- Cleaning DataFrame: {df_name} ---\")\n",
        "\n",
        "            # 1. Convert 'object' columns to numeric\n",
        "            for col in df.select_dtypes(include='object').columns:\n",
        "                if df[col].astype(str).str.contains(',').any() or df[col].astype(str).str.fullmatch(r'\\d+\\.?\\d*').any():\n",
        "                    cleaned_col = df[col].astype(str).str.replace(',', '', regex=False).str.strip()\n",
        "                    converted_col = pd.to_numeric(cleaned_col, errors='coerce')\n",
        "                    if converted_col.notna().sum() > 0 and converted_col.dtype != object:\n",
        "                        df[col] = converted_col\n",
        "                        print(f\"  Converted column '{col}' to numeric type.\")\n",
        "\n",
        "            # 2. Drop predominantly null 'Unnamed' columns\n",
        "            unnamed_cols = [col for col in df.columns if re.match(r'Unnamed: \\d+', str(col))]\n",
        "            cols_to_drop = [col for col in unnamed_cols if (df[col].isnull().sum() / len(df) * 100) > 90]\n",
        "\n",
        "            if cols_to_drop:\n",
        "                df.drop(columns=cols_to_drop, inplace=True)\n",
        "                print(f\"  Dropped columns: {', '.join(cols_to_drop)}\")\n",
        "\n",
        "    def check_discrepancies(self):\n",
        "        \"\"\"Checks for missing core columns or data type mismatches.\"\"\"\n",
        "        all_discrepancies = []\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            discrepancies = []\n",
        "            for conceptual_col, possible_names in Config.EXPECTED_COLS.items():\n",
        "                found_col_name = next((name for name in possible_names if name in df.columns), None)\n",
        "\n",
        "                if found_col_name:\n",
        "                    current_dtype = df[found_col_name].dtype\n",
        "                    null_count = df[found_col_name].isnull().sum()\n",
        "\n",
        "                    if conceptual_col == 'Year' and not pd.api.types.is_numeric_dtype(current_dtype):\n",
        "                        discrepancies.append({'dataframe': df_name, 'column': found_col_name, 'issue': 'Inconsistent Data Type'})\n",
        "                    elif conceptual_col in ['Region', 'Council'] and not pd.api.types.is_object_dtype(current_dtype):\n",
        "                        discrepancies.append({'dataframe': df_name, 'column': found_col_name, 'issue': 'Inconsistent Data Type'})\n",
        "\n",
        "                    if null_count > 0:\n",
        "                        discrepancies.append({'dataframe': df_name, 'column': found_col_name, 'issue': 'Null Values', 'count': null_count})\n",
        "                else:\n",
        "                    discrepancies.append({'dataframe': df_name, 'column': conceptual_col, 'issue': 'Missing Column'})\n",
        "\n",
        "            if discrepancies:\n",
        "                all_discrepancies.extend(discrepancies)\n",
        "\n",
        "        if all_discrepancies:\n",
        "            print(\"--- Discrepancies Found ---\")\n",
        "            for d in all_discrepancies: print(d)\n",
        "        else:\n",
        "            print(\"No discrepancies found for core columns.\")\n",
        "\n",
        "    def merge_lga_status(self):\n",
        "        \"\"\"Merges LGA Status into all other dataframes.\"\"\"\n",
        "        if 'LGAs Urban and Rural Status' not in self.dataframes:\n",
        "            print(\"LGA Status dataframe not found.\")\n",
        "            return\n",
        "\n",
        "        df_lga_status = self.dataframes['LGAs Urban and Rural Status'].copy()\n",
        "        if 'Remarks' in df_lga_status.columns:\n",
        "            df_lga_status.drop(columns=['Remarks'], inplace=True)\n",
        "\n",
        "        df_lga_status.rename(columns={'Region': 'Region', 'Council': 'Council', 'Classification': 'LGA_Status'}, inplace=True)\n",
        "        df_lga_status['Region'] = df_lga_status['Region'].str.upper()\n",
        "        df_lga_status['Council'] = df_lga_status['Council'].str.upper()\n",
        "\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            if df_name == 'LGAs Urban and Rural Status': continue\n",
        "\n",
        "            # Identify columns\n",
        "            actual_region = next((n for n in Config.EXPECTED_COLS['Region'] if n in df.columns), None)\n",
        "            actual_council = next((n for n in Config.EXPECTED_COLS['Council'] if n in df.columns), None)\n",
        "\n",
        "            if actual_region and actual_council:\n",
        "                df[actual_region] = df[actual_region].astype(str).str.upper()\n",
        "                df[actual_council] = df[actual_council].astype(str).str.upper()\n",
        "\n",
        "                try:\n",
        "                    merged_df = pd.merge(df, df_lga_status,\n",
        "                                         left_on=[actual_region, actual_council],\n",
        "                                         right_on=['Region', 'Council'],\n",
        "                                         how='left', suffixes=('', '_LGA'))\n",
        "                    if 'Region_LGA' in merged_df.columns: merged_df.drop(columns=['Region_LGA'], inplace=True)\n",
        "                    if 'Council_LGA' in merged_df.columns: merged_df.drop(columns=['Council_LGA'], inplace=True)\n",
        "\n",
        "                    self.dataframes[df_name] = merged_df\n",
        "                    print(f\"  Merged LGA_Status into {df_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error merging {df_name}: {e}\")\n",
        "\n",
        "        # Cleanup\n",
        "        del self.dataframes['LGAs Urban and Rural Status']\n",
        "        if 'Pre-primary GER NA NER 2017-2025' in self.dataframes:\n",
        "            del self.dataframes['Pre-primary GER NA NER 2017-2025']\n",
        "\n",
        "    def drop_null_locations(self):\n",
        "        \"\"\"Drops rows where Region or Council is null.\"\"\"\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            actual_region = next((n for n in Config.EXPECTED_COLS['Region'] if n in df.columns), None)\n",
        "            actual_council = next((n for n in Config.EXPECTED_COLS['Council'] if n in df.columns), None)\n",
        "\n",
        "            if actual_region and actual_council:\n",
        "                df.dropna(subset=[actual_region, actual_council], inplace=True)\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "\n",
        "class GeoProcessor:\n",
        "    \"\"\"Handles Geocoding and Clustering.\"\"\"\n",
        "\n",
        "    def __init__(self, data_handler):\n",
        "        self.data_handler = data_handler\n",
        "        self.geo_data = None\n",
        "\n",
        "    def process_geodata(self):\n",
        "        \"\"\"Loads or generates geodata, then performs clustering.\"\"\"\n",
        "        if os.path.exists(Config.GEODATA_FILENAME):\n",
        "            print(f\"Loading geodata from {Config.GEODATA_FILENAME}\")\n",
        "            self.geo_data = pd.read_csv(Config.GEODATA_FILENAME)\n",
        "        else:\n",
        "            self._generate_geodata()\n",
        "\n",
        "        self._cluster_geodata()\n",
        "        self._merge_geodata_to_dataframes()\n",
        "\n",
        "    def _generate_geodata(self):\n",
        "        print(\"Generating new Geodata...\")\n",
        "        location_list = []\n",
        "        for df_name, df in self.data_handler.dataframes.items():\n",
        "            region_col = next((col for col in df.columns if col.lower() in ['region', 'regon']), None)\n",
        "            council_col = next((col for col in df.columns if col.lower() in ['council', 'district', 'lga name']), None)\n",
        "\n",
        "            if region_col and council_col:\n",
        "                subset = df[[region_col, council_col]].astype(str).drop_duplicates().copy()\n",
        "                subset.rename(columns={region_col: 'Region', council_col: 'Council'}, inplace=True)\n",
        "                subset['Region'] = subset['Region'].str.upper()\n",
        "                subset['Council'] = subset['Council'].str.upper()\n",
        "                location_list.append(subset)\n",
        "\n",
        "        self.geo_data = pd.concat(location_list).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        # Geocoding Logic\n",
        "        def clean_council_name(name):\n",
        "            name = str(name).replace(\" MC\", \" Municipal Council\").replace(\" DC\", \" District Council\")\n",
        "            name = name.replace(\" TC\", \" Town Council\").replace(\" CC\", \" City Council\")\n",
        "            return name\n",
        "\n",
        "        self.geo_data['Search_Query'] = (\n",
        "            self.geo_data['Council'].apply(clean_council_name) + \", \" +\n",
        "            self.geo_data['Region'] + \", Tanzania\"\n",
        "        )\n",
        "\n",
        "        geolocator = Nominatim(user_agent=\"tanzania_education_mapping_project_refactored\")\n",
        "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1.5)\n",
        "\n",
        "        print(\"Starting geocoding (this may take time)...\")\n",
        "        # In a real run, this loop runs. For refactoring safety, we keep logic but assume it runs.\n",
        "        lats, longs = [], []\n",
        "        for query in self.geo_data['Search_Query']:\n",
        "            try:\n",
        "                location = geocode(query)\n",
        "                lats.append(location.latitude if location else None)\n",
        "                longs.append(location.longitude if location else None)\n",
        "            except Exception as e:\n",
        "                print(f\"Error {query}: {e}\")\n",
        "                lats.append(None)\n",
        "                longs.append(None)\n",
        "\n",
        "        self.geo_data['Latitude'] = lats\n",
        "        self.geo_data['Longitude'] = longs\n",
        "        self.geo_data = self.geo_data[['Region', 'Council', 'Latitude', 'Longitude']]\n",
        "        self.geo_data.to_csv(Config.GEODATA_FILENAME, index=False)\n",
        "\n",
        "    def _cluster_geodata(self):\n",
        "        print(\"Clustering Geodata...\")\n",
        "        self.geo_data['Latitude'] = pd.to_numeric(self.geo_data['Latitude'], errors='coerce')\n",
        "        self.geo_data['Longitude'] = pd.to_numeric(self.geo_data['Longitude'], errors='coerce')\n",
        "        self.geo_data.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
        "\n",
        "        X = self.geo_data[['Latitude', 'Longitude']]\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        self.geo_data['Geo_Cluster'] = kmeans.fit_predict(X)\n",
        "        print(\"Clustering complete.\")\n",
        "\n",
        "    def _merge_geodata_to_dataframes(self):\n",
        "        print(\"Merging Geo_Cluster into main dataframes...\")\n",
        "        for df_name, df in self.data_handler.dataframes.items():\n",
        "            actual_region = next((n for n in Config.EXPECTED_COLS['Region'] if n in df.columns), None)\n",
        "            actual_council = next((n for n in Config.EXPECTED_COLS['Council'] if n in df.columns), None)\n",
        "\n",
        "            if actual_region and actual_council:\n",
        "                df[actual_region] = df[actual_region].astype(str).str.upper()\n",
        "                df[actual_council] = df[actual_council].astype(str).str.upper()\n",
        "\n",
        "                try:\n",
        "                    merged_df = pd.merge(df, self.geo_data[['Region', 'Council', 'Geo_Cluster']],\n",
        "                                         left_on=[actual_region, actual_council],\n",
        "                                         right_on=['Region', 'Council'],\n",
        "                                         how='left', suffixes=('', '_geo'))\n",
        "\n",
        "                    if 'Region_geo' in merged_df.columns: merged_df.drop(columns=['Region_geo'], inplace=True)\n",
        "                    if 'Council_geo' in merged_df.columns: merged_df.drop(columns=['Council_geo'], inplace=True)\n",
        "\n",
        "                    self.data_handler.dataframes[df_name] = merged_df\n",
        "                except Exception as e:\n",
        "                    print(f\"Error merging Geo for {df_name}: {e}\")\n",
        "\n",
        "\n",
        "class SubjectModeler:\n",
        "    \"\"\"Handles Feature Engineering, Training, and Forecasting for Subjects.\"\"\"\n",
        "\n",
        "    def __init__(self, data_handler):\n",
        "        self.dh = data_handler\n",
        "        self.xgb_model = None\n",
        "        self.lgb_model = None\n",
        "\n",
        "    @staticmethod\n",
        "    def standard_cols(df):\n",
        "        df = df.copy()\n",
        "        df.columns = [str(c).strip().upper() for c in df.columns]\n",
        "        rename_map = {\n",
        "            'YEAR': 'YEAR', 'REGION': 'REGION', 'COUNCIL': 'COUNCIL',\n",
        "            'LGA_STATUS': 'LGA_STATUS', 'GEO_CLUSTER': 'GEO_CLUSTER'\n",
        "        }\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "        return df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Standardizes and reshapes subject data to long format.\"\"\"\n",
        "        # Retrieve necessary dataframes\n",
        "        df_subject = self.dh.get_dataframe(\"Secondary_students_per_subject\")\n",
        "        df_table = self.dh.get_dataframe(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "        df_reentry = self.dh.get_dataframe(\"Secondary-Re_entry\")\n",
        "        df_disability = self.dh.get_dataframe(\"Secondary - DISABALITY 2020-2025\")\n",
        "        df_ict = self.dh.get_dataframe(\"Combined_Secondary_ICT_All_G_NG\")\n",
        "        df_elec = self.dh.get_dataframe(\"Combined_Secondary_Electricity_All_G_NG\")\n",
        "        df_labs = self.dh.get_dataframe(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "\n",
        "        # Standardize\n",
        "        enroll = self.standard_cols(df_subject)\n",
        "        tables = self.standard_cols(df_table)\n",
        "        reentry = self.standard_cols(df_reentry)\n",
        "        disability = self.standard_cols(df_disability)\n",
        "        ict = self.standard_cols(df_ict)\n",
        "        elec = self.standard_cols(df_elec)\n",
        "        labs = self.standard_cols(df_labs)\n",
        "\n",
        "        # Melt Subject Columns\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in enroll.columns]\n",
        "        subject_cols = [c for c in enroll.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        print(f\"Melting {len(subject_cols)} subject columns...\")\n",
        "        long_df = enroll.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "\n",
        "        # Merge Council Features\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "\n",
        "        # Tables\n",
        "        if 'AVAILABLE_TABLES' in tables.columns:\n",
        "            long_df = long_df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna(0)\n",
        "        else:\n",
        "            long_df['AVAILABLE_TABLES'] = 0\n",
        "\n",
        "        # Labs\n",
        "        lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "        if lab_cols:\n",
        "            labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "            long_df = long_df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna(0)\n",
        "        else:\n",
        "            long_df['TOTAL_LABS'] = 0\n",
        "\n",
        "        return long_df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "\n",
        "    def engineer_features(self, df):\n",
        "        \"\"\"Adds Lags, Growth, and Cohort logic.\"\"\"\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "\n",
        "        # Cohort Flow\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup).fillna(-1)\n",
        "\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "    # ==========================================\n",
        "    # 3. Model Training (Updated for Subject)\n",
        "    # ==========================================\n",
        "    def calculate_metrics(y_true, y_pred, model_name):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        # Handle division by zero for MAPE\n",
        "        mask = y_true != 0\n",
        "        if mask.sum() > 0:\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "        else:\n",
        "            mape = np.nan\n",
        "\n",
        "        print(f\"--- {model_name} Results ---\")\n",
        "        print(f\"MAE  : {mae:,.2f}\")\n",
        "        print(f\"RMSE : {rmse:,.2f}\")\n",
        "        print(f\"R^2  : {r2:.4f}\")\n",
        "        print(f\"MAPE : {mape:.2f}% Accuracy :{(100-mape) if not np.isnan(mape) else 0:.2f}%\")\n",
        "        print(\"-\" * 30)\n",
        "        return {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MAPE': mape}\n",
        "\n",
        "    def train_models(self, df):\n",
        "        \"\"\"Trains XGBoost and LightGBM models.\"\"\"\n",
        "        le_reg = LabelEncoder()\n",
        "        le_cou = LabelEncoder()\n",
        "        le_sub = LabelEncoder()\n",
        "\n",
        "        df['REGION_ENC'] = le_reg.fit_transform(df['REGION'].astype(str))\n",
        "        df['COUNCIL_ENC'] = le_cou.fit_transform(df['COUNCIL'].astype(str))\n",
        "        df['SUBJECT_ENC'] = le_sub.fit_transform(df['SUBJECT'].astype(str))\n",
        "\n",
        "        feats = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_LABS', 'LAG_1', 'LAG_2',\n",
        "            'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "\n",
        "        train_df = df[df['YEAR'] <= 2025].copy()\n",
        "        X = train_df[feats]\n",
        "        y = train_df['ENROLLMENT']\n",
        "\n",
        "        print(f\"Training Models on {len(train_df)} rows...\")\n",
        "\n",
        "        self.xgb_model = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1)\n",
        "        self.xgb_model.fit(X, y)\n",
        "\n",
        "        self.lgb_model = lgb.LGBMRegressor(n_estimators=200, num_leaves=60, verbose=-1)\n",
        "        self.lgb_model.fit(X, y)\n",
        "\n",
        "        return df, feats\n",
        "\n",
        "    def _create_next_year_features(self, last_year_df, current_year):\n",
        "        next_df = last_year_df.copy()\n",
        "        next_df['YEAR'] = current_year\n",
        "\n",
        "        next_df['LAG_2'] = next_df['LAG_1']\n",
        "        next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "        next_df['YOY_GROWTH'] = (next_df['LAG_1'] - next_df['LAG_2']) / (next_df['LAG_2'] + 1e-5)\n",
        "\n",
        "        cohort_lookup = last_year_df.set_index(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort(row):\n",
        "            target_form = row['FORM_NUM'] - 1\n",
        "            if target_form < 1: return -1\n",
        "            key = (row['REGION'], row['COUNCIL'], row['SUBJECT'], target_form)\n",
        "            return cohort_lookup.get(key, -1)\n",
        "\n",
        "        next_df['COHORT_LAG'] = next_df.apply(get_cohort, axis=1)\n",
        "        next_df['IS_ELECTION_YEAR'] = 1 if current_year in [2025, 2030] else 0\n",
        "        next_df['ENROLLMENT'] = np.nan\n",
        "        return next_df\n",
        "\n",
        "    def forecast(self, df, feats):\n",
        "        \"\"\"Recursive forecasting from 2026 to 2030.\"\"\"\n",
        "        print(\"Recursive Forecasting (2026-2030)...\")\n",
        "        future_preds = []\n",
        "        current_sim = df[df['YEAR'] == 2025].copy()\n",
        "\n",
        "        for year in range(2026, 2031):\n",
        "            next_step = self._create_next_year_features(current_sim, year)\n",
        "            X_future = next_step[feats]\n",
        "\n",
        "            pred_xgb = self.xgb_model.predict(X_future)\n",
        "            pred_lgb = self.lgb_model.predict(X_future)\n",
        "\n",
        "            next_step['ENROLLMENT'] = (pred_xgb + pred_lgb) / 2\n",
        "            next_step['ENROLLMENT'] = next_step['ENROLLMENT'].apply(lambda x: max(0, x))\n",
        "\n",
        "            future_preds.append(next_step)\n",
        "            current_sim = next_step.copy()\n",
        "            print(f\" > {year} Forecast Complete.\")\n",
        "\n",
        "        forecast_df = pd.concat(future_preds, ignore_index=True)\n",
        "        output_cols = ['YEAR', 'REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'ENROLLMENT']\n",
        "        final_output = forecast_df[output_cols].copy()\n",
        "        final_output['ENROLLMENT'] = final_output['ENROLLMENT'].round(0).astype(int)\n",
        "        return final_output\n",
        "\n",
        "class Pipeline:\n",
        "    \"\"\"Main Orchestrator.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Mount drive logic kept as per original request, though abstracted\n",
        "        # from google.colab import drive\n",
        "        # drive.mount('/content/drive/')\n",
        "        self.data_handler = DataHandler(Config.BASE_DIRECTORY)\n",
        "        self.geo_processor = GeoProcessor(self.data_handler)\n",
        "        self.modeler = SubjectModeler(self.data_handler)\n",
        "\n",
        "    def run(self):\n",
        "        # 1. Data Loading & Cleaning\n",
        "        self.data_handler.load_data()\n",
        "        self.data_handler.clean_data()\n",
        "        self.data_handler.check_discrepancies()\n",
        "        self.data_handler.merge_lga_status()\n",
        "        self.data_handler.drop_null_locations()\n",
        "\n",
        "        # 2. Geo Processing\n",
        "        self.geo_processor.process_geodata()\n",
        "\n",
        "        # 3. Subject Modeling\n",
        "        print(\"\\n=== Starting Subject Modeling Pipeline ===\")\n",
        "        processed_df = self.modeler.prepare_data()\n",
        "        engineered_df = self.modeler.engineer_features(processed_df)\n",
        "        trained_df, feats = self.modeler.train_models(engineered_df)\n",
        "        forecast_results = self.modeler.forecast(trained_df, feats)\n",
        "\n",
        "        print(\"\\n--- Sample Subject Forecast (2026-2030) ---\")\n",
        "        print(forecast_results.head())\n",
        "        return forecast_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pipeline = Pipeline()\n",
        "    forecast = pipeline.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxX3uE0Ckqxe",
        "outputId": "7cbd680e-5c29-47b3-b548-c99cffe11f00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered files: ['Dropout-Secondary  2017-2024.csv', 'Data-Secondary Tables and chairs 2016-2025.csv', 'Secondary-Re_entry.csv', 'Secondary - DISABALITY 2020-2025.csv', 'LGAs Urban and Rural Status.csv', 'Combined_Secondary_Laboratories_Govt.csv', 'Combined_Secondary_Laboratories_All_G_NG.csv', 'Combined_Secondary_ICT_All_G_NG.csv', 'Combined_Secondary_ICT_Govt.csv', 'Combined_Secondary_Electricity_All_G_NG.csv', 'Combined_Secondary_Electricity_Govt.csv', 'Secondary_students_per_subject.csv']\n",
            "Loaded Dropout-Secondary  2017-2024 successfully.\n",
            "Loaded Data-Secondary Tables and chairs 2016-2025 successfully.\n",
            "Loaded Secondary-Re_entry successfully.\n",
            "Loaded Secondary - DISABALITY 2020-2025 successfully.\n",
            "Loaded LGAs Urban and Rural Status successfully.\n",
            "Loaded Combined_Secondary_Laboratories_Govt successfully.\n",
            "Loaded Combined_Secondary_Laboratories_All_G_NG successfully.\n",
            "Loaded Combined_Secondary_ICT_All_G_NG successfully.\n",
            "Loaded Combined_Secondary_ICT_Govt successfully.\n",
            "Loaded Combined_Secondary_Electricity_All_G_NG successfully.\n",
            "Loaded Combined_Secondary_Electricity_Govt successfully.\n",
            "Loaded Secondary_students_per_subject successfully.\n",
            "\n",
            "--- Cleaning DataFrame: Dropout-Secondary  2017-2024 ---\n",
            "\n",
            "--- Cleaning DataFrame: Data-Secondary Tables and chairs 2016-2025 ---\n",
            "  Dropped columns: Unnamed: 6, Unnamed: 7\n",
            "\n",
            "--- Cleaning DataFrame: Secondary-Re_entry ---\n",
            "\n",
            "--- Cleaning DataFrame: Secondary - DISABALITY 2020-2025 ---\n",
            "\n",
            "--- Cleaning DataFrame: LGAs Urban and Rural Status ---\n",
            "\n",
            "--- Cleaning DataFrame: Combined_Secondary_Laboratories_Govt ---\n",
            "\n",
            "--- Cleaning DataFrame: Combined_Secondary_Laboratories_All_G_NG ---\n",
            "\n",
            "--- Cleaning DataFrame: Combined_Secondary_ICT_All_G_NG ---\n",
            "\n",
            "--- Cleaning DataFrame: Combined_Secondary_ICT_Govt ---\n",
            "\n",
            "--- Cleaning DataFrame: Combined_Secondary_Electricity_All_G_NG ---\n",
            "\n",
            "--- Cleaning DataFrame: Combined_Secondary_Electricity_Govt ---\n",
            "\n",
            "--- Cleaning DataFrame: Secondary_students_per_subject ---\n",
            "--- Discrepancies Found ---\n",
            "{'dataframe': 'LGAs Urban and Rural Status', 'column': 'Year', 'issue': 'Missing Column'}\n",
            "  Merged LGA_Status into Dropout-Secondary  2017-2024\n",
            "  Merged LGA_Status into Data-Secondary Tables and chairs 2016-2025\n",
            "  Merged LGA_Status into Secondary-Re_entry\n",
            "  Merged LGA_Status into Secondary - DISABALITY 2020-2025\n",
            "  Merged LGA_Status into Combined_Secondary_Laboratories_Govt\n",
            "  Merged LGA_Status into Combined_Secondary_Laboratories_All_G_NG\n",
            "  Merged LGA_Status into Combined_Secondary_ICT_All_G_NG\n",
            "  Merged LGA_Status into Combined_Secondary_ICT_Govt\n",
            "  Merged LGA_Status into Combined_Secondary_Electricity_All_G_NG\n",
            "  Merged LGA_Status into Combined_Secondary_Electricity_Govt\n",
            "  Merged LGA_Status into Secondary_students_per_subject\n",
            "Loading geodata from /content/drive/MyDrive/MOEST/tanzania_council_geodata.csv\n",
            "Clustering Geodata...\n",
            "Clustering complete.\n",
            "Merging Geo_Cluster into main dataframes...\n",
            "\n",
            "=== Starting Subject Modeling Pipeline ===\n",
            "Melting 283 subject columns...\n",
            "Training Models on 519588 rows...\n",
            "Recursive Forecasting (2026-2030)...\n",
            " > 2026 Forecast Complete.\n",
            " > 2027 Forecast Complete.\n",
            " > 2028 Forecast Complete.\n",
            " > 2029 Forecast Complete.\n",
            " > 2030 Forecast Complete.\n",
            "\n",
            "--- Sample Subject Forecast (2026-2030) ---\n",
            "   YEAR  REGION COUNCIL                         SUBJECT  FORM_NUM  ENROLLMENT\n",
            "0  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         1           0\n",
            "1  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         2           0\n",
            "2  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         3           0\n",
            "3  2026  ARUSHA  ARUSHA             ACCOUNTANCY_GENERAL         4           0\n",
            "4  2026  ARUSHA  ARUSHA  ADDITIONAL MATHEMATICS_GENERAL         1           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Refactored MoEST Modeling: OO Implementation with Individual Model Evaluation\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import (\n",
        "    GradientBoostingRegressor,\n",
        "    RandomForestRegressor,\n",
        "    HistGradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "\n",
        "class Config:\n",
        "    BASE_DIRECTORY = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEODATA_FILENAME = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "\n",
        "    EXPECTED_COLS = {\n",
        "        'Year': ['Year', 'YEAR', 'Academic Year'],\n",
        "        'Region': ['Region', 'REGION', 'REGON'],\n",
        "        'Council': ['Council', 'COUNCIL', 'DISTRICT', 'LGA NAME']\n",
        "    }\n",
        "\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'COBET', 'Vocational', 'Enrollment']\n",
        "\n",
        "class DataHandler:\n",
        "    def __init__(self, base_dir):\n",
        "        self.base_dir = base_dir\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            all_files_in_dir = os.listdir(self.base_dir)\n",
        "            all_files = [f for f in all_files_in_dir if f.endswith('.csv')]\n",
        "\n",
        "            filtered_files = []\n",
        "            for file_name in all_files:\n",
        "                if not any(keyword.lower() in file_name.lower() for keyword in Config.EXCLUDE_KEYWORDS):\n",
        "                    filtered_files.append(file_name)\n",
        "\n",
        "            for file_name in filtered_files:\n",
        "                file_path = os.path.join(self.base_dir, file_name)\n",
        "                df_name = file_name.replace('.csv', '')\n",
        "                try:\n",
        "                    self.dataframes[df_name] = pd.read_csv(file_path)\n",
        "                    print(f\"Loaded {df_name}.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {file_name}: {e}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Directory not found: {self.base_dir}\")\n",
        "\n",
        "    def clean_data(self):\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            for col in df.select_dtypes(include='object').columns:\n",
        "                if df[col].astype(str).str.contains(',').any() or df[col].astype(str).str.fullmatch(r'\\d+\\.?\\d*').any():\n",
        "                    cleaned_col = df[col].astype(str).str.replace(',', '', regex=False).str.strip()\n",
        "                    converted_col = pd.to_numeric(cleaned_col, errors='coerce')\n",
        "                    if converted_col.notna().sum() > 0 and converted_col.dtype != object:\n",
        "                        df[col] = converted_col\n",
        "\n",
        "            unnamed_cols = [col for col in df.columns if re.match(r'Unnamed: \\d+', str(col))]\n",
        "            cols_to_drop = [col for col in unnamed_cols if (df[col].isnull().sum() / len(df) * 100) > 90]\n",
        "            if cols_to_drop:\n",
        "                df.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "    def merge_lga_status(self):\n",
        "        if 'LGAs Urban and Rural Status' not in self.dataframes: return\n",
        "\n",
        "        df_lga_status = self.dataframes['LGAs Urban and Rural Status'].copy()\n",
        "        if 'Remarks' in df_lga_status.columns: df_lga_status.drop(columns=['Remarks'], inplace=True)\n",
        "\n",
        "        df_lga_status.rename(columns={'Region': 'Region', 'Council': 'Council', 'Classification': 'LGA_Status'}, inplace=True)\n",
        "        df_lga_status['Region'] = df_lga_status['Region'].str.upper()\n",
        "        df_lga_status['Council'] = df_lga_status['Council'].str.upper()\n",
        "\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            if df_name == 'LGAs Urban and Rural Status': continue\n",
        "\n",
        "            actual_region = next((n for n in Config.EXPECTED_COLS['Region'] if n in df.columns), None)\n",
        "            actual_council = next((n for n in Config.EXPECTED_COLS['Council'] if n in df.columns), None)\n",
        "\n",
        "            if actual_region and actual_council:\n",
        "                df[actual_region] = df[actual_region].astype(str).str.upper()\n",
        "                df[actual_council] = df[actual_council].astype(str).str.upper()\n",
        "                try:\n",
        "                    merged_df = pd.merge(df, df_lga_status,\n",
        "                                         left_on=[actual_region, actual_council],\n",
        "                                         right_on=['Region', 'Council'],\n",
        "                                         how='left', suffixes=('', '_LGA'))\n",
        "                    if 'Region_LGA' in merged_df.columns: merged_df.drop(columns=['Region_LGA'], inplace=True)\n",
        "                    if 'Council_LGA' in merged_df.columns: merged_df.drop(columns=['Council_LGA'], inplace=True)\n",
        "                    self.dataframes[df_name] = merged_df\n",
        "                except Exception: pass\n",
        "\n",
        "        del self.dataframes['LGAs Urban and Rural Status']\n",
        "        if 'Pre-primary GER NA NER 2017-2025' in self.dataframes:\n",
        "            del self.dataframes['Pre-primary GER NA NER 2017-2025']\n",
        "\n",
        "    def drop_null_locations(self):\n",
        "        for df_name, df in self.dataframes.items():\n",
        "            actual_region = next((n for n in Config.EXPECTED_COLS['Region'] if n in df.columns), None)\n",
        "            actual_council = next((n for n in Config.EXPECTED_COLS['Council'] if n in df.columns), None)\n",
        "            if actual_region and actual_council:\n",
        "                df.dropna(subset=[actual_region, actual_council], inplace=True)\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "class GeoProcessor:\n",
        "    def __init__(self, data_handler):\n",
        "        self.data_handler = data_handler\n",
        "        self.geo_data = None\n",
        "\n",
        "    def process_geodata(self):\n",
        "        if os.path.exists(Config.GEODATA_FILENAME):\n",
        "            print(f\"Loading geodata from {Config.GEODATA_FILENAME}\")\n",
        "            self.geo_data = pd.read_csv(Config.GEODATA_FILENAME)\n",
        "        else:\n",
        "            self._generate_geodata()\n",
        "\n",
        "        self._cluster_geodata()\n",
        "        self._merge_geodata_to_dataframes()\n",
        "\n",
        "    def _generate_geodata(self):\n",
        "        pass\n",
        "\n",
        "    def _cluster_geodata(self):\n",
        "        if self.geo_data is None: return\n",
        "        self.geo_data['Latitude'] = pd.to_numeric(self.geo_data['Latitude'], errors='coerce')\n",
        "        self.geo_data['Longitude'] = pd.to_numeric(self.geo_data['Longitude'], errors='coerce')\n",
        "        self.geo_data.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
        "\n",
        "        X = self.geo_data[['Latitude', 'Longitude']]\n",
        "        if len(X) > 0:\n",
        "            kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "            self.geo_data['Geo_Cluster'] = kmeans.fit_predict(X)\n",
        "\n",
        "    def _merge_geodata_to_dataframes(self):\n",
        "        if self.geo_data is None: return\n",
        "        for df_name, df in self.data_handler.dataframes.items():\n",
        "            actual_region = next((n for n in Config.EXPECTED_COLS['Region'] if n in df.columns), None)\n",
        "            actual_council = next((n for n in Config.EXPECTED_COLS['Council'] if n in df.columns), None)\n",
        "\n",
        "            if actual_region and actual_council:\n",
        "                df[actual_region] = df[actual_region].astype(str).str.upper()\n",
        "                df[actual_council] = df[actual_council].astype(str).str.upper()\n",
        "                try:\n",
        "                    merged_df = pd.merge(df, self.geo_data[['Region', 'Council', 'Geo_Cluster']],\n",
        "                                         left_on=[actual_region, actual_council],\n",
        "                                         right_on=['Region', 'Council'],\n",
        "                                         how='left', suffixes=('', '_geo'))\n",
        "                    if 'Region_geo' in merged_df.columns: merged_df.drop(columns=['Region_geo'], inplace=True)\n",
        "                    if 'Council_geo' in merged_df.columns: merged_df.drop(columns=['Council_geo'], inplace=True)\n",
        "                    self.data_handler.dataframes[df_name] = merged_df\n",
        "                except Exception: pass\n",
        "\n",
        "class SubjectModeler:\n",
        "    def __init__(self, data_handler):\n",
        "        self.dh = data_handler\n",
        "\n",
        "    @staticmethod\n",
        "    def standard_cols(df):\n",
        "        if df is None: return pd.DataFrame()\n",
        "        df = df.copy()\n",
        "        df.columns = [str(c).strip().upper() for c in df.columns]\n",
        "        rename_map = {\n",
        "            'YEAR': 'YEAR', 'REGION': 'REGION', 'COUNCIL': 'COUNCIL',\n",
        "            'LGA_STATUS': 'LGA_STATUS', 'GEO_CLUSTER': 'GEO_CLUSTER'\n",
        "        }\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "        return df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "    def prepare_data(self):\n",
        "        df_subject = self.dh.get_dataframe(\"Secondary_students_per_subject\")\n",
        "        df_table = self.dh.get_dataframe(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "        df_drop = self.dh.get_dataframe(\"Dropout-Secondary  2017-2024\")\n",
        "        df_reentry = self.dh.get_dataframe(\"Secondary-Re_entry\")\n",
        "        df_disability = self.dh.get_dataframe(\"Secondary - DISABALITY 2020-2025\")\n",
        "        df_ict = self.dh.get_dataframe(\"Combined_Secondary_ICT_All_G_NG\")\n",
        "        df_elec = self.dh.get_dataframe(\"Combined_Secondary_Electricity_All_G_NG\")\n",
        "        df_labs = self.dh.get_dataframe(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "\n",
        "        enroll = self.standard_cols(df_subject)\n",
        "        tables = self.standard_cols(df_table)\n",
        "        drops = self.standard_cols(df_drop)\n",
        "        reentry = self.standard_cols(df_reentry)\n",
        "        disability = self.standard_cols(df_disability)\n",
        "        ict = self.standard_cols(df_ict)\n",
        "        elec = self.standard_cols(df_elec)\n",
        "        labs = self.standard_cols(df_labs)\n",
        "\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in enroll.columns]\n",
        "        subject_cols = [c for c in enroll.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        long_df = enroll.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "\n",
        "        if 'AVAILABLE_TABLES' in tables.columns:\n",
        "            long_df = long_df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna(0)\n",
        "        else: long_df['AVAILABLE_TABLES'] = 0\n",
        "\n",
        "        lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "        if lab_cols:\n",
        "            labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "            long_df = long_df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna(0)\n",
        "        else: long_df['TOTAL_LABS'] = 0\n",
        "\n",
        "        re_cols = [c for c in reentry.columns if 'RE-ENROLLED' in c]\n",
        "        if re_cols:\n",
        "            reentry['TOTAL_REENTRY'] = reentry[re_cols].sum(axis=1)\n",
        "            long_df = long_df.merge(reentry[keys + ['TOTAL_REENTRY']], on=keys, how='left').fillna(0)\n",
        "        else: long_df['TOTAL_REENTRY'] = 0\n",
        "\n",
        "        dis_cols = [c for c in disability.columns if c in ['BLIND', 'LOW VISION']]\n",
        "        if dis_cols:\n",
        "            disability['TOTAL_DISABLED'] = disability[dis_cols].sum(axis=1)\n",
        "            long_df = long_df.merge(disability[keys + ['TOTAL_DISABLED']], on=keys, how='left').fillna(0)\n",
        "        else: long_df['TOTAL_DISABLED'] = 0\n",
        "\n",
        "        ict_cols = [c for c in ict.columns if 'COMPUTERS' in c]\n",
        "        if ict_cols:\n",
        "            ict['TOTAL_COMPUTERS'] = ict[ict_cols].sum(axis=1)\n",
        "            long_df = long_df.merge(ict[keys + ['TOTAL_COMPUTERS']], on=keys, how='left').fillna(0)\n",
        "        else: long_df['TOTAL_COMPUTERS'] = 0\n",
        "\n",
        "        elec_col = 'NATIONAL GRID (TANESCO) %'\n",
        "        if elec_col in elec.columns:\n",
        "            elec.rename(columns={elec_col: 'ELEC_GRID_PCT'}, inplace=True)\n",
        "            long_df = long_df.merge(elec[keys + ['ELEC_GRID_PCT']], on=keys, how='left').fillna(0)\n",
        "        else: long_df['ELEC_GRID_PCT'] = 0\n",
        "\n",
        "        d_cols = [c for c in ['TRUANCY', 'PREGNANCY', 'INDISCIPLINE'] if c in drops.columns]\n",
        "        if d_cols:\n",
        "            d_grp = drops.groupby(keys)[d_cols].sum().reset_index()\n",
        "            long_df = long_df.merge(d_grp, on=keys, how='left').fillna(0)\n",
        "            for col in ['TRUANCY', 'PREGNANCY', 'INDISCIPLINE']:\n",
        "                if col not in long_df.columns: long_df[col] = 0\n",
        "        else:\n",
        "             for col in ['TRUANCY', 'PREGNANCY', 'INDISCIPLINE']:\n",
        "                long_df[col] = 0\n",
        "\n",
        "        return long_df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "\n",
        "    def engineer_features(self, df):\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup).fillna(-1)\n",
        "\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name, year_label):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "        mask = y_true != 0\n",
        "        if mask.sum() > 0:\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "        else:\n",
        "            mape = np.nan\n",
        "\n",
        "        accuracy = 100 - mape if not np.isnan(mape) else 0\n",
        "\n",
        "        print(f\" > {model_name} [{year_label}]: RMSE={rmse:,.0f} | MAE={mae:,.0f} | MAPE={mape:.2f}% | Acc={accuracy:.2f}%\")\n",
        "\n",
        "    def evaluate_years(self, df):\n",
        "        le_reg = LabelEncoder()\n",
        "        le_cou = LabelEncoder()\n",
        "        le_sub = LabelEncoder()\n",
        "\n",
        "        df['REGION_ENC'] = le_reg.fit_transform(df['REGION'].astype(str))\n",
        "        df['COUNCIL_ENC'] = le_cou.fit_transform(df['COUNCIL'].astype(str))\n",
        "        df['SUBJECT_ENC'] = le_sub.fit_transform(df['SUBJECT'].astype(str))\n",
        "\n",
        "        feats = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_REENTRY', 'TOTAL_DISABLED',\n",
        "            'TOTAL_COMPUTERS', 'ELEC_GRID_PCT', 'TOTAL_LABS',\n",
        "            'TRUANCY', 'PREGNANCY', 'INDISCIPLINE',\n",
        "            'LAG_1', 'LAG_2', 'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "\n",
        "        available_feats = [f for f in feats if f in df.columns]\n",
        "\n",
        "        # 1. TRAIN on Data <= 2023\n",
        "        print(f\"\\nTraining Models on Data (Years <= 2023)...\")\n",
        "        train_df = df[df['YEAR'] <= 2023].copy()\n",
        "        X_train = train_df[available_feats]\n",
        "        y_train = train_df['ENROLLMENT']\n",
        "\n",
        "        models = {\n",
        "            \"XGBoost\": xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1),\n",
        "            \"LightGBM\": lgb.LGBMRegressor(n_estimators=500, num_leaves=50, min_child_samples=10, learning_rate=0.1, verbose=-1),\n",
        "            \"RandomForest\": RandomForestRegressor(n_estimators=300, max_depth=12, n_jobs=-1, random_state=42),\n",
        "            \"RandomForest 2\": RandomForestRegressor(n_estimators=500, max_depth=12, n_jobs=-1, random_state=42),\n",
        "\n",
        "         #   \"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, max_depth=8, learning_rate=0.05, random_state=42),\n",
        "          #  \"HistGradBoost\": HistGradientBoostingRegressor(max_iter=200, learning_rate=0.05, max_depth=10, random_state=42)\n",
        "        }\n",
        "\n",
        "        for name, model in models.items():\n",
        "            print(f\" > Training {name}...\")\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "        # 2. TEST LOOP\n",
        "        for year in [2024, 2025]:\n",
        "            print(f\"\\n--- Results for Year {year} ---\")\n",
        "            test_df = df[df['YEAR'] == year].copy()\n",
        "\n",
        "            if not test_df.empty:\n",
        "                X_test = test_df[available_feats]\n",
        "                y_test = test_df['ENROLLMENT']\n",
        "\n",
        "                for name, model in models.items():\n",
        "                    print(f\" > Testing {name}...\")\n",
        "                    preds = model.predict(X_test)\n",
        "                    self.calculate_metrics(y_test, preds, name, str(year))\n",
        "            else:\n",
        "                print(f\"No data found for {year}.\")\n",
        "\n",
        "class Pipeline:\n",
        "    def __init__(self):\n",
        "        self.data_handler = DataHandler(Config.BASE_DIRECTORY)\n",
        "        self.geo_processor = GeoProcessor(self.data_handler)\n",
        "        self.modeler = SubjectModeler(self.data_handler)\n",
        "\n",
        "    def run(self):\n",
        "        self.data_handler.load_data()\n",
        "        self.data_handler.clean_data()\n",
        "        self.data_handler.merge_lga_status()\n",
        "        self.data_handler.drop_null_locations()\n",
        "        self.geo_processor.process_geodata()\n",
        "\n",
        "        print(\"\\n=== Starting Subject Modeling Pipeline ===\")\n",
        "        processed_df = self.modeler.prepare_data()\n",
        "        engineered_df = self.modeler.engineer_features(processed_df)\n",
        "        self.modeler.evaluate_years(engineered_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pipeline = Pipeline()\n",
        "    pipeline.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuujUorsmt0c",
        "outputId": "1161d319-b9a6-4c46-8be4-4df1fead8f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Dropout-Secondary  2017-2024.\n",
            "Loaded Data-Secondary Tables and chairs 2016-2025.\n",
            "Loaded Secondary-Re_entry.\n",
            "Loaded Secondary - DISABALITY 2020-2025.\n",
            "Loaded LGAs Urban and Rural Status.\n",
            "Loaded Combined_Secondary_Laboratories_Govt.\n",
            "Loaded Combined_Secondary_Laboratories_All_G_NG.\n",
            "Loaded Combined_Secondary_ICT_All_G_NG.\n",
            "Loaded Combined_Secondary_ICT_Govt.\n",
            "Loaded Combined_Secondary_Electricity_All_G_NG.\n",
            "Loaded Combined_Secondary_Electricity_Govt.\n",
            "Loaded Secondary_students_per_subject.\n",
            "Loading geodata from /content/drive/MyDrive/MOEST/tanzania_council_geodata.csv\n",
            "\n",
            "=== Starting Subject Modeling Pipeline ===\n",
            "\n",
            "Training Models on Data (Years <= 2023)...\n",
            " > Training XGBoost...\n",
            " > Training LightGBM...\n",
            " > Training RandomForest...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtk6Z9IEr3je5J4s6XvqtS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}