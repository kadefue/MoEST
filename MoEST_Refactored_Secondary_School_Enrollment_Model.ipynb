{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjMX3hm5I6CAmKn7N2LUvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kadefue/MoEST/blob/main/MoEST_Refactored_Secondary_School_Enrollment_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsBI_ntH7qr8",
        "outputId": "6dd6418d-ade5-4481-c62f-ad2db690936f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Found 13 files to load.\n",
            "Loaded: Data-Secondary Enrollment 2016-2025\n",
            "Loaded: Dropout-Secondary  2017-2024\n",
            "Loaded: Data-Secondary Tables and chairs 2016-2025\n",
            "Loaded: Secondary-Re_entry\n",
            "Loaded: Secondary - DISABALITY 2020-2025\n",
            "Loaded: LGAs Urban and Rural Status\n",
            "Loaded: Combined_Secondary_Laboratories_Govt\n",
            "Loaded: Combined_Secondary_Laboratories_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_All_G_NG\n",
            "Loaded: Combined_Secondary_ICT_Govt\n",
            "Loaded: Combined_Secondary_Electricity_All_G_NG\n",
            "Loaded: Combined_Secondary_Electricity_Govt\n",
            "Loaded: Secondary_students_per_subject\n",
            "Merged LGA Status into Data-Secondary Enrollment 2016-2025\n",
            "Merged LGA Status into Dropout-Secondary  2017-2024\n",
            "Merged LGA Status into Data-Secondary Tables and chairs 2016-2025\n",
            "Merged LGA Status into Secondary-Re_entry\n",
            "Merged LGA Status into Secondary - DISABALITY 2020-2025\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_Govt\n",
            "Merged LGA Status into Combined_Secondary_Laboratories_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_ICT_Govt\n",
            "Merged LGA Status into Combined_Secondary_Electricity_All_G_NG\n",
            "Merged LGA Status into Combined_Secondary_Electricity_Govt\n",
            "Merged LGA Status into Secondary_students_per_subject\n",
            "\n",
            "--- Starting Feature Engineering ---\n",
            "Melting 391 subject columns...\n",
            "\n",
            "--- Starting Model Engine ---\n",
            "\n",
            "Training all candidate models on Data <= 2023...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Training Random Forest...\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Refactored MoEST Modeling for Secondary School Enrollment\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    GradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 1: Data Loader & Cleaner\n",
        "# =============================================================================\n",
        "\n",
        "class MOESTDataLoader:\n",
        "    \"\"\"\n",
        "    Handles mounting drive, loading CSVs, cleaning headers, handling types,\n",
        "    and managing initial data quality checks.\n",
        "    \"\"\"\n",
        "    def __init__(self, base_directory, exclude_keywords=None):\n",
        "        self.base_directory = base_directory\n",
        "        self.exclude_keywords = exclude_keywords if exclude_keywords else []\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def mount_drive(self):\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "    def get_file_list(self):\n",
        "        all_files = [f for f in os.listdir(self.base_directory) if f.endswith('.csv')]\n",
        "        filtered_files = []\n",
        "        for file_name in all_files:\n",
        "            if not any(keyword.lower() in file_name.lower() for keyword in self.exclude_keywords):\n",
        "                filtered_files.append(file_name)\n",
        "        return filtered_files\n",
        "\n",
        "    def load_data(self):\n",
        "        files = self.get_file_list()\n",
        "        print(f\"Found {len(files)} files to load.\")\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(self.base_directory, file_name)\n",
        "            df_name = file_name.replace('.csv', '')\n",
        "            try:\n",
        "                df = pd.read_csv(file_path)\n",
        "                self.dataframes[df_name] = self._initial_clean(df)\n",
        "                print(f\"Loaded: {df_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "\n",
        "    def _initial_clean(self, df):\n",
        "        \"\"\"Standardizes headers and cleans numeric columns.\"\"\"\n",
        "        df.columns = [str(col).strip().upper() for col in df.columns]\n",
        "\n",
        "        for col in df.select_dtypes(include='object').columns:\n",
        "            if df[col].astype(str).str.contains(',').any():\n",
        "                cleaned = df[col].astype(str).str.replace(',', '', regex=False)\n",
        "                converted = pd.to_numeric(cleaned, errors='coerce')\n",
        "                if converted.notna().sum() > 0:\n",
        "                    df[col] = converted\n",
        "\n",
        "        unnamed = [c for c in df.columns if 'UNNAMED' in c]\n",
        "        to_drop = [c for c in unnamed if df[c].isnull().mean() > 0.9]\n",
        "        df.drop(columns=to_drop, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def get_dataframe(self, name):\n",
        "        return self.dataframes.get(name)\n",
        "\n",
        "    def get_all_dataframes(self):\n",
        "        return self.dataframes\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 2: Geography & Location Manager\n",
        "# =============================================================================\n",
        "\n",
        "class LocationManager:\n",
        "    \"\"\"\n",
        "    Handles Geocoding, LGA Status merging, and Clustering.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframes, geodata_path):\n",
        "        self.dataframes = dataframes\n",
        "        self.geodata_path = geodata_path\n",
        "        self.geo_data = None\n",
        "        self.lga_status_df = None\n",
        "\n",
        "    def standardize_location_columns(self):\n",
        "        for name, df in self.dataframes.items():\n",
        "            reg_col = next((c for c in df.columns if c in ['REGION', 'REGON']), None)\n",
        "            cou_col = next((c for c in df.columns if c in ['COUNCIL', 'DISTRICT', 'LGA NAME']), None)\n",
        "\n",
        "            if reg_col and cou_col:\n",
        "                df.rename(columns={reg_col: 'REGION', cou_col: 'COUNCIL'}, inplace=True)\n",
        "                df['REGION'] = df['REGION'].astype(str).str.upper()\n",
        "                df['COUNCIL'] = df['COUNCIL'].astype(str).str.upper()\n",
        "\n",
        "    def merge_lga_status(self, lga_df_name='LGAs Urban and Rural Status'):\n",
        "        if lga_df_name not in self.dataframes:\n",
        "            print(\"LGA Status DataFrame not found.\")\n",
        "            return\n",
        "\n",
        "        self.lga_status_df = self.dataframes[lga_df_name].copy()\n",
        "        if 'REMARKS' in self.lga_status_df.columns:\n",
        "            self.lga_status_df.drop(columns=['REMARKS'], inplace=True)\n",
        "        self.lga_status_df.rename(columns={'CLASSIFICATION': 'LGA_STATUS'}, inplace=True)\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if name == lga_df_name: continue\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.lga_status_df, on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged LGA Status into {name}\")\n",
        "        del self.dataframes[lga_df_name]\n",
        "\n",
        "    def process_geocoding(self):\n",
        "        if os.path.exists(self.geodata_path):\n",
        "            print(\"Loading existing geodata...\")\n",
        "            self.geo_data = pd.read_csv(self.geodata_path)\n",
        "        else:\n",
        "            print(\"Generating new geodata...\")\n",
        "            self._fetch_geodata()\n",
        "\n",
        "        self._apply_clustering()\n",
        "\n",
        "        for name, df in self.dataframes.items():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                merged = pd.merge(df, self.geo_data[['REGION', 'COUNCIL', 'GEO_CLUSTER']],\n",
        "                                  on=['REGION', 'COUNCIL'], how='left')\n",
        "                self.dataframes[name] = merged\n",
        "                print(f\"Merged Geo Cluster into {name}\")\n",
        "\n",
        "    def _fetch_geodata(self):\n",
        "        locs = []\n",
        "        for df in self.dataframes.values():\n",
        "            if 'REGION' in df.columns and 'COUNCIL' in df.columns:\n",
        "                locs.append(df[['REGION', 'COUNCIL']])\n",
        "        unique_locs = pd.concat(locs).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "        geolocator = Nominatim(user_agent=\"moest_geo_mapper_v3\")\n",
        "        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1.0)\n",
        "\n",
        "        lats, lons = [], []\n",
        "        for idx, row in unique_locs.iterrows():\n",
        "            query = f\"{row['COUNCIL']}, {row['REGION']}, Tanzania\"\n",
        "            try:\n",
        "                loc = geocode(query)\n",
        "                if loc:\n",
        "                    lats.append(loc.latitude)\n",
        "                    lons.append(loc.longitude)\n",
        "                else:\n",
        "                    lats.append(None)\n",
        "                    lons.append(None)\n",
        "            except:\n",
        "                lats.append(None)\n",
        "                lons.append(None)\n",
        "\n",
        "        unique_locs['LATITUDE'] = lats\n",
        "        unique_locs['LONGITUDE'] = lons\n",
        "        self.geo_data = unique_locs.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "        self.geo_data.to_csv(self.geodata_path, index=False)\n",
        "\n",
        "    def _apply_clustering(self):\n",
        "        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "        self.geo_data['GEO_CLUSTER'] = kmeans.fit_predict(self.geo_data[['LATITUDE', 'LONGITUDE']])\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 3: Feature Engineer\n",
        "# =============================================================================\n",
        "\n",
        "class FeatureEngineer:\n",
        "    \"\"\"\n",
        "    Handles specific transformation logic for Secondary School Subjects.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def melt_subjects(df):\n",
        "        id_vars = [c for c in ['YEAR', 'REGION', 'COUNCIL'] if c in df.columns]\n",
        "        subject_cols = [c for c in df.columns if 'FORM ' in c and ' - ' in c]\n",
        "\n",
        "        print(f\"Melting {len(subject_cols)} subject columns...\")\n",
        "        long_df = df.melt(id_vars=id_vars, value_vars=subject_cols, var_name='RAW', value_name='ENROLLMENT')\n",
        "\n",
        "        long_df['FORM_NUM'] = long_df['RAW'].str.extract(r'FORM (\\d)').astype(int)\n",
        "        long_df['SUBJECT'] = long_df['RAW'].str.split(' - ').str[1].str.strip()\n",
        "        long_df.drop(columns=['RAW'], inplace=True)\n",
        "        return long_df\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_infrastructure(main_df, infrastructure_dfs):\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "        df = main_df.copy()\n",
        "\n",
        "        # Tables\n",
        "        tables = infrastructure_dfs.get('tables')\n",
        "        if tables is not None and 'AVAILABLE_TABLES' in tables.columns:\n",
        "            df = df.merge(tables[keys + ['AVAILABLE_TABLES']], on=keys, how='left').fillna({'AVAILABLE_TABLES': 0})\n",
        "\n",
        "        # Labs\n",
        "        labs = infrastructure_dfs.get('labs')\n",
        "        if labs is not None:\n",
        "            lab_cols = [c for c in labs.columns if 'LABORATORY' in c]\n",
        "            if lab_cols:\n",
        "                labs['TOTAL_LABS'] = labs[lab_cols].sum(axis=1)\n",
        "                df = df.merge(labs[keys + ['TOTAL_LABS']], on=keys, how='left').fillna({'TOTAL_LABS': 0})\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_lag_features(df):\n",
        "        df = df.sort_values(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'YEAR'])\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])\n",
        "\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "        df['IS_ELECTION_YEAR'] = df['YEAR'].isin([2015, 2020, 2025, 2030]).astype(int)\n",
        "\n",
        "        return df.fillna(-1)\n",
        "\n",
        "    @staticmethod\n",
        "    def create_cohort_features(df):\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_FORM'] = df['FORM_NUM'] - 1\n",
        "\n",
        "        df['LOOKUP_KEY'] = (df['YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['FORM_NUM'].astype(str))\n",
        "\n",
        "        lookup_dict = df.groupby('LOOKUP_KEY')['ENROLLMENT'].sum().to_dict()\n",
        "\n",
        "        df['SEARCH_KEY'] = (df['PREV_YEAR'].astype(str) + '_' + df['REGION'] + '_' +\n",
        "                            df['COUNCIL'] + '_' + df['SUBJECT'] + '_' + df['PREV_FORM'].astype(str))\n",
        "\n",
        "        df['COHORT_LAG'] = df['SEARCH_KEY'].map(lookup_dict).fillna(-1)\n",
        "        df.drop(columns=['PREV_YEAR', 'PREV_FORM', 'LOOKUP_KEY', 'SEARCH_KEY'], inplace=True)\n",
        "        return df\n",
        "\n",
        "# =============================================================================\n",
        "# CLASS 4: Model Engine (Conditional Ensemble)\n",
        "# =============================================================================\n",
        "\n",
        "class EnrollmentModelEngine:\n",
        "    \"\"\"\n",
        "    Manages Training, Conditional Selection, and Recursive Forecasting.\n",
        "    Implements logic: Use Best Model ONLY unless others are within 60% performance.\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.models = {}\n",
        "        self.encoders = {}\n",
        "        self.features = [\n",
        "            'YEAR', 'REGION_ENC', 'COUNCIL_ENC', 'SUBJECT_ENC', 'FORM_NUM',\n",
        "            'AVAILABLE_TABLES', 'TOTAL_LABS', 'LAG_1', 'LAG_2',\n",
        "            'YOY_GROWTH', 'COHORT_LAG', 'IS_ELECTION_YEAR'\n",
        "        ]\n",
        "        self.selected_model_keys = [] # Stores keys of models to be used for inference\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.encoders['REG'] = LabelEncoder()\n",
        "        self.encoders['COU'] = LabelEncoder()\n",
        "        self.encoders['SUB'] = LabelEncoder()\n",
        "\n",
        "        self.df['REGION_ENC'] = self.encoders['REG'].fit_transform(self.df['REGION'].astype(str))\n",
        "        self.df['COUNCIL_ENC'] = self.encoders['COU'].fit_transform(self.df['COUNCIL'].astype(str))\n",
        "        self.df['SUBJECT_ENC'] = self.encoders['SUB'].fit_transform(self.df['SUBJECT'].astype(str))\n",
        "\n",
        "    def train_all_models(self, cutoff_year=2023):\n",
        "        \"\"\"Trains all 5 candidate models.\"\"\"\n",
        "        print(f\"\\nTraining all candidate models on Data <= {cutoff_year}...\")\n",
        "        train_df = self.df[self.df['YEAR'] <= cutoff_year]\n",
        "        X = train_df[self.features]\n",
        "        y = train_df['ENROLLMENT']\n",
        "\n",
        "        # 1. XGBoost\n",
        "        print(\"Training XGBoost...\")\n",
        "        self.models['XGB'] = xgb.XGBRegressor(n_estimators=300, max_depth=9, learning_rate=0.05, n_jobs=-1)\n",
        "        self.models['XGB'].fit(X, y)\n",
        "\n",
        "        # 2. LightGBM\n",
        "        print(\"Training LightGBM...\")\n",
        "        self.models['LGB'] = lgb.LGBMRegressor(n_estimators=500, num_leaves=50, min_child_samples=10, learning_rate=0.1, verbose=-1)\n",
        "        self.models['LGB'].fit(X, y)\n",
        "\n",
        "        # 3. Random Forest\n",
        "        print(\"Training Random Forest...\")\n",
        "        self.models['RF'] = RandomForestRegressor(n_estimators=300, max_depth=12, n_jobs=-1, random_state=42)\n",
        "        self.models['RF'].fit(X, y)\n",
        "\n",
        "        # 4. HistGradientBoosting (Scikit-Learn)\n",
        "        print(\"Training HistGradientBoosting...\")\n",
        "        self.models['HGB'] = HistGradientBoostingRegressor(max_iter=500, learning_rate=0.1, max_depth=10)\n",
        "        self.models['HGB'].fit(X, y)\n",
        "\n",
        "        # 5. GradientBoosting (Standard)\n",
        "        # Limiting estimators slightly for speed as GB is sequential and slow\n",
        "        print(\"Training GradientBoosting...\")\n",
        "        self.models['GB'] = GradientBoostingRegressor(n_estimators=300, max_depth=9, learning_rate=0.05)\n",
        "        self.models['GB'].fit(X, y)\n",
        "\n",
        "        print(\"All models trained successfully.\")\n",
        "    def calculate_metrics(y_true, y_pred, model_name):\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "        # Handle division by zero for MAPE\n",
        "        mask = y_true != 0\n",
        "        if mask.sum() > 0:\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "            accuracy = 100 - mape\n",
        "        else:\n",
        "            mape = np.nan\n",
        "            accuracy = np.nan\n",
        "\n",
        "        print(f\"--- {model_name} Results ---\")\n",
        "        print(f\"   > {model_name}: R2={r2:.4f}, MAE={mae:,.2f}, RMSE={rmse:,.2f}, Acc={accuracy:.2f}%\")\n",
        "        print(\"-\" * 30)\n",
        "        return rmse\n",
        "\n",
        "    def evaluate_and_select_strategy(self, test_year_start=2024):\n",
        "        \"\"\"\n",
        "        Evaluates models and applies the 60% rule:\n",
        "        1. Find Best Model (Lowest RMSE).\n",
        "        2. Identify models with RMSE <= Best RMSE * 1.6 (Within 60% of best).\n",
        "        3. If only Best fits criteria -> Use Single Best.\n",
        "        4. If others fit criteria -> Use Ensemble (Average of valid candidates).\n",
        "        \"\"\"\n",
        "        test_df = self.df[self.df['YEAR'] >= test_year_start]\n",
        "        if test_df.empty:\n",
        "            print(\"No test data available. Defaulting to XGB only.\")\n",
        "            self.selected_model_keys = ['XGB']\n",
        "            return\n",
        "\n",
        "        X_test = test_df[self.features]\n",
        "        y_true = test_df['ENROLLMENT']\n",
        "\n",
        "        performance = {}\n",
        "        print(f\"\\n--- Evaluation Results (Test Data {test_year_start}+) ---\")\n",
        "\n",
        "        # Evaluate all\n",
        "        print(\"Evaluating all models...\")\n",
        "        for name, model in self.models.items():\n",
        "            preds = model.predict(X_test)\n",
        "            rmse = self.calculate_metrics(y_true, preds, name)\n",
        "            performance[name] = rmse\n",
        "            print(f\"Model: {name} | RMSE: {rmse:,.2f}\")\n",
        "\n",
        "        # Find Best\n",
        "        best_model_name = min(performance, key=performance.get)\n",
        "        best_rmse = performance[best_model_name]\n",
        "        print(f\"\\nBEST MODEL: {best_model_name} (RMSE: {best_rmse:,.2f})\")\n",
        "\n",
        "        # Apply Threshold Rule (RMSE within 40% of best)\n",
        "        # \"Performance at least 40% of best\" usually means Error is not more than 40% higher.\n",
        "        # Threshold = Best_RMSE + (0.40 * Best_RMSE) = 1.4 * Best_RMSE\n",
        "        threshold = best_rmse * 1.4\n",
        "        candidates = [name for name, score in performance.items() if score <= threshold]\n",
        "\n",
        "        print(f\"Selection Threshold (RMSE <= {threshold:,.2f})\")\n",
        "        print(f\"Qualifying Models: {candidates}\")\n",
        "\n",
        "        # Logic: If others exist besides best -> Ensemble. Else -> Single.\n",
        "        if len(candidates) > 1:\n",
        "            self.selected_model_keys = candidates\n",
        "            print(f\"Strategy: ENSEMBLE (Average of {', '.join(candidates)})\")\n",
        "        else:\n",
        "            self.selected_model_keys = [best_model_name]\n",
        "            print(f\"Strategy: SINGLE BEST MODEL ({best_model_name})\")\n",
        "\n",
        "    def _predict(self, X):\n",
        "        \"\"\"Predicts using the selected strategy.\"\"\"\n",
        "        preds = []\n",
        "        for key in self.selected_model_keys:\n",
        "            preds.append(self.models[key].predict(X))\n",
        "\n",
        "        # Average the predictions of selected models\n",
        "        return np.mean(preds, axis=0)\n",
        "\n",
        "    def recursive_forecast(self, start_year, end_year):\n",
        "        print(f\"\\nStarting Recursive Forecast ({start_year}-{end_year}) using {self.selected_model_keys}...\")\n",
        "        future_data = []\n",
        "        current_data = self.df[self.df['YEAR'] == (start_year - 1)].copy()\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            next_df = self._prepare_next_step(current_data, year)\n",
        "\n",
        "            X_future = next_df[self.features]\n",
        "            preds = self._predict(X_future)\n",
        "\n",
        "            next_df['ENROLLMENT'] = np.maximum(0, preds)\n",
        "\n",
        "            future_data.append(next_df)\n",
        "            current_data = next_df.copy()\n",
        "            print(f\" > Forecasted {year}\")\n",
        "\n",
        "        return pd.concat(future_data, ignore_index=True)\n",
        "\n",
        "    def _prepare_next_step(self, prev_df, target_year):\n",
        "        next_df = prev_df.copy()\n",
        "        next_df['YEAR'] = target_year\n",
        "\n",
        "        # Shift Lags\n",
        "        next_df['LAG_2'] = next_df['LAG_1']\n",
        "        next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "\n",
        "        # Update Growth\n",
        "        next_df['YOY_GROWTH'] = (next_df['LAG_1'] - next_df['LAG_2']) / (next_df['LAG_2'] + 1e-5)\n",
        "\n",
        "        # Update Cohort Logic\n",
        "        cohort_lookup = prev_df.set_index(['REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort(row):\n",
        "            target_form = row['FORM_NUM'] - 1\n",
        "            if target_form < 1: return -1\n",
        "            key = (row['REGION'], row['COUNCIL'], row['SUBJECT'], target_form)\n",
        "            return cohort_lookup.get(key, -1)\n",
        "\n",
        "        next_df['COHORT_LAG'] = next_df.apply(get_cohort, axis=1)\n",
        "        next_df['IS_ELECTION_YEAR'] = 1 if target_year in [2025, 2030] else 0\n",
        "\n",
        "        return next_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # 1. Configuration\n",
        "    BASE_DIR = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "    GEO_FILE = '/content/drive/MyDrive/MOEST/tanzania_council_geodata.csv'\n",
        "    EXCLUDE_KEYWORDS = ['Primary', 'Textbooks', 'Population', 'Teacher', 'COBET', 'Vocational']\n",
        "\n",
        "    # 2. Load Data\n",
        "    loader = MOESTDataLoader(BASE_DIR, EXCLUDE_KEYWORDS)\n",
        "    loader.mount_drive()\n",
        "    loader.load_data()\n",
        "    all_dfs = loader.get_all_dataframes()\n",
        "\n",
        "    # 3. Location & Clean Up\n",
        "    loc_manager = LocationManager(all_dfs, GEO_FILE)\n",
        "    loc_manager.standardize_location_columns()\n",
        "    loc_manager.merge_lga_status()\n",
        "\n",
        "    # 4. Feature Engineering\n",
        "    print(\"\\n--- Starting Feature Engineering ---\")\n",
        "    df_subject = all_dfs.get(\"Secondary_students_per_subject\")\n",
        "    df_tables = all_dfs.get(\"Data-Secondary Tables and chairs 2016-2025\")\n",
        "    df_labs = all_dfs.get(\"Combined_Secondary_Laboratories_All_G_NG\")\n",
        "\n",
        "    if df_subject is None:\n",
        "        raise ValueError(\"Critical DataFrame 'Secondary_students_per_subject' not found.\")\n",
        "\n",
        "    engineer = FeatureEngineer()\n",
        "    long_df = engineer.melt_subjects(df_subject)\n",
        "    merged_df = engineer.merge_infrastructure(long_df, {'tables': df_tables, 'labs': df_labs})\n",
        "    lagged_df = engineer.create_lag_features(merged_df)\n",
        "    final_df = engineer.create_cohort_features(lagged_df)\n",
        "\n",
        "    # 5. Modeling & Forecasting (Updated Strategy)\n",
        "    print(\"\\n--- Starting Model Engine ---\")\n",
        "    engine = EnrollmentModelEngine(final_df)\n",
        "    engine.preprocess()\n",
        "\n",
        "    # Train (Using data up to 2023 to test on 2024 and 2025)\n",
        "    engine.train_all_models(cutoff_year=2023)\n",
        "\n",
        "    # Evaluate & Select Strategy (Best or Ensemble)\n",
        "    engine.evaluate_and_select_strategy(test_year_start=2024)\n",
        "\n",
        "    # 6. Generate Forecast\n",
        "    # Note: Recursive forecast starts from 2026, using 2025 as the base history\n",
        "    forecast_df = engine.recursive_forecast(2026, 2030)\n",
        "\n",
        "    # 7. Output\n",
        "    print(\"\\n--- Final Forecast Sample ---\")\n",
        "    output_cols = ['YEAR', 'REGION', 'COUNCIL', 'SUBJECT', 'FORM_NUM', 'ENROLLMENT']\n",
        "    final_view = forecast_df[output_cols].copy()\n",
        "    final_view['ENROLLMENT'] = final_view['ENROLLMENT'].round(0).astype(int)\n",
        "    print(final_view.head(10))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}