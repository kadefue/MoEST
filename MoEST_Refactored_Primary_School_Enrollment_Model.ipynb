{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kadefue/MoEST/blob/main/MoEST_Refactored_Primary_School_Enrollment_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    HistGradientBoostingRegressor\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class EnrollmentForecaster:\n",
        "    \"\"\"\n",
        "    Object-Oriented Pipeline for Enrollment Forecasting.\n",
        "    Handles data preparation, feature engineering, model selection, and recursive forecasting.\n",
        "    Designed for Pre-Primary and Primary School datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, enrollment_df, infrastructure_dfs=None, name=\"Model\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            enrollment_df: DataFrame containing the main enrollment numbers.\n",
        "            infrastructure_dfs: Dictionary of helper DataFrames (Dropouts, Classrooms, etc.)\n",
        "            name: Name of the category (e.g., 'Primary', 'Pre-Primary')\n",
        "        \"\"\"\n",
        "        self.raw_df = enrollment_df\n",
        "        self.infra_dfs = infrastructure_dfs if infrastructure_dfs else {}\n",
        "        self.name = name\n",
        "\n",
        "        # Define the 5 models to compare\n",
        "        self.models = {\n",
        "            'XGBoost': xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.05, n_jobs=-1, random_state=42),\n",
        "            'LightGBM': lgb.LGBMRegressor(n_estimators=300, num_leaves=31, learning_rate=0.05, verbose=-1, random_state=42),\n",
        "            'RandomForest': RandomForestRegressor(n_estimators=200, max_depth=12, n_jobs=-1, random_state=42),\n",
        "            'GradientBoosting': GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.05, random_state=42),\n",
        "            'HistGradientBoosting': HistGradientBoostingRegressor(max_iter=200, max_depth=10, random_state=42)\n",
        "        }\n",
        "\n",
        "        self.best_models = []\n",
        "        self.le_reg = LabelEncoder()\n",
        "        self.le_cou = LabelEncoder()\n",
        "\n",
        "        # Will be populated during processing\n",
        "        self.final_df = None\n",
        "        self.features = []\n",
        "\n",
        "    def _standardize_columns(self, df):\n",
        "        \"\"\"Standardize column names to Upper Case and strip whitespace.\"\"\"\n",
        "        df = df.copy()\n",
        "        df.columns = [str(c).strip().upper() for c in df.columns]\n",
        "\n",
        "        # Map common variations to standard names\n",
        "        rename_map = {\n",
        "            'YEAR': 'YEAR', 'ACADEMIC YEAR': 'YEAR',\n",
        "            'REGION': 'REGION', 'REGON': 'REGION',\n",
        "            'COUNCIL': 'COUNCIL', 'DISTRICT': 'COUNCIL', 'LGA NAME': 'COUNCIL'\n",
        "        }\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "        return df\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"\n",
        "        Cleans, melts (if wide), and merges infrastructure data.\n",
        "        \"\"\"\n",
        "        print(f\"[{self.name}] Preparing Data...\")\n",
        "        df = self._standardize_columns(self.raw_df)\n",
        "\n",
        "        # 1. Identify ID columns and Value columns\n",
        "        id_vars = ['YEAR', 'REGION', 'COUNCIL']\n",
        "        potential_values = [c for c in df.columns if c not in id_vars]\n",
        "\n",
        "        # Heuristic: Value columns usually contain specific keywords\n",
        "        value_vars = [c for c in potential_values if any(x in c for x in ['STD', 'STANDARD', 'GRADE', 'PRE', 'TOTAL', 'BOYS', 'GIRLS'])]\n",
        "\n",
        "        if not value_vars:\n",
        "             # Fallback: If no explicit grade columns found, assume 'ENROLLMENT' or use all remaining numeric columns\n",
        "             numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "             value_vars = [c for c in numeric_cols if c not in id_vars]\n",
        "\n",
        "        if not value_vars:\n",
        "             raise ValueError(f\"Could not identify enrollment columns in {self.name} dataset. Columns found: {df.columns}\")\n",
        "\n",
        "        # Melt to Long Format\n",
        "        long_df = df.melt(id_vars=[c for c in id_vars if c in df.columns],\n",
        "                          value_vars=value_vars,\n",
        "                          var_name='GRADE_LEVEL',\n",
        "                          value_name='ENROLLMENT')\n",
        "\n",
        "        # Convert 'ENROLLMENT' to numeric, handling commas and missing values\n",
        "        long_df['ENROLLMENT'] = pd.to_numeric(long_df['ENROLLMENT'].astype(str).str.replace(',', ''), errors='coerce')\n",
        "        long_df['ENROLLMENT'] = long_df['ENROLLMENT'].fillna(0)\n",
        "\n",
        "        # 2. Clean Grade Level & Extract Numeric Grade\n",
        "        long_df['GRADE_LEVEL'] = long_df['GRADE_LEVEL'].astype(str).str.upper()\n",
        "\n",
        "        def extract_grade_num(s):\n",
        "            if 'PRE' in s: return 0\n",
        "            if '1' in s or 'I' in s: return 1\n",
        "            if '2' in s or 'II' in s: return 2\n",
        "            if '3' in s or 'III' in s: return 3\n",
        "            if '4' in s or 'IV' in s: return 4\n",
        "            if '5' in s or 'V' in s: return 5\n",
        "            if '6' in s or 'VI' in s: return 6\n",
        "            if '7' in s or 'VII' in s: return 7\n",
        "            return 0 # Default to 0 (Entry level) if unknown\n",
        "\n",
        "        long_df['GRADE_NUM'] = long_df['GRADE_LEVEL'].apply(extract_grade_num)\n",
        "\n",
        "        # 3. Merge Infrastructure (if available)\n",
        "        keys = ['YEAR', 'REGION', 'COUNCIL']\n",
        "\n",
        "        for name, infra_df in self.infra_dfs.items():\n",
        "            if infra_df is None: continue\n",
        "\n",
        "            infra_clean = self._standardize_columns(infra_df)\n",
        "\n",
        "            # Simple aggregation: Sum numeric columns by Council\n",
        "            numeric_cols = infra_clean.select_dtypes(include=np.number).columns.tolist()\n",
        "            numeric_cols = [c for c in numeric_cols if c not in ['YEAR']]\n",
        "\n",
        "            # Check if we can merge (must have Region/Council)\n",
        "            if numeric_cols and all(k in infra_clean.columns for k in keys):\n",
        "                agg_infra = infra_clean.groupby(keys)[numeric_cols].sum().reset_index()\n",
        "                # Rename columns to avoid collision\n",
        "                agg_infra.columns = keys + [f\"{name}_{c}\" for c in numeric_cols]\n",
        "\n",
        "                long_df = long_df.merge(agg_infra, on=keys, how='left')\n",
        "\n",
        "        # Fill missing infrastructure/enrollment with 0\n",
        "        long_df = long_df.fillna(0)\n",
        "\n",
        "        # 4. Sort for Feature Engineering\n",
        "        long_df = long_df.sort_values(['REGION', 'COUNCIL', 'GRADE_NUM', 'YEAR'])\n",
        "        self.final_df = long_df\n",
        "        return self\n",
        "\n",
        "    def engineer_features(self):\n",
        "        \"\"\"\n",
        "        Creates Lags, Year-over-Year Growth, and Cohort Features.\n",
        "        \"\"\"\n",
        "        print(f\"[{self.name}] Engineering Features...\")\n",
        "        df = self.final_df.copy()\n",
        "\n",
        "        # Group by Unit of Analysis\n",
        "        g = df.groupby(['REGION', 'COUNCIL', 'GRADE_NUM'])\n",
        "\n",
        "        # 1. Simple Lags\n",
        "        df['LAG_1'] = g['ENROLLMENT'].shift(1)\n",
        "        df['LAG_2'] = g['ENROLLMENT'].shift(2)\n",
        "        df['YOY_GROWTH'] = (df['ENROLLMENT'] - df['LAG_1']) / (df['LAG_1'] + 1e-5)\n",
        "\n",
        "        # 2. Cohort Logic (The \"Flow\" Feature)\n",
        "        # Students in Grade N (Year T) come from Grade N-1 (Year T-1)\n",
        "        df['PREV_YEAR'] = df['YEAR'] - 1\n",
        "        df['PREV_GRADE'] = df['GRADE_NUM'] - 1\n",
        "\n",
        "        # Create a Lookup Dictionary for fast access\n",
        "        lookup = df.set_index(['YEAR', 'REGION', 'COUNCIL', 'GRADE_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "        def get_cohort_flow(row):\n",
        "            # If Grade 1 or Pre-Primary, there is no \"Previous Grade\" in this system\n",
        "            if row['PREV_GRADE'] < 1 and self.name == 'Primary':\n",
        "                return -1 # Entry grade\n",
        "            if row['GRADE_NUM'] == 0: # Pre-Primary\n",
        "                return -1\n",
        "\n",
        "            key = (row['PREV_YEAR'], row['REGION'], row['COUNCIL'], row['PREV_GRADE'])\n",
        "            return lookup.get(key, -1)\n",
        "\n",
        "        df['COHORT_LAG'] = df.apply(get_cohort_flow, axis=1)\n",
        "\n",
        "        # 3. Encodings\n",
        "        df['REGION_ENC'] = self.le_reg.fit_transform(df['REGION'].astype(str))\n",
        "        df['COUNCIL_ENC'] = self.le_cou.fit_transform(df['COUNCIL'].astype(str))\n",
        "\n",
        "        # 4. Clean up\n",
        "        df = df.drop(columns=['PREV_YEAR', 'PREV_GRADE'])\n",
        "        df = df.fillna(-1)\n",
        "\n",
        "        # Define Features for Training (exclude IDs and Target)\n",
        "        exclude_cols = ['YEAR', 'REGION', 'COUNCIL', 'GRADE_LEVEL', 'ENROLLMENT']\n",
        "        self.features = [c for c in df.columns if c not in exclude_cols]\n",
        "\n",
        "        self.final_df = df\n",
        "        return self\n",
        "\n",
        "    def train_and_select_best(self):\n",
        "        \"\"\"\n",
        "        Trains all 5 models and selects the top 2 based on R2 Score.\n",
        "        Now includes MAPE and Accuracy metrics.\n",
        "        \"\"\"\n",
        "        print(f\"[{self.name}] Training 5 Models & Selecting Best 2...\")\n",
        "\n",
        "        # Determine Train/Test Split\n",
        "        max_year = self.final_df['YEAR'].max()\n",
        "        if self.final_df['YEAR'].nunique() > 1:\n",
        "            train_df = self.final_df[self.final_df['YEAR'] < max_year]\n",
        "            test_df = self.final_df[self.final_df['YEAR'] == max_year]\n",
        "\n",
        "        X_train = train_df[self.features]\n",
        "        y_train = train_df['ENROLLMENT']\n",
        "        X_test = test_df[self.features]\n",
        "        y_test = test_df['ENROLLMENT']\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "                preds = model.predict(X_test)\n",
        "\n",
        "                # Standard Metrics\n",
        "                r2 = r2_score(y_test, preds)\n",
        "                mae = mean_absolute_error(y_test, preds)\n",
        "                rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "\n",
        "                # Percentage Metrics (MAPE & Accuracy)\n",
        "                # Avoid division by zero\n",
        "                mask = y_test != 0\n",
        "                if mask.sum() > 0:\n",
        "                    mape = np.mean(np.abs((y_test[mask] - preds[mask]) / y_test[mask])) * 100\n",
        "                    accuracy = 100 - mape\n",
        "                else:\n",
        "                    mape = np.nan\n",
        "                    accuracy = np.nan\n",
        "\n",
        "                results.append({\n",
        "                    'Name': name,\n",
        "                    'Model': model,\n",
        "                    'R2': r2,\n",
        "                    'MAE': mae,\n",
        "                    'RMSE': rmse,\n",
        "                    'MAPE': mape,\n",
        "                    'Accuracy': accuracy\n",
        "                })\n",
        "                print(f\"   > {name}: R2={r2:.4f}, MAE={mae:,.2f}, MAPE={mape:.2f}%, Acc={accuracy:.2f}%\")\n",
        "            except Exception as e:\n",
        "                print(f\"   > {name} failed: {e}\")\n",
        "\n",
        "        # Select Top 2 by R2\n",
        "        sorted_models = sorted(results, key=lambda x: x['R2'], reverse=True)\n",
        "        self.best_models = sorted_models[:2]\n",
        "\n",
        "        print(f\"   >> WINNERS for {self.name}: {self.best_models[0]['Name']} & {self.best_models[1]['Name']}\")\n",
        "        print(\"-\" * 40)\n",
        "        return self.best_models\n",
        "\n",
        "    def forecast_recursive(self, start_year=2026, end_year=2030):\n",
        "        \"\"\"\n",
        "        Generates forecasts for the specified range using the average of the top 2 models.\n",
        "        Returns detailed dataframe with readable grades.\n",
        "        \"\"\"\n",
        "        print(f\"[{self.name}] Generating Recursive Forecast ({start_year}-{end_year})...\")\n",
        "\n",
        "        # Start with the latest available data\n",
        "        current_data = self.final_df[self.final_df['YEAR'] == self.final_df['YEAR'].max()].copy()\n",
        "        forecasts = []\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            next_df = current_data.copy()\n",
        "            next_df['YEAR'] = year\n",
        "\n",
        "            # 1. Update Lags\n",
        "            next_df['LAG_2'] = next_df['LAG_1']\n",
        "            next_df['LAG_1'] = next_df['ENROLLMENT']\n",
        "\n",
        "            # 2. Update Cohort Lag\n",
        "            lookup = current_data.set_index(['REGION', 'COUNCIL', 'GRADE_NUM'])['ENROLLMENT'].to_dict()\n",
        "\n",
        "            def update_cohort(row):\n",
        "                if row['GRADE_NUM'] <= 1: return -1\n",
        "                return lookup.get((row['REGION'], row['COUNCIL'], row['GRADE_NUM'] - 1), -1)\n",
        "\n",
        "            next_df['COHORT_LAG'] = next_df.apply(update_cohort, axis=1)\n",
        "\n",
        "            # 3. Predict using Top 2 Models\n",
        "            print(\"Now generating the results-----Best models are: \")\n",
        "            print(self.best_models[0])\n",
        "            print(self.best_models[1])\n",
        "            model_1 = self.best_models[0]['Model']\n",
        "            model_2 = self.best_models[1]['Model']\n",
        "\n",
        "            p1 = model_1.predict(next_df[self.features])\n",
        "            p2 = model_2.predict(next_df[self.features])\n",
        "\n",
        "            # Average and Clip\n",
        "            avg_pred = (p1 + p2) / 2\n",
        "            next_df['ENROLLMENT'] = np.maximum(avg_pred, 0)\n",
        "\n",
        "            forecasts.append(next_df)\n",
        "            current_data = next_df.copy()\n",
        "\n",
        "        result_df = pd.concat(forecasts, ignore_index=True)\n",
        "\n",
        "        # Map Grade Num back to Labels for Readability\n",
        "        grade_map = {\n",
        "            0: 'Pre-Primary', 1: 'Standard 1', 2: 'Standard 2', 3: 'Standard 3',\n",
        "            4: 'Standard 4', 5: 'Standard 5', 6: 'Standard 6', 7: 'Standard 7'\n",
        "        }\n",
        "        result_df['GRADE_LABEL'] = result_df['GRADE_NUM'].map(grade_map)\n",
        "\n",
        "        return result_df\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# MAIN EXECUTION BLOCK WITH GOOGLE DRIVE\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    loaded_dataframes = {}\n",
        "\n",
        "    # 1. ATTEMPT TO CONNECT TO GOOGLE DRIVE\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        print(\">> Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive/')\n",
        "        IN_COLAB = True\n",
        "\n",
        "        base_directory = '/content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/'\n",
        "\n",
        "        if os.path.exists(base_directory):\n",
        "            print(f\">> Loading files from: {base_directory}\")\n",
        "            all_files = [f for f in os.listdir(base_directory) if f.endswith('.csv')]\n",
        "\n",
        "            # Keywords to exclude\n",
        "            exclude_keywords = ['Secondary', 'Textbooks', 'Population', 'Teacher', 'COBET', 'Vocational']\n",
        "\n",
        "            filtered_files = [f for f in all_files if not any(k.lower() in f.lower() for k in exclude_keywords)]\n",
        "\n",
        "            for file_name in filtered_files:\n",
        "                file_path = os.path.join(base_directory, file_name)\n",
        "                df_name = file_name.replace('.csv', '')\n",
        "                try:\n",
        "                    loaded_dataframes[df_name] = pd.read_csv(file_path)\n",
        "                    print(f\"   Loaded: {df_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   Error loading {file_name}: {e}\")\n",
        "        else:\n",
        "            print(f\"Error: Directory not found: {base_directory}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\">> Not running in Google Colab. Drive mounting skipped.\")\n",
        "        IN_COLAB = False\n",
        "\n",
        "    # 2. CHECK DATA AND RUN PIPELINE\n",
        "    if loaded_dataframes:\n",
        "        # Retrieve Primary Data\n",
        "        df_prim = loaded_dataframes.get(\"Data-Primary Enrollment 2016-2025\")\n",
        "        df_pre = loaded_dataframes.get(\"Data-Pre-Primary Enrollment 2016-2025\")\n",
        "\n",
        "        # Retrieve Infrastructure (Shared)\n",
        "        infra_dict = {\n",
        "            'Classrooms': loaded_dataframes.get(\"PRIMARY Pit Latrine AND CLASSROOMS 2017-2025\"),\n",
        "            'Dropout': loaded_dataframes.get(\"Dropout-Primary 2017-2024\"),\n",
        "            'Repeaters': loaded_dataframes.get(\"Repeaters-Primary 2017-2024\")\n",
        "        }\n",
        "\n",
        "        all_forecasts = []\n",
        "\n",
        "        # --- PRIMARY FORECAST ---\n",
        "        if df_prim is not None:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"   STARTING PRIMARY SCHOOL FORECAST   \")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            prim_forecaster = EnrollmentForecaster(df_prim, infra_dict, name=\"Primary\")\n",
        "            prim_forecaster.prepare_data()\n",
        "            prim_forecaster.engineer_features()\n",
        "            prim_forecaster.train_and_select_best()\n",
        "\n",
        "            prim_forecast = prim_forecaster.forecast_recursive(2026, 2030)\n",
        "            all_forecasts.append(prim_forecast)\n",
        "\n",
        "        # --- PRE-PRIMARY FORECAST ---\n",
        "        if df_pre is not None:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"   STARTING PRE-PRIMARY SCHOOL FORECAST   \")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            pre_forecaster = EnrollmentForecaster(df_pre, infra_dict, name=\"Pre-Primary\")\n",
        "            pre_forecaster.prepare_data()\n",
        "            pre_forecaster.engineer_features()\n",
        "            pre_forecaster.train_and_select_best()\n",
        "\n",
        "            pre_forecast = pre_forecaster.forecast_recursive(2026, 2030)\n",
        "            all_forecasts.append(pre_forecast)\n",
        "\n",
        "        # --- COMBINE AND FORMAT OUTPUT ---\n",
        "        if all_forecasts:\n",
        "            final_combined_df = pd.concat(all_forecasts, ignore_index=True)\n",
        "\n",
        "            # Ensure sorting logic uses the numeric grade before we drop it (Pre-Primary = 0)\n",
        "            final_combined_df = final_combined_df.sort_values(['YEAR', 'REGION', 'COUNCIL', 'GRADE_NUM'])\n",
        "\n",
        "            # Select relevant columns and rename GRADE_LABEL to GRADE_LEVEL as requested\n",
        "            output_cols = ['YEAR', 'REGION', 'COUNCIL', 'GRADE_LABEL', 'ENROLLMENT']\n",
        "            final_output = final_combined_df[output_cols].rename(columns={'GRADE_LABEL': 'GRADE_LEVEL'})\n",
        "\n",
        "            # Round off to integer\n",
        "            final_output['ENROLLMENT'] = final_output['ENROLLMENT'].round(0).astype(int)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"   COMBINED ENROLLMENT FORECAST (2026-2030)   \")\n",
        "            print(\"   Format: YEAR  REGION  COUNCIL  GRADE_LEVEL  ENROLLMENT\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            # Displaying first 50 rows as a preview to avoid console overflow\n",
        "            # In a real environment, you can export this dataframe or view more\n",
        "            print(final_output.head(50).to_string(index=False))\n",
        "\n",
        "            print(f\"\\n[Note] Total rows generated: {len(final_output)}\")\n",
        "\n",
        "    else:\n",
        "        print(\"WARNING: No data loaded. Please check your Drive path or ensure you are in Colab.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Mounting Google Drive...\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            ">> Loading files from: /content/drive/MyDrive/GUIDELINES_TSC_JAN2026/Data Set/csvs/\n",
            "   Loaded: Data-Pre-Primary Enrollment 2016-2025\n",
            "   Loaded: Data-Primary Enrollment 2016-2025\n",
            "   Loaded: Dropout-Primary 2017-2024\n",
            "   Loaded: Pre-primary GER NA NER 2017-2025\n",
            "   Loaded: Data-Primary repeaters 2017-2025\n",
            "   Loaded: Data-Primary STD VII Leavers 2017-2025\n",
            "   Loaded: Primary GIR NA NIR 2017-2025\n",
            "   Loaded: PRIMARY DESK 2016-2025\n",
            "   Loaded: Primary-Re_entry\n",
            "   Loaded: PRE-PRIMARY - DISABALITY 2024-2025\n",
            "   Loaded: PRIMARY - DISABALITY 2017-2025\n",
            "   Loaded: PRIMARY Pit Latrine AND CLASSROOMS  Final 2016-2025\n",
            "   Loaded: LGAs Urban and Rural Status\n",
            "   Loaded: Combined_Primary_ICT_Govt\n",
            "   Loaded: Combined_Primary_ICT_All_G_NG\n",
            "   Loaded: Combined_Primary_Electricity_All_G_NG\n",
            "   Loaded: Combined_Primary_Electricity_Govt\n",
            "\n",
            "==================================================\n",
            "   STARTING PRIMARY SCHOOL FORECAST   \n",
            "==================================================\n",
            "[Primary] Preparing Data...\n",
            "[Primary] Engineering Features...\n",
            "[Primary] Training 5 Models & Selecting Best 2...\n",
            "   > XGBoost: R2=0.9938, MAE=155.46, MAPE=1.44%, Acc=98.56%\n",
            "   > LightGBM: R2=0.9915, MAE=214.25, MAPE=2.18%, Acc=97.82%\n",
            "   > RandomForest: R2=0.9935, MAE=111.84, MAPE=0.86%, Acc=99.14%\n",
            "   > GradientBoosting: R2=0.9962, MAE=149.35, MAPE=1.58%, Acc=98.42%\n",
            "   > HistGradientBoosting: R2=0.9904, MAE=222.76, MAPE=2.15%, Acc=97.85%\n",
            "   >> WINNERS for Primary: GradientBoosting & XGBoost\n",
            "----------------------------------------\n",
            "[Primary] Generating Recursive Forecast (2026-2030)...\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9962110737431841, 'MAE': 149.34988828839653, 'RMSE': np.float64(368.55055075673147), 'MAPE': np.float64(1.5764077139120147), 'Accuracy': np.float64(98.42359228608798)}\n",
            "{'Name': 'XGBoost', 'Model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             feature_weights=None, gamma=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
            "             max_leaves=None, min_child_weight=None, missing=nan,\n",
            "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
            "             n_jobs=-1, num_parallel_tree=None, ...), 'R2': 0.9938210844993591, 'MAE': 155.4579315185547, 'RMSE': np.float64(470.6473932255442), 'MAPE': np.float64(1.4398955787408938), 'Accuracy': np.float64(98.56010442125911)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9962110737431841, 'MAE': 149.34988828839653, 'RMSE': np.float64(368.55055075673147), 'MAPE': np.float64(1.5764077139120147), 'Accuracy': np.float64(98.42359228608798)}\n",
            "{'Name': 'XGBoost', 'Model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             feature_weights=None, gamma=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
            "             max_leaves=None, min_child_weight=None, missing=nan,\n",
            "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
            "             n_jobs=-1, num_parallel_tree=None, ...), 'R2': 0.9938210844993591, 'MAE': 155.4579315185547, 'RMSE': np.float64(470.6473932255442), 'MAPE': np.float64(1.4398955787408938), 'Accuracy': np.float64(98.56010442125911)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9962110737431841, 'MAE': 149.34988828839653, 'RMSE': np.float64(368.55055075673147), 'MAPE': np.float64(1.5764077139120147), 'Accuracy': np.float64(98.42359228608798)}\n",
            "{'Name': 'XGBoost', 'Model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             feature_weights=None, gamma=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
            "             max_leaves=None, min_child_weight=None, missing=nan,\n",
            "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
            "             n_jobs=-1, num_parallel_tree=None, ...), 'R2': 0.9938210844993591, 'MAE': 155.4579315185547, 'RMSE': np.float64(470.6473932255442), 'MAPE': np.float64(1.4398955787408938), 'Accuracy': np.float64(98.56010442125911)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9962110737431841, 'MAE': 149.34988828839653, 'RMSE': np.float64(368.55055075673147), 'MAPE': np.float64(1.5764077139120147), 'Accuracy': np.float64(98.42359228608798)}\n",
            "{'Name': 'XGBoost', 'Model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             feature_weights=None, gamma=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
            "             max_leaves=None, min_child_weight=None, missing=nan,\n",
            "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
            "             n_jobs=-1, num_parallel_tree=None, ...), 'R2': 0.9938210844993591, 'MAE': 155.4579315185547, 'RMSE': np.float64(470.6473932255442), 'MAPE': np.float64(1.4398955787408938), 'Accuracy': np.float64(98.56010442125911)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9962110737431841, 'MAE': 149.34988828839653, 'RMSE': np.float64(368.55055075673147), 'MAPE': np.float64(1.5764077139120147), 'Accuracy': np.float64(98.42359228608798)}\n",
            "{'Name': 'XGBoost', 'Model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "             feature_weights=None, gamma=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
            "             max_leaves=None, min_child_weight=None, missing=nan,\n",
            "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
            "             n_jobs=-1, num_parallel_tree=None, ...), 'R2': 0.9938210844993591, 'MAE': 155.4579315185547, 'RMSE': np.float64(470.6473932255442), 'MAPE': np.float64(1.4398955787408938), 'Accuracy': np.float64(98.56010442125911)}\n",
            "\n",
            "==================================================\n",
            "   STARTING PRE-PRIMARY SCHOOL FORECAST   \n",
            "==================================================\n",
            "[Pre-Primary] Preparing Data...\n",
            "[Pre-Primary] Engineering Features...\n",
            "[Pre-Primary] Training 5 Models & Selecting Best 2...\n",
            "   > XGBoost: R2=0.8917, MAE=1,231.64, MAPE=21.63%, Acc=78.37%\n",
            "   > LightGBM: R2=0.9618, MAE=532.53, MAPE=7.48%, Acc=92.52%\n",
            "   > RandomForest: R2=0.9920, MAE=168.94, MAPE=2.26%, Acc=97.74%\n",
            "   > GradientBoosting: R2=0.9672, MAE=501.67, MAPE=7.74%, Acc=92.26%\n",
            "   > HistGradientBoosting: R2=0.9668, MAE=553.09, MAPE=7.99%, Acc=92.01%\n",
            "   >> WINNERS for Pre-Primary: RandomForest & GradientBoosting\n",
            "----------------------------------------\n",
            "[Pre-Primary] Generating Recursive Forecast (2026-2030)...\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'RandomForest', 'Model': RandomForestRegressor(max_depth=12, n_estimators=200, n_jobs=-1,\n",
            "                      random_state=42), 'R2': 0.9919718083328445, 'MAE': 168.93668021308636, 'RMSE': np.float64(449.18002059840563), 'MAPE': np.float64(2.256991673127867), 'Accuracy': np.float64(97.74300832687213)}\n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9671515499764085, 'MAE': 501.66967158700817, 'RMSE': np.float64(908.5922026552473), 'MAPE': np.float64(7.737450915539166), 'Accuracy': np.float64(92.26254908446083)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'RandomForest', 'Model': RandomForestRegressor(max_depth=12, n_estimators=200, n_jobs=-1,\n",
            "                      random_state=42), 'R2': 0.9919718083328445, 'MAE': 168.93668021308636, 'RMSE': np.float64(449.18002059840563), 'MAPE': np.float64(2.256991673127867), 'Accuracy': np.float64(97.74300832687213)}\n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9671515499764085, 'MAE': 501.66967158700817, 'RMSE': np.float64(908.5922026552473), 'MAPE': np.float64(7.737450915539166), 'Accuracy': np.float64(92.26254908446083)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'RandomForest', 'Model': RandomForestRegressor(max_depth=12, n_estimators=200, n_jobs=-1,\n",
            "                      random_state=42), 'R2': 0.9919718083328445, 'MAE': 168.93668021308636, 'RMSE': np.float64(449.18002059840563), 'MAPE': np.float64(2.256991673127867), 'Accuracy': np.float64(97.74300832687213)}\n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9671515499764085, 'MAE': 501.66967158700817, 'RMSE': np.float64(908.5922026552473), 'MAPE': np.float64(7.737450915539166), 'Accuracy': np.float64(92.26254908446083)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'RandomForest', 'Model': RandomForestRegressor(max_depth=12, n_estimators=200, n_jobs=-1,\n",
            "                      random_state=42), 'R2': 0.9919718083328445, 'MAE': 168.93668021308636, 'RMSE': np.float64(449.18002059840563), 'MAPE': np.float64(2.256991673127867), 'Accuracy': np.float64(97.74300832687213)}\n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9671515499764085, 'MAE': 501.66967158700817, 'RMSE': np.float64(908.5922026552473), 'MAPE': np.float64(7.737450915539166), 'Accuracy': np.float64(92.26254908446083)}\n",
            "Now generating the results-----Best models are: \n",
            "{'Name': 'RandomForest', 'Model': RandomForestRegressor(max_depth=12, n_estimators=200, n_jobs=-1,\n",
            "                      random_state=42), 'R2': 0.9919718083328445, 'MAE': 168.93668021308636, 'RMSE': np.float64(449.18002059840563), 'MAPE': np.float64(2.256991673127867), 'Accuracy': np.float64(97.74300832687213)}\n",
            "{'Name': 'GradientBoosting', 'Model': GradientBoostingRegressor(learning_rate=0.05, max_depth=5, n_estimators=200,\n",
            "                          random_state=42), 'R2': 0.9671515499764085, 'MAE': 501.66967158700817, 'RMSE': np.float64(908.5922026552473), 'MAPE': np.float64(7.737450915539166), 'Accuracy': np.float64(92.26254908446083)}\n",
            "\n",
            "============================================================\n",
            "   COMBINED ENROLLMENT FORECAST (2026-2030)   \n",
            "   Format: YEAR  REGION  COUNCIL  GRADE_LEVEL  ENROLLMENT\n",
            "============================================================\n",
            " YEAR REGION    COUNCIL GRADE_LEVEL  ENROLLMENT\n",
            " 2026 ARUSHA     Arusha Pre-Primary       13677\n",
            " 2026 ARUSHA     Arusha  Standard 1       17222\n",
            " 2026 ARUSHA     Arusha  Standard 1       11103\n",
            " 2026 ARUSHA     Arusha  Standard 1       13003\n",
            " 2026 ARUSHA     Arusha  Standard 1       10261\n",
            " 2026 ARUSHA     Arusha  Standard 1        9284\n",
            " 2026 ARUSHA     Arusha  Standard 1        9986\n",
            " 2026 ARUSHA     Arusha  Standard 5        9202\n",
            " 2026 ARUSHA  Arusha CC Pre-Primary       13134\n",
            " 2026 ARUSHA  Arusha CC  Standard 1       22016\n",
            " 2026 ARUSHA  Arusha CC  Standard 1       15125\n",
            " 2026 ARUSHA  Arusha CC  Standard 1       17903\n",
            " 2026 ARUSHA  Arusha CC  Standard 1       16085\n",
            " 2026 ARUSHA  Arusha CC  Standard 1       12223\n",
            " 2026 ARUSHA  Arusha CC  Standard 1       12384\n",
            " 2026 ARUSHA  Arusha CC  Standard 5       18637\n",
            " 2026 ARUSHA     Karatu Pre-Primary        8280\n",
            " 2026 ARUSHA     Karatu  Standard 1        8933\n",
            " 2026 ARUSHA     Karatu  Standard 1        8028\n",
            " 2026 ARUSHA     Karatu  Standard 1        8114\n",
            " 2026 ARUSHA     Karatu  Standard 1        8293\n",
            " 2026 ARUSHA     Karatu  Standard 1        5344\n",
            " 2026 ARUSHA     Karatu  Standard 1        5440\n",
            " 2026 ARUSHA     Karatu  Standard 5        6342\n",
            " 2026 ARUSHA    Longido Pre-Primary        7753\n",
            " 2026 ARUSHA    Longido  Standard 1       12836\n",
            " 2026 ARUSHA    Longido  Standard 1        4616\n",
            " 2026 ARUSHA    Longido  Standard 1        5593\n",
            " 2026 ARUSHA    Longido  Standard 1        4860\n",
            " 2026 ARUSHA    Longido  Standard 1        2368\n",
            " 2026 ARUSHA    Longido  Standard 1        2903\n",
            " 2026 ARUSHA    Longido  Standard 5        4275\n",
            " 2026 ARUSHA       Meru Pre-Primary       11695\n",
            " 2026 ARUSHA       Meru  Standard 1       10183\n",
            " 2026 ARUSHA       Meru  Standard 1        7688\n",
            " 2026 ARUSHA       Meru  Standard 1       10100\n",
            " 2026 ARUSHA       Meru  Standard 1        7538\n",
            " 2026 ARUSHA       Meru  Standard 1        7023\n",
            " 2026 ARUSHA       Meru  Standard 1        7766\n",
            " 2026 ARUSHA       Meru  Standard 5        8414\n",
            " 2026 ARUSHA    Monduli Pre-Primary        5854\n",
            " 2026 ARUSHA    Monduli  Standard 1       16115\n",
            " 2026 ARUSHA    Monduli  Standard 1        4649\n",
            " 2026 ARUSHA    Monduli  Standard 1        7539\n",
            " 2026 ARUSHA    Monduli  Standard 1        5687\n",
            " 2026 ARUSHA    Monduli  Standard 1        4775\n",
            " 2026 ARUSHA    Monduli  Standard 1        4828\n",
            " 2026 ARUSHA    Monduli  Standard 5        5000\n",
            " 2026 ARUSHA Ngorongoro Pre-Primary       14355\n",
            " 2026 ARUSHA Ngorongoro  Standard 1       15423\n",
            "\n",
            "[Note] Total rows generated: 7360\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S852l8JXnkFY",
        "outputId": "d32ce6ca-2f0f-4667-b5d7-6d5a2b0d2b93"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}