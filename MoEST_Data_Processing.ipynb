{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CIBAwSB1qniFyR_Q-szL1r1I2XmGbK8X",
      "authorship_tag": "ABX9TyPdVLIvoZGuwZk2G/kOu14N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kadefue/MoEST/blob/main/MoEST_Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsjZCZpMy-qK",
        "outputId": "eeee4099-3490-4589-9df0-18fed33f25b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/BEST/BEST 2016.xlsx...\n",
            "  -> Extracted '3.26Lab' to 2016_3.26Lab.csv\n",
            "  -> Extracted '3.27LabGov' to 2016_3.27LabGov.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2017.xlsx...\n",
            "  -> Extracted '3.36LabRegCoun' to 2017_3.36LabRegCoun.csv\n",
            "  -> Extracted '3.37LabGovtRegCoun' to 2017_3.37LabGovtRegCoun.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2018.xlsx...\n",
            "  -> Extracted '3.37Lab' to 2018_3.37Lab.csv\n",
            "  -> Extracted '3.38LabGov' to 2018_3.38LabGov.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2019.xlsx...\n",
            "  -> Extracted '3.37Lab' to 2019_3.37Lab.csv\n",
            "  -> Extracted '3.38LabGov' to 2019_3.38LabGov.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2020.xlsx...\n",
            "  -> Extracted '3.37Lab' to 2020_3.37Lab.csv\n",
            "  -> Extracted '3.38LabGov' to 2020_3.38LabGov.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2021.xlsx...\n",
            "  -> Extracted 'T3.37Lab' to 2021_T3.37Lab.csv\n",
            "  -> Extracted 'T3.38LabGov' to 2021_T3.38LabGov.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2022.xlsx...\n",
            "  -> Extracted 'T3.38Lab' to 2022_T3.38Lab.csv\n",
            "  -> Extracted 'T3.39LabGov' to 2022_T3.39LabGov.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2023.xlsx...\n",
            "  -> Extracted 'T3.39LabG&NG' to 2023_T3.39LabG&NG.csv\n",
            "  -> Extracted 'T3.40LabG' to 2023_T3.40LabG.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2024.xlsx...\n",
            "  -> Extracted 'T3.39LabG&NG' to 2024_T3.39LabG&NG.csv\n",
            "  -> Extracted 'T3.40LabG' to 2024_T3.40LabG.csv\n",
            "Processing /content/drive/MyDrive/BEST/BEST 2025.xlsx...\n",
            "  -> Extracted 'T3.40LabG&NG' to 2025_T3.40LabG&NG.csv\n",
            "  -> Extracted 'T3.41LabG' to 2025_T3.41LabG.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def extract_sheets_no_spaces():\n",
        "    # 1. Define the mapping of Year -> Sheet Names (No Spaces)\n",
        "    sheet_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"], # Appears identically in both columns\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    # 2. Directory settings (Change '.' to your folder path if needed)\n",
        "    base_dir = \".\"\n",
        "\n",
        "    # 3. Iterate through years and process files\n",
        "    for year, sheets_to_extract in sheet_mapping.items():\n",
        "        filename = f\"/content/drive/MyDrive/BEST/BEST {year}.xlsx\"\n",
        "        file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Skipping {year}: File '{filename}' not found.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {filename}...\")\n",
        "\n",
        "        try:\n",
        "            # Load the Excel file\n",
        "            xls = pd.ExcelFile(file_path)\n",
        "\n",
        "            # Get list of actual sheets in the file\n",
        "            available_sheets = xls.sheet_names\n",
        "\n",
        "            for sheet_name in sheets_to_extract:\n",
        "                if sheet_name in available_sheets:\n",
        "                    # Read the specific sheet\n",
        "                    df = pd.read_excel(xls, sheet_name=sheet_name)\n",
        "\n",
        "                    # 4. Save the extracted sheet\n",
        "                    output_filename = f\"{year}_{sheet_name}.csv\"\n",
        "                    df.to_csv(output_filename, index=False)\n",
        "                    print(f\"  -> Extracted '{sheet_name}' to {output_filename}\")\n",
        "                else:\n",
        "                    print(f\"  [Warning] Sheet '{sheet_name}' not found in {filename}.\")\n",
        "                    # Optional: Print available sheets to help debug typos\n",
        "                    # print(f\"  Available sheets: {available_sheets}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_sheets_no_spaces()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# Helper Functions from council_data_extractor.py\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells (NaNs).\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    3. Drop sparse columns.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # 1. Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # 2. Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # 3. \"Grand\" Logic: Delete row and all below if \"Grand\" is found\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # 4. \"Total\" Logic (Region): Delete rows containing \"Total\"\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # 5. \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # 6. Sparsity Logic: Drop column if >60% empty\n",
        "    cols_to_keep = []\n",
        "    threshold = 0.60\n",
        "    for col in df.columns:\n",
        "        is_missing = df[col].isna() | df[col].isin([0, '0', ''])\n",
        "        missing_pct = is_missing.mean()\n",
        "        if missing_pct <= threshold:\n",
        "            cols_to_keep.append(col)\n",
        "    df = df[cols_to_keep]\n",
        "\n",
        "    # 7. Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # 8. Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# Main Extraction Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_sheets_cleaned():\n",
        "    # 1. Define the mapping of Year -> Sheet Names (No Spaces)\n",
        "    sheet_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    # 2. Directory settings\n",
        "    # Note: Using standard path joining to be safe\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # 3. Iterate through years and process files\n",
        "    for year, sheets_to_extract in sheet_mapping.items():\n",
        "        filename = f\"BEST {year}.xlsx\"\n",
        "        file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Skipping {year}: File '{file_path}' not found.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {filename}...\")\n",
        "\n",
        "        try:\n",
        "            # Load the Excel file wrapper\n",
        "            xls = pd.ExcelFile(file_path)\n",
        "            available_sheets = xls.sheet_names\n",
        "\n",
        "            for sheet_name in sheets_to_extract:\n",
        "                if sheet_name in available_sheets:\n",
        "                    # LOAD with header=None to support the cleaning logic\n",
        "                    df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
        "\n",
        "                    # APPLY CLEANING LOGIC\n",
        "                    df = normalize_merged_cells(df)\n",
        "                    df = process_council_sheet(df)\n",
        "\n",
        "                    # SAVE\n",
        "                    output_filename = f\"{year}_{sheet_name}.csv\"\n",
        "                    # Use header=False because headers are part of the data rows now\n",
        "                    df.to_csv(output_filename, index=False, header=False)\n",
        "                    print(f\"  -> Extracted & Cleaned '{sheet_name}' to {output_filename}\")\n",
        "                else:\n",
        "                    print(f\"  [Warning] Sheet '{sheet_name}' not found in {filename}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_sheets_cleaned()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp6F4AONzbXN",
        "outputId": "46db8d9d-6b94-45b2-f523-f22fd8fd4397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BEST 2016.xlsx...\n",
            "  -> Extracted & Cleaned '3.26Lab' to 2016_3.26Lab.csv\n",
            "  -> Extracted & Cleaned '3.27LabGov' to 2016_3.27LabGov.csv\n",
            "Processing BEST 2017.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 126.0 133.0 41.0 9.0 133.0 38.0 14.0 494.0\n",
            " 295.0 48.0 214.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 76.66666666666667 96.15384615384616\n",
            " 34.48275862068966 22.22222222222222 66.66666666666666 58.333333333333336\n",
            " 30 61.53846153846154 87.71929824561403 78.57142857142857\n",
            " 85.71428571428571]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Extracted & Cleaned '3.36LabRegCoun' to 2017_3.36LabRegCoun.csv\n",
            "  -> Extracted & Cleaned '3.37LabGovtRegCoun' to 2017_3.37LabGovtRegCoun.csv\n",
            "Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government and Non-Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 124.0 143.0 49.0 12.0 164.0 45.0 23.0\n",
            " 560.0 301.0 61.0 216.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 5 1 18 5 9 4 5 47 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 5 1 18 5 9 4 5 351 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Extracted & Cleaned '3.37Lab' to 2018_3.37Lab.csv\n",
            "  -> Extracted & Cleaned '3.38LabGov' to 2018_3.38LabGov.csv\n",
            "Processing BEST 2019.xlsx...\n",
            "  -> Extracted & Cleaned '3.37Lab' to 2019_3.37Lab.csv\n",
            "  -> Extracted & Cleaned '3.38LabGov' to 2019_3.38LabGov.csv\n",
            "Processing BEST 2020.xlsx...\n",
            "  -> Extracted & Cleaned '3.37Lab' to 2020_3.37Lab.csv\n",
            "  -> Extracted & Cleaned '3.38LabGov' to 2020_3.38LabGov.csv\n",
            "Processing BEST 2021.xlsx...\n",
            "  -> Extracted & Cleaned 'T3.37Lab' to 2021_T3.37Lab.csv\n",
            "  -> Extracted & Cleaned 'T3.38LabGov' to 2021_T3.38LabGov.csv\n",
            "Processing BEST 2022.xlsx...\n",
            "  -> Extracted & Cleaned 'T3.38Lab' to 2022_T3.38Lab.csv\n",
            "  -> Extracted & Cleaned 'T3.39LabGov' to 2022_T3.39LabGov.csv\n",
            "Processing BEST 2023.xlsx...\n",
            "  -> Extracted & Cleaned 'T3.39LabG&NG' to 2023_T3.39LabG&NG.csv\n",
            "  -> Extracted & Cleaned 'T3.40LabG' to 2023_T3.40LabG.csv\n",
            "Processing BEST 2024.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Extracted & Cleaned 'T3.39LabG&NG' to 2024_T3.39LabG&NG.csv\n",
            "  -> Extracted & Cleaned 'T3.40LabG' to 2024_T3.40LabG.csv\n",
            "Processing BEST 2025.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 87.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Extracted & Cleaned 'T3.40LabG&NG' to 2025_T3.40LabG&NG.csv\n",
            "  -> Extracted & Cleaned 'T3.41LabG' to 2025_T3.41LabG.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-3108776045.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 90.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 1. Cleaning & Helper Functions\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    3. Drop sparse columns.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # \"Grand\" Logic\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # \"Total\" Logic (Region)\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # Sparsity Logic\n",
        "    cols_to_keep = []\n",
        "    threshold = 0.60\n",
        "    for col in df.columns:\n",
        "        is_missing = df[col].isna() | df[col].isin([0, '0', ''])\n",
        "        missing_pct = is_missing.mean()\n",
        "        if missing_pct <= threshold:\n",
        "            cols_to_keep.append(col)\n",
        "    df = df[cols_to_keep]\n",
        "\n",
        "    # Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Main Extraction and Combination Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_and_combine():\n",
        "    # Mapping based on your latest snippet\n",
        "    sheet_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # Lists to hold the dataframes for final merging\n",
        "    left_dfs = []\n",
        "    right_dfs = []\n",
        "\n",
        "    for year, sheets in sheet_mapping.items():\n",
        "        filename = f\"BEST {year}.xlsx\"\n",
        "        file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Skipping {year}: File not found at {file_path}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {filename}...\")\n",
        "\n",
        "        try:\n",
        "            xls = pd.ExcelFile(file_path)\n",
        "            available_sheets = xls.sheet_names\n",
        "\n",
        "            # --- PROCESS LEFT SHEET (Index 0) ---\n",
        "            target_left = sheets[0]\n",
        "            if target_left in available_sheets:\n",
        "                df_left = pd.read_excel(xls, sheet_name=target_left, header=None)\n",
        "                df_left = normalize_merged_cells(df_left)\n",
        "                df_left = process_council_sheet(df_left)\n",
        "\n",
        "                # Add Year column for tracking\n",
        "                df_left.insert(0, 'Source_Year', year)\n",
        "                left_dfs.append(df_left)\n",
        "                print(f\"  -> Added Left Sheet: {target_left}\")\n",
        "            else:\n",
        "                print(f\"  [Warning] Left Sheet '{target_left}' missing.\")\n",
        "\n",
        "            # --- PROCESS RIGHT SHEET (Index 1) ---\n",
        "            if len(sheets) > 1:\n",
        "                target_right = sheets[1]\n",
        "                if target_right in available_sheets:\n",
        "                    df_right = pd.read_excel(xls, sheet_name=target_right, header=None)\n",
        "                    df_right = normalize_merged_cells(df_right)\n",
        "                    df_right = process_council_sheet(df_right)\n",
        "\n",
        "                    # Add Year column for tracking\n",
        "                    df_right.insert(0, 'Source_Year', year)\n",
        "                    right_dfs.append(df_right)\n",
        "                    print(f\"  -> Added Right Sheet: {target_right}\")\n",
        "                else:\n",
        "                    print(f\"  [Warning] Right Sheet '{target_right}' missing.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. Save Combined Files\n",
        "    # ==========================================\n",
        "\n",
        "    print(\"\\n--- Saving Combined Files ---\")\n",
        "\n",
        "    if left_dfs:\n",
        "        combined_left = pd.concat(left_dfs, ignore_index=True)\n",
        "        combined_left.to_csv(\"Combined_Left_Sheets.csv\", index=False, header=False)\n",
        "        print(f\"Saved 'Combined_Left_Sheets.csv' with {len(combined_left)} rows.\")\n",
        "    else:\n",
        "        print(\"No Left sheets extracted.\")\n",
        "\n",
        "    if right_dfs:\n",
        "        combined_right = pd.concat(right_dfs, ignore_index=True)\n",
        "        combined_right.to_csv(\"Combined_Right_Sheets.csv\", index=False, header=False)\n",
        "        print(f\"Saved 'Combined_Right_Sheets.csv' with {len(combined_right)} rows.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_combine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L19OVCt09IDn",
        "outputId": "b5015ca7-f1e6-451b-d8be-73c29f1f0e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BEST 2016.xlsx...\n",
            "  -> Added Left Sheet: 3.26Lab\n",
            "  -> Added Right Sheet: 3.27LabGov\n",
            "Processing BEST 2017.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 126.0 133.0 41.0 9.0 133.0 38.0 14.0 494.0\n",
            " 295.0 48.0 214.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 76.66666666666667 96.15384615384616\n",
            " 34.48275862068966 22.22222222222222 66.66666666666666 58.333333333333336\n",
            " 30 61.53846153846154 87.71929824561403 78.57142857142857\n",
            " 85.71428571428571]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet: 3.36LabRegCoun\n",
            "  -> Added Right Sheet: 3.37LabGovtRegCoun\n",
            "Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government and Non-Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 124.0 143.0 49.0 12.0 164.0 45.0 23.0\n",
            " 560.0 301.0 61.0 216.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 5 1 18 5 9 4 5 47 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 5 1 18 5 9 4 5 351 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet: 3.37Lab\n",
            "  -> Added Right Sheet: 3.38LabGov\n",
            "Processing BEST 2019.xlsx...\n",
            "  -> Added Left Sheet: 3.37Lab\n",
            "  -> Added Right Sheet: 3.38LabGov\n",
            "Processing BEST 2020.xlsx...\n",
            "  -> Added Left Sheet: 3.37Lab\n",
            "  -> Added Right Sheet: 3.38LabGov\n",
            "Processing BEST 2021.xlsx...\n",
            "  -> Added Left Sheet: T3.37Lab\n",
            "  -> Added Right Sheet: T3.38LabGov\n",
            "Processing BEST 2022.xlsx...\n",
            "  -> Added Left Sheet: T3.38Lab\n",
            "  -> Added Right Sheet: T3.39LabGov\n",
            "Processing BEST 2023.xlsx...\n",
            "  -> Added Left Sheet: T3.39LabG&NG\n",
            "  -> Added Right Sheet: T3.40LabG\n",
            "Processing BEST 2024.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet: T3.39LabG&NG\n",
            "  -> Added Right Sheet: T3.40LabG\n",
            "Processing BEST 2025.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 87.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet: T3.40LabG&NG\n",
            "  -> Added Right Sheet: T3.41LabG\n",
            "\n",
            "--- Saving Combined Files ---\n",
            "Saved 'Combined_Left_Sheets.csv' with 1876 rows.\n",
            "Saved 'Combined_Right_Sheets.csv' with 1876 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2151808901.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 90.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 1. Cleaning & Helper Functions\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    3. Drop sparse columns.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # \"Grand\" Logic\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # \"Total\" Logic (Region)\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # Sparsity Logic\n",
        "    cols_to_keep = []\n",
        "    threshold = 0.60\n",
        "    for col in df.columns:\n",
        "        is_missing = df[col].isna() | df[col].isin([0, '0', ''])\n",
        "        missing_pct = is_missing.mean()\n",
        "        if missing_pct <= threshold:\n",
        "            cols_to_keep.append(col)\n",
        "    df = df[cols_to_keep]\n",
        "\n",
        "    # Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Main Extraction and Combination Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_and_combine():\n",
        "    # Mapping based on your latest snippet\n",
        "    sheet_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # Lists to hold the dataframes for final merging\n",
        "    left_dfs = []\n",
        "    right_dfs = []\n",
        "\n",
        "    # Sorted ensures we start with 2016, then 2017, etc.\n",
        "    for year, sheets in sorted(sheet_mapping.items()):\n",
        "        filename = f\"BEST {year}.xlsx\"\n",
        "        file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Skipping {year}: File not found at {file_path}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {filename}...\")\n",
        "\n",
        "        try:\n",
        "            xls = pd.ExcelFile(file_path)\n",
        "            available_sheets = xls.sheet_names\n",
        "\n",
        "            # --- PROCESS LEFT SHEET (Index 0) ---\n",
        "            target_left = sheets[0]\n",
        "            if target_left in available_sheets:\n",
        "                # 1. Load & Clean\n",
        "                df_left = pd.read_excel(xls, sheet_name=target_left, header=None)\n",
        "                df_left = normalize_merged_cells(df_left)\n",
        "                df_left = process_council_sheet(df_left)\n",
        "\n",
        "                # 2. Add Year Column\n",
        "                df_left.insert(0, 'Source_Year', year)\n",
        "\n",
        "                # 3. Handle Header Rows (Keep for first file, Drop for rest)\n",
        "                if len(left_dfs) > 0:\n",
        "                    # This is NOT the first file -> Drop rows 1 to 4 (Indices 0-3)\n",
        "                    # We assume cleaning didn't drastically alter row count at the top\n",
        "                    df_left = df_left.iloc[4:]\n",
        "                    print(f\"  -> Added Left Sheet (Rows 1-4 dropped): {target_left}\")\n",
        "                else:\n",
        "                    # This IS the first file -> Keep all rows\n",
        "                    print(f\"  -> Added Left Sheet (Headers kept): {target_left}\")\n",
        "\n",
        "                left_dfs.append(df_left)\n",
        "            else:\n",
        "                print(f\"  [Warning] Left Sheet '{target_left}' missing.\")\n",
        "\n",
        "            # --- PROCESS RIGHT SHEET (Index 1) ---\n",
        "            if len(sheets) > 1:\n",
        "                target_right = sheets[1]\n",
        "                if target_right in available_sheets:\n",
        "                    # 1. Load & Clean\n",
        "                    df_right = pd.read_excel(xls, sheet_name=target_right, header=None)\n",
        "                    df_right = normalize_merged_cells(df_right)\n",
        "                    df_right = process_council_sheet(df_right)\n",
        "\n",
        "                    # 2. Add Year Column\n",
        "                    df_right.insert(0, 'Source_Year', year)\n",
        "\n",
        "                    # 3. Handle Header Rows (Keep for first file, Drop for rest)\n",
        "                    if len(right_dfs) > 0:\n",
        "                        # This is NOT the first file -> Drop rows 1 to 4\n",
        "                        df_right = df_right.iloc[4:]\n",
        "                        print(f\"  -> Added Right Sheet (Rows 1-4 dropped): {target_right}\")\n",
        "                    else:\n",
        "                        # This IS the first file -> Keep all rows\n",
        "                        print(f\"  -> Added Right Sheet (Headers kept): {target_right}\")\n",
        "\n",
        "                    right_dfs.append(df_right)\n",
        "                else:\n",
        "                    print(f\"  [Warning] Right Sheet '{target_right}' missing.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. Save Combined Files\n",
        "    # ==========================================\n",
        "\n",
        "    print(\"\\n--- Saving Combined Files ---\")\n",
        "\n",
        "    if left_dfs:\n",
        "        combined_left = pd.concat(left_dfs, ignore_index=True)\n",
        "        combined_left.to_csv(\"Combined_Left_Sheets.csv\", index=False, header=False)\n",
        "        print(f\"Saved 'Combined_Left_Sheets.csv' with {len(combined_left)} rows.\")\n",
        "    else:\n",
        "        print(\"No Left sheets extracted.\")\n",
        "\n",
        "    if right_dfs:\n",
        "        combined_right = pd.concat(right_dfs, ignore_index=True)\n",
        "        combined_right.to_csv(\"Combined_Right_Sheets.csv\", index=False, header=False)\n",
        "        print(f\"Saved 'Combined_Right_Sheets.csv' with {len(combined_right)} rows.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_combine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1FvLoci-j9z",
        "outputId": "81269946-7597-473b-f96f-69a565061076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing BEST 2016.xlsx...\n",
            "  -> Added Left Sheet (Headers kept): 3.26Lab\n",
            "  -> Added Right Sheet (Headers kept): 3.27LabGov\n",
            "Processing BEST 2017.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 126.0 133.0 41.0 9.0 133.0 38.0 14.0 494.0\n",
            " 295.0 48.0 214.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 76.66666666666667 96.15384615384616\n",
            " 34.48275862068966 22.22222222222222 66.66666666666666 58.333333333333336\n",
            " 30 61.53846153846154 87.71929824561403 78.57142857142857\n",
            " 85.71428571428571]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet (Rows 1-4 dropped): 3.36LabRegCoun\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): 3.37LabGovtRegCoun\n",
            "Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government and Non-Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 124.0 143.0 49.0 12.0 164.0 45.0 23.0\n",
            " 560.0 301.0 61.0 216.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 5 1 18 5 9 4 5 47 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 5 1 18 5 9 4 5 351 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet (Rows 1-4 dropped): 3.37Lab\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): 3.38LabGov\n",
            "Processing BEST 2019.xlsx...\n",
            "  -> Added Left Sheet (Rows 1-4 dropped): 3.37Lab\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): 3.38LabGov\n",
            "Processing BEST 2020.xlsx...\n",
            "  -> Added Left Sheet (Rows 1-4 dropped): 3.37Lab\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): 3.38LabGov\n",
            "Processing BEST 2021.xlsx...\n",
            "  -> Added Left Sheet (Rows 1-4 dropped): T3.37Lab\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): T3.38LabGov\n",
            "Processing BEST 2022.xlsx...\n",
            "  -> Added Left Sheet (Rows 1-4 dropped): T3.38Lab\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): T3.39LabGov\n",
            "Processing BEST 2023.xlsx...\n",
            "  -> Added Left Sheet (Rows 1-4 dropped): T3.39LabG&NG\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): T3.40LabG\n",
            "Processing BEST 2024.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet (Rows 1-4 dropped): T3.39LabG&NG\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): T3.40LabG\n",
            "Processing BEST 2025.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 87.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Added Left Sheet (Rows 1-4 dropped): T3.40LabG&NG\n",
            "  -> Added Right Sheet (Rows 1-4 dropped): T3.41LabG\n",
            "\n",
            "--- Saving Combined Files ---\n",
            "Saved 'F_Combined_Left_Sheets.csv' with 1840 rows.\n",
            "Saved 'F_Combined_Right_Sheets.csv' with 1840 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-1510879472.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 90.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 1. Cleaning & Helper Functions\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    3. Drop sparse columns.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # \"Grand\" Logic\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # \"Total\" Logic (Region)\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # Sparsity Logic\n",
        "    cols_to_keep = []\n",
        "    threshold = 0.60\n",
        "    for col in df.columns:\n",
        "        is_missing = df[col].isna() | df[col].isin([0, '0', ''])\n",
        "        missing_pct = is_missing.mean()\n",
        "        if missing_pct <= threshold:\n",
        "            cols_to_keep.append(col)\n",
        "    df = df[cols_to_keep]\n",
        "\n",
        "    # Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Main Extraction and Combination Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_and_combine_all():\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # --- DEFINITION: Data Categories and Mappings ---\n",
        "    # NOTE: All keys in the lists below have had spaces REMOVED as per instruction.\n",
        "\n",
        "    # 1. Laboratories\n",
        "    lab_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    # 2. ICT Equipment\n",
        "    # Notes: Spaces removed from \"Table 170\" -> \"Table170\", \"T 3.46 ICT\" -> \"T3.46ICT\" etc.\n",
        "    ict_mapping = {\n",
        "        2017: [\"T3.42ICTAllRegCoun\", \"T3.43ICTGovRegCoun\"],\n",
        "        2018: [\"T2.42_ICT_G&N\", \"T2.43_ICT_G\"],\n",
        "        2019: [\"Table170\", \"Table169\"],\n",
        "        2020: [\"Table147\", \"Table148\"],\n",
        "        2021: [\"Table155\", \"Table156\"],\n",
        "        2022: [\"T2.43_ICT_G&N\", \"T2.44_ICT_G\"],\n",
        "        2023: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2024: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2025: [\"T3.46ICT\", \"T3.47ICT_Gov\"]\n",
        "    }\n",
        "\n",
        "    # Grouping them for processing\n",
        "    tasks = [\n",
        "        (\"Laboratories\", lab_mapping, \"Combined_Laboratories_All_G_NG.csv\", \"Combined_Laboratories_Govt.csv\"),\n",
        "        (\"ICT_Equipment\", ict_mapping, \"Combined_ICT_All_G_NG.csv\", \"Combined_ICT_Govt.csv\")\n",
        "    ]\n",
        "\n",
        "    # --- EXECUTION LOOP ---\n",
        "\n",
        "    for category_name, mapping, left_out, right_out in tasks:\n",
        "        print(f\"\\n=== Starting Extraction for: {category_name} ===\")\n",
        "\n",
        "        left_dfs = []\n",
        "        right_dfs = []\n",
        "\n",
        "        # Track if we have processed the \"first file\" yet for this specific category\n",
        "        processed_first_file = False\n",
        "\n",
        "        # Sort years to ensure chronological order\n",
        "        for year, sheets in sorted(mapping.items()):\n",
        "            filename = f\"BEST {year}.xlsx\"\n",
        "            file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"  Skipping {year}: File not found at {file_path}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  Processing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                xls = pd.ExcelFile(file_path)\n",
        "                available_sheets = xls.sheet_names\n",
        "\n",
        "                # Helper to process a single sheet\n",
        "                def process_sheet_data(sheet_name, is_first_time):\n",
        "                    # Double check if sheet exists, or try matching without case if needed\n",
        "                    if sheet_name in available_sheets:\n",
        "                        # Load & Clean\n",
        "                        df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
        "                        df = normalize_merged_cells(df)\n",
        "                        df = process_council_sheet(df)\n",
        "\n",
        "                        # Add Year\n",
        "                        df.insert(0, 'Source_Year', year)\n",
        "\n",
        "                        # Handle Headers: Drop rows 0-3 (first 4 rows) if NOT the first file\n",
        "                        if not is_first_time:\n",
        "                            df = df.iloc[4:]\n",
        "\n",
        "                        return df\n",
        "                    else:\n",
        "                        print(f\"    [Warning] Sheet '{sheet_name}' missing in {filename}.\")\n",
        "                        return None\n",
        "\n",
        "                # --- EXTRACT LEFT ---\n",
        "                df_left = process_sheet_data(sheets[0], not processed_first_file)\n",
        "                if df_left is not None:\n",
        "                    left_dfs.append(df_left)\n",
        "\n",
        "                # --- EXTRACT RIGHT ---\n",
        "                if len(sheets) > 1:\n",
        "                    df_right = process_sheet_data(sheets[1], not processed_first_file)\n",
        "                    if df_right is not None:\n",
        "                        right_dfs.append(df_right)\n",
        "\n",
        "                # Mark that we have successfully processed at least one file\n",
        "                processed_first_file = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error processing {filename}: {e}\")\n",
        "\n",
        "        # --- SAVE FILES FOR THIS CATEGORY ---\n",
        "        print(f\"  > Saving {category_name} files...\")\n",
        "\n",
        "        if left_dfs:\n",
        "            combined_left = pd.concat(left_dfs, ignore_index=True)\n",
        "            combined_left.to_csv(left_out, index=False, header=False)\n",
        "            print(f\"    -> Created '{left_out}' ({len(combined_left)} rows).\")\n",
        "        else:\n",
        "            print(f\"    -> No Left sheets found for {category_name}.\")\n",
        "\n",
        "        if right_dfs:\n",
        "            combined_right = pd.concat(right_dfs, ignore_index=True)\n",
        "            combined_right.to_csv(right_out, index=False, header=False)\n",
        "            print(f\"    -> Created '{right_out}' ({len(combined_right)} rows).\")\n",
        "\n",
        "    print(\"\\n=== All Tasks Complete ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_combine_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weIh6ZDfqqZg",
        "outputId": "c19f1f2a-8a29-400a-d729-5bde5f0fc81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Extraction for: Laboratories ===\n",
            "  Processing BEST 2016.xlsx...\n",
            "  Processing BEST 2017.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.6923076923077 90.19607843137256 40.625 30\n",
            " 73.68421052631578 61.904761904761905 36.36363636363637 70.08547008547008\n",
            " 89.81481481481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 126.0 133.0 41.0 9.0 133.0 38.0 14.0 494.0\n",
            " 295.0 48.0 214.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 76.66666666666667 96.15384615384616\n",
            " 34.48275862068966 22.22222222222222 66.66666666666666 58.333333333333336\n",
            " 30 61.53846153846154 87.71929824561403 78.57142857142857\n",
            " 85.71428571428571]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government and Non-Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 124.0 143.0 49.0 12.0 164.0 45.0 23.0\n",
            " 560.0 301.0 61.0 216.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 5 1 18 5 9 4 5 47 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 5 1 18 5 9 4 5 351 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2019.xlsx...\n",
            "  Processing BEST 2020.xlsx...\n",
            "  Processing BEST 2021.xlsx...\n",
            "  Processing BEST 2022.xlsx...\n",
            "  Processing BEST 2023.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2024.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 87.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2025.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 90.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > Saving Laboratories files...\n",
            "    -> Created 'Combined_Laboratories_All_G_NG.csv' (1840 rows).\n",
            "    -> Created 'Combined_Laboratories_Govt.csv' (1840 rows).\n",
            "\n",
            "=== Starting Extraction for: ICT_Equipment ===\n",
            "  Processing BEST 2017.xlsx...\n",
            "  Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:33: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  subset = subset.ffill(axis=1)\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan 'Primary Education'\n",
            " 'Table 2.43: Number of ICT Equipments  in Government Schools by Type, Region and Council, 2018'\n",
            " 'Radio' 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2019.xlsx...\n",
            "  Processing BEST 2020.xlsx...\n",
            "  Processing BEST 2021.xlsx...\n",
            "  Processing BEST 2022.xlsx...\n",
            "  Processing BEST 2023.xlsx...\n",
            "  Processing BEST 2024.xlsx...\n",
            "  Processing BEST 2025.xlsx...\n",
            "  > Saving ICT_Equipment files...\n",
            "    -> Created 'Combined_ICT_All_G_NG.csv' (1657 rows).\n",
            "    -> Created 'Combined_ICT_Govt.csv' (1650 rows).\n",
            "\n",
            "=== All Tasks Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# ==========================================\n",
        "# 1. Cleaning & Helper Functions\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    3. Drop sparse columns.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # \"Grand\" Logic\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # \"Total\" Logic (Region)\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # Sparsity Logic\n",
        "    cols_to_keep = []\n",
        "    threshold = 0.60\n",
        "    for col in df.columns:\n",
        "        is_missing = df[col].isna() | df[col].isin([0, '0', ''])\n",
        "        missing_pct = is_missing.mean()\n",
        "        if missing_pct <= threshold:\n",
        "            cols_to_keep.append(col)\n",
        "    df = df[cols_to_keep]\n",
        "\n",
        "    # Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Main Extraction and Combination Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_and_combine_all():\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # --- DEFINITION: Data Categories and Mappings ---\n",
        "    # NOTE: All keys in the lists below have had spaces REMOVED as per instruction.\n",
        "\n",
        "    # 1. Laboratories\n",
        "    lab_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    # 2. ICT Equipment\n",
        "    # Notes: Spaces removed from \"Table 170\" -> \"Table170\", \"T 3.46 ICT\" -> \"T3.46ICT\" etc.\n",
        "    ict_mapping = {\n",
        "        2017: [\"T3.42ICTAllRegCoun\", \"T3.43ICTGovRegCoun\"],\n",
        "        2018: [\"T2.42_ICT_G&N\", \"T2.43_ICT_G\"],\n",
        "        2019: [\"Table170\", \"Table169\"],\n",
        "        2020: [\"Table147\", \"Table148\"],\n",
        "        2021: [\"Table155\", \"Table156\"],\n",
        "        2022: [\"T2.43_ICT_G&N\", \"T2.44_ICT_G\"],\n",
        "        2023: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2024: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2025: [\"T3.46ICT\", \"T3.47ICT_Gov\"]\n",
        "    }\n",
        "\n",
        "    # Grouping them for processing\n",
        "    tasks = [\n",
        "        (\"Laboratories\", lab_mapping, \"Combined_Laboratories_All_G_NG.csv\", \"Combined_Laboratories_Govt.csv\"),\n",
        "        (\"ICT_Equipment\", ict_mapping, \"Combined_ICT_All_G_NG.csv\", \"Combined_ICT_Govt.csv\")\n",
        "    ]\n",
        "\n",
        "    # --- EXECUTION LOOP ---\n",
        "\n",
        "    for category_name, mapping, left_out, right_out in tasks:\n",
        "        print(f\"\\n=== Starting Extraction for: {category_name} ===\")\n",
        "\n",
        "        left_dfs = []\n",
        "        right_dfs = []\n",
        "\n",
        "        # Track if we have processed the \"first file\" yet for this specific category\n",
        "        processed_first_file = False\n",
        "\n",
        "        # Sort years to ensure chronological order\n",
        "        for year, sheets in sorted(mapping.items()):\n",
        "            filename = f\"BEST {year}.xlsx\"\n",
        "            file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"  Skipping {year}: File not found at {file_path}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  Processing {filename}...\")\n",
        "\n",
        "            try:\n",
        "                xls = pd.ExcelFile(file_path)\n",
        "                available_sheets = xls.sheet_names\n",
        "\n",
        "                # Helper to process a single sheet\n",
        "                def process_sheet_data(sheet_name, is_first_time):\n",
        "                    # Double check if sheet exists, or try matching without case if needed\n",
        "                    if sheet_name in available_sheets:\n",
        "                        # Load & Clean\n",
        "                        df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
        "                        df = normalize_merged_cells(df)\n",
        "                        df = process_council_sheet(df)\n",
        "\n",
        "                        # Add Year\n",
        "                        df.insert(0, 'Source_Year', year)\n",
        "\n",
        "                        # Handle Headers: Drop rows 0-3 (first 4 rows) if NOT the first file\n",
        "                        if not is_first_time:\n",
        "                            df = df.iloc[4:]\n",
        "\n",
        "                        return df\n",
        "                    else:\n",
        "                        print(f\"    [Warning] Sheet '{sheet_name}' missing in {filename}.\")\n",
        "                        return None\n",
        "\n",
        "                # --- EXTRACT LEFT ---\n",
        "                df_left = process_sheet_data(sheets[0], not processed_first_file)\n",
        "                if df_left is not None:\n",
        "                    left_dfs.append(df_left)\n",
        "\n",
        "                # --- EXTRACT RIGHT ---\n",
        "                if len(sheets) > 1:\n",
        "                    df_right = process_sheet_data(sheets[1], not processed_first_file)\n",
        "                    if df_right is not None:\n",
        "                        right_dfs.append(df_right)\n",
        "\n",
        "                # Mark that we have successfully processed at least one file\n",
        "                processed_first_file = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error processing {filename}: {e}\")\n",
        "\n",
        "        # --- SAVE FILES FOR THIS CATEGORY ---\n",
        "        print(f\"  > Saving {category_name} files...\")\n",
        "\n",
        "        if left_dfs:\n",
        "            combined_left = pd.concat(left_dfs, ignore_index=True)\n",
        "            combined_left.to_csv(left_out, index=False, header=False)\n",
        "            print(f\"    -> Created '{left_out}' ({len(combined_left)} rows).\")\n",
        "        else:\n",
        "            print(f\"    -> No Left sheets found for {category_name}.\")\n",
        "\n",
        "        if right_dfs:\n",
        "            combined_right = pd.concat(right_dfs, ignore_index=True)\n",
        "            combined_right.to_csv(right_out, index=False, header=False)\n",
        "            print(f\"    -> Created '{right_out}' ({len(combined_right)} rows).\")\n",
        "\n",
        "    print(\"\\n=== All Tasks Complete ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_combine_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GURr5rRT52CO",
        "outputId": "a1f0f55b-7e6a-4f04-df52-11ed928e6d0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Extraction for: Laboratories ===\n",
            "  Processing BEST 2016.xlsx...\n",
            "  Processing BEST 2017.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.69230769 90.19607843 40.625 30 73.68421053\n",
            " 61.9047619 36.36363636 70.08547009 89.81481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 82.69230769 90.19607843 40.625 30 73.68421053\n",
            " 61.9047619 36.36363636 70.08547009 89.81481481 80 87.5]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.36: Number of Laboratories in Government and Non Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 126.0 133.0 41.0 9.0 133.0 38.0 14.0 494.0\n",
            " 295.0 48.0 214.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government Schools, 2017'\n",
            " '% of Available' 'SHORTAGE' 76.66666667 96.15384615 34.48275862\n",
            " 22.22222222 66.66666667 58.33333333 30 61.53846154 87.71929825\n",
            " 78.57142857 85.71428571]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.37: Number of Laboratories in Government and Non-Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 124.0 143.0 49.0 12.0 164.0 45.0 23.0\n",
            " 560.0 301.0 61.0 216.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 5 1 18 5 9 4 5 47 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.38: Number of Laboratories in Government Schools, 2018'\n",
            " 'PHYSICS LABORATORIES' 'council' 5 1 18 5 9 4 5 351 -1 0 3]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2019.xlsx...\n",
            "  Processing BEST 2020.xlsx...\n",
            "  Processing BEST 2021.xlsx...\n",
            "  Processing BEST 2022.xlsx...\n",
            "  Processing BEST 2023.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2023'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 58 25 3 13]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2024.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.40: Number of Science Laboratories in Government Schools, 2024'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 87.0 5.0 6.0 7.0 8.0 9.0 1 56 16 3 8]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2025.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 4.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Secondary Education'\n",
            " 'Table 3.41: Number of Science Laboratories in Government Schools, 2025'\n",
            " 'PHYSICS LABORATORIES' 'SHORTAGE' 90.0 5.0 6.0 7.0 8.0 9.0 3 62 22 7 9]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > Saving Laboratories files...\n",
            "    -> Created 'Combined_Laboratories_All_G_NG.csv' (1840 rows).\n",
            "    -> Created 'Combined_Laboratories_Govt.csv' (1840 rows).\n",
            "\n",
            "=== Starting Extraction for: ICT_Equipment ===\n",
            "  Processing BEST 2017.xlsx...\n",
            "  Processing BEST 2018.xlsx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2832236850.py:33: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  subset = subset.ffill(axis=1)\n",
            "/tmp/ipython-input-2832236850.py:36: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan 'Primary Education'\n",
            " 'Table 2.43: Number of ICT Equipments  in Government Schools by Type, Region and Council, 2018'\n",
            " 'Radio' 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.iloc[:limit] = subset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processing BEST 2019.xlsx...\n",
            "  Processing BEST 2020.xlsx...\n",
            "  Processing BEST 2021.xlsx...\n",
            "  Processing BEST 2022.xlsx...\n",
            "  Processing BEST 2023.xlsx...\n",
            "  Processing BEST 2024.xlsx...\n",
            "  Processing BEST 2025.xlsx...\n",
            "  > Saving ICT_Equipment files...\n",
            "    -> Created 'Combined_ICT_All_G_NG.csv' (1657 rows).\n",
            "    -> Created 'Combined_ICT_Govt.csv' (1654 rows).\n",
            "\n",
            "=== All Tasks Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# ==========================================\n",
        "# 0. Setup: Block Warnings\n",
        "# ==========================================\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. Cleaning & Helper Functions\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    (Sparsity and Row checks are now moved to the final stage)\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # \"Grand\" Logic\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # \"Total\" Logic (Region)\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "def row_has_numeric(series):\n",
        "    \"\"\"Returns True if the row contains any numeric value.\"\"\"\n",
        "    for val in series:\n",
        "        if isinstance(val, (int, float)) and not isinstance(val, bool):\n",
        "            return True\n",
        "        if isinstance(val, str):\n",
        "            s = val.strip().replace(',', '')\n",
        "            if s.replace('.', '', 1).isdigit():\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def perform_final_cleanup(df):\n",
        "    \"\"\"\n",
        "    Executes the final requested operations:\n",
        "    1. Delete rows with only 1 cell of value (excluding the Source_Year column).\n",
        "    2. Delete columns with >15% empty cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # --- 1. ROW CLEANUP ---\n",
        "    # We check non-null count on all columns EXCEPT 'Source_Year'\n",
        "    # If a row has <= 1 valid data cell, we drop it.\n",
        "    cols_to_check = [c for c in df.columns if c != 'Source_Year']\n",
        "\n",
        "    # Calculate non-nulls row-wise for data columns\n",
        "    # We treat empty strings '' as Null here just in case\n",
        "    temp_df = df[cols_to_check].replace('', None)\n",
        "    row_counts = temp_df.notna().sum(axis=1)\n",
        "\n",
        "    # Keep rows where we have MORE than 1 data value\n",
        "    initial_rows = len(df)\n",
        "    df = df[row_counts > 1]\n",
        "    dropped_rows = initial_rows - len(df)\n",
        "    if dropped_rows > 0:\n",
        "        print(f\"    (Cleaned {dropped_rows} rows having <= 1 data value)\")\n",
        "\n",
        "    # --- 2. COLUMN SPARSITY (15% Threshold) ---\n",
        "    # Remove columns which have MORE than 15% empty cells\n",
        "    threshold = 0.15\n",
        "    initial_cols = len(df.columns)\n",
        "\n",
        "    # Calculate null percentage\n",
        "    # We treat 0 and '0' as valid values here? Usually yes, 0 is data.\n",
        "    # But often empty strings are loaded as objects. Let's stick to standard NaNs/None.\n",
        "    # If you consider '0' as empty, uncomment the replacement line below.\n",
        "    # df_check = df.replace({0: None, '0': None, '': None})\n",
        "\n",
        "    missing_pct = df.isna().mean()\n",
        "    cols_to_keep = missing_pct[missing_pct <= threshold].index\n",
        "\n",
        "    df = df[cols_to_keep]\n",
        "    dropped_cols = initial_cols - len(df.columns)\n",
        "    if dropped_cols > 0:\n",
        "        print(f\"    (Dropped {dropped_cols} columns with >15% empty cells)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Main Extraction and Combination Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_and_combine_all():\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # --- DEFINITION: Data Categories and Mappings ---\n",
        "\n",
        "    # 1. Laboratories\n",
        "    lab_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    # 2. ICT Equipment\n",
        "    ict_mapping = {\n",
        "        2017: [\"T3.42ICTAllRegCoun\", \"T3.43ICTGovRegCoun\"],\n",
        "        2018: [\"T2.42_ICT_G&N\", \"T2.43_ICT_G\"],\n",
        "        2019: [\"Table170\", \"Table169\"],\n",
        "        2020: [\"Table147\", \"Table148\"],\n",
        "        2021: [\"Table155\", \"Table156\"],\n",
        "        2022: [\"T2.43_ICT_G&N\", \"T2.44_ICT_G\"],\n",
        "        2023: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2024: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2025: [\"T3.46ICT\", \"T3.47ICT_Gov\"]\n",
        "    }\n",
        "\n",
        "    # 3. Electricity\n",
        "    elec_mapping = {\n",
        "        2017: [\"T3.40SchElecAllRegCoun\", \"T3.41SchElecGovRegCoun\"],\n",
        "        2018: [\"T2.44_Elect_G&N\", \"T2.45_Elect_G\"],\n",
        "        2019: [\"Table165\", \"Table167\"],\n",
        "        2020: [\"Table145\", \"Table146\"],\n",
        "        2021: [\"Table152\", \"Table153\"],\n",
        "        2022: [\"T2.41_Elect_G&N\", \"T2.42_Elect_G\"],\n",
        "        2023: [\"T2.42_Elect_G&N\", \"T2.43_Elect_G\"],\n",
        "        2024: [\"T2.42_Elect_G&N\", \"T2.43_Elect_G\"],\n",
        "        2025: [\"T2.42_Elect_G&N\", \"T2.43_Elect_G\"]\n",
        "    }\n",
        "\n",
        "    tasks = [\n",
        "        (\"Laboratories\", lab_mapping, \"Combined_Laboratories_All_G_NG.csv\", \"Combined_Laboratories_Govt.csv\"),\n",
        "        (\"ICT_Equipment\", ict_mapping, \"Combined_ICT_All_G_NG.csv\", \"Combined_ICT_Govt.csv\"),\n",
        "        (\"Electricity\", elec_mapping, \"Combined_Electricity_All_G_NG.csv\", \"Combined_Electricity_Govt.csv\")\n",
        "    ]\n",
        "\n",
        "    for category_name, mapping, left_out, right_out in tasks:\n",
        "        print(f\"\\n=======================================================\")\n",
        "        print(f\" PROCESSING CATEGORY: {category_name}\")\n",
        "        print(f\"=======================================================\")\n",
        "\n",
        "        left_dfs = []\n",
        "        right_dfs = []\n",
        "\n",
        "        processed_first_file = False\n",
        "\n",
        "        for year, sheets in sorted(mapping.items()):\n",
        "            filename = f\"BEST {year}.xlsx\"\n",
        "            file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"Year {year}: File not found ({filename})\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                xls = pd.ExcelFile(file_path)\n",
        "                available_sheets = xls.sheet_names\n",
        "\n",
        "                # Normalize sheet names for robust lookup (ignore spaces)\n",
        "                normalized_lookup = {s.replace(\" \", \"\"): s for s in available_sheets}\n",
        "\n",
        "                # Helper to process a single sheet\n",
        "                def process_sheet_data(target_name_clean, is_first_time):\n",
        "                    if target_name_clean in normalized_lookup:\n",
        "                        real_sheet_name = normalized_lookup[target_name_clean]\n",
        "\n",
        "                        # Load & Clean\n",
        "                        df = pd.read_excel(xls, sheet_name=real_sheet_name, header=None)\n",
        "                        df = normalize_merged_cells(df)\n",
        "                        df = process_council_sheet(df)\n",
        "\n",
        "                        # --- SMART ROW DELETION (Before adding Year) ---\n",
        "                        status_suffix = \"\"\n",
        "                        if not is_first_time:\n",
        "                            check_limit = min(4, len(df))\n",
        "                            top_slice = df.iloc[:check_limit]\n",
        "                            rest_slice = df.iloc[check_limit:]\n",
        "\n",
        "                            rows_to_keep = []\n",
        "                            for idx in range(len(top_slice)):\n",
        "                                row_data = top_slice.iloc[idx]\n",
        "                                if row_has_numeric(row_data):\n",
        "                                    rows_to_keep.append(top_slice.iloc[[idx]])\n",
        "\n",
        "                            if rows_to_keep:\n",
        "                                df = pd.concat(rows_to_keep + [rest_slice])\n",
        "                                dropped_count = check_limit - len(rows_to_keep)\n",
        "                                status_suffix = f\"(Dropped {dropped_count} header rows, kept {len(rows_to_keep)} numeric rows)\"\n",
        "                            else:\n",
        "                                df = rest_slice\n",
        "                                status_suffix = f\"(Dropped top {check_limit} header rows)\"\n",
        "                        else:\n",
        "                            status_suffix = \"(First file: All rows kept)\"\n",
        "\n",
        "                        # --- ADD YEAR COLUMN ---\n",
        "                        df.insert(0, 'Source_Year', year)\n",
        "\n",
        "                        print(f\"  {year}: [FOUND] '{real_sheet_name}' {status_suffix}\")\n",
        "                        return df\n",
        "                    else:\n",
        "                        print(f\"  {year}: [MISSING] '{target_name_clean}'\")\n",
        "                        return None\n",
        "\n",
        "                # --- EXTRACT LEFT ---\n",
        "                df_left = process_sheet_data(sheets[0], not processed_first_file)\n",
        "                if df_left is not None:\n",
        "                    left_dfs.append(df_left)\n",
        "\n",
        "                # --- EXTRACT RIGHT ---\n",
        "                if len(sheets) > 1:\n",
        "                    df_right = process_sheet_data(sheets[1], not processed_first_file)\n",
        "                    if df_right is not None:\n",
        "                        right_dfs.append(df_right)\n",
        "\n",
        "                # Mark success\n",
        "                if df_left is not None or (len(sheets) > 1 and df_right is not None):\n",
        "                    processed_first_file = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  {year}: [ERROR] Processing file: {e}\")\n",
        "\n",
        "        # --- SAVE FILES FOR THIS CATEGORY ---\n",
        "        print(f\"\\n--- Finalizing & Saving {category_name} ---\")\n",
        "\n",
        "        if left_dfs:\n",
        "            combined_left = pd.concat(left_dfs, ignore_index=True)\n",
        "            # PERFORM FINAL CLEANUP\n",
        "            combined_left = perform_final_cleanup(combined_left)\n",
        "            combined_left.to_csv(left_out, index=False, header=False)\n",
        "            print(f\"  -> Saved '{left_out}' ({len(combined_left)} rows)\")\n",
        "        else:\n",
        "            print(f\"  -> No data for '{left_out}'\")\n",
        "\n",
        "        if right_dfs:\n",
        "            combined_right = pd.concat(right_dfs, ignore_index=True)\n",
        "            # PERFORM FINAL CLEANUP\n",
        "            combined_right = perform_final_cleanup(combined_right)\n",
        "            combined_right.to_csv(right_out, index=False, header=False)\n",
        "            print(f\"  -> Saved '{right_out}' ({len(combined_right)} rows)\")\n",
        "\n",
        "    print(\"\\n=== All Tasks Complete ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_combine_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbn1Jo4W7JlL",
        "outputId": "7812053f-035b-4683-a798-0bc6603f6e2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================================\n",
            " PROCESSING CATEGORY: Laboratories\n",
            "=======================================================\n",
            "  2016: [FOUND] '3.26Lab' (First file: All rows kept)\n",
            "  2016: [FOUND] '3.27LabGov' (First file: All rows kept)\n",
            "  2017: [FOUND] '3.36LabRegCoun' (Dropped top 4 header rows)\n",
            "  2017: [FOUND] '3.37LabGovtRegCoun' (Dropped top 4 header rows)\n",
            "  2018: [FOUND] '3.37Lab' (Dropped top 4 header rows)\n",
            "  2018: [FOUND] '3.38LabGov' (Dropped top 4 header rows)\n",
            "  2019: [FOUND] '3.37Lab' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2019: [FOUND] '3.38LabGov' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2020: [FOUND] '3.37Lab' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2020: [FOUND] '3.38LabGov' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2021: [FOUND] 'T3.37Lab' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2021: [FOUND] 'T3.38LabGov' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2022: [FOUND] 'T3.38Lab' (Dropped top 4 header rows)\n",
            "  2022: [FOUND] 'T3.39LabGov' (Dropped top 4 header rows)\n",
            "  2023: [FOUND] 'T3.39LabG&NG' (Dropped top 4 header rows)\n",
            "  2023: [FOUND] 'T3.40LabG' (Dropped top 4 header rows)\n",
            "  2024: [FOUND] 'T3.39LabG&NG' (Dropped top 4 header rows)\n",
            "  2024: [FOUND] 'T3.40LabG' (Dropped top 4 header rows)\n",
            "  2025: [FOUND] 'T3.40LabG&NG' (Dropped top 4 header rows)\n",
            "  2025: [FOUND] 'T3.41LabG' (Dropped top 4 header rows)\n",
            "\n",
            "--- Finalizing & Saving Laboratories ---\n",
            "    (Cleaned 6 rows having <= 1 data value)\n",
            "    (Dropped 5 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_Laboratories_All_G_NG.csv' (1840 rows)\n",
            "    (Cleaned 6 rows having <= 1 data value)\n",
            "    (Dropped 4 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_Laboratories_Govt.csv' (1840 rows)\n",
            "\n",
            "=======================================================\n",
            " PROCESSING CATEGORY: ICT_Equipment\n",
            "=======================================================\n",
            "  2017: [FOUND] 'T3.42ICTAllRegCoun' (First file: All rows kept)\n",
            "  2017: [FOUND] 'T3.43ICTGovRegCoun' (First file: All rows kept)\n",
            "  2018: [FOUND] 'T2.42_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2018: [FOUND] 'T2.43_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2019: [FOUND] 'Table170' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2019: [FOUND] 'Table169' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2020: [FOUND] 'Table147' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2020: [FOUND] 'Table148' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2021: [FOUND] 'Table155' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2021: [FOUND] 'Table156' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2022: [FOUND] 'T2.43_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2022: [FOUND] 'T2.44_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2023: [FOUND] 'T2.44_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2023: [FOUND] 'T2.45_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2024: [FOUND] 'T2.44_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2024: [FOUND] 'T2.45_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2025: [FOUND] 'T3.46ICT' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2025: [FOUND] 'T3.47ICT_Gov' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "\n",
            "--- Finalizing & Saving ICT_Equipment ---\n",
            "    (Cleaned 13 rows having <= 1 data value)\n",
            "    (Dropped 4 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_ICT_All_G_NG.csv' (1658 rows)\n",
            "    (Cleaned 13 rows having <= 1 data value)\n",
            "    (Dropped 4 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_ICT_Govt.csv' (1658 rows)\n",
            "\n",
            "=======================================================\n",
            " PROCESSING CATEGORY: Electricity\n",
            "=======================================================\n",
            "  2017: [FOUND] 'T3.40SchElecAllRegCoun' (First file: All rows kept)\n",
            "  2017: [FOUND] 'T3.41SchElecGovRegCoun' (First file: All rows kept)\n",
            "  2018: [FOUND] 'T2.44_Elect_G&N' (Dropped top 4 header rows)\n",
            "  2018: [FOUND] 'T2.45_Elect_G' (Dropped top 4 header rows)\n",
            "  2019: [FOUND] 'Table165' (Dropped 0 header rows, kept 4 numeric rows)\n",
            "  2019: [FOUND] 'Table167' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2020: [FOUND] 'Table145' (Dropped 0 header rows, kept 4 numeric rows)\n",
            "  2020: [FOUND] 'Table146' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2021: [FOUND] 'Table152' (Dropped 0 header rows, kept 4 numeric rows)\n",
            "  2021: [FOUND] 'Table153' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2022: [FOUND] 'T2.41_Elect_G&N' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2022: [FOUND] 'T2.42_Elect_G' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2023: [FOUND] 'T2.42_Elect_G&N' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2023: [FOUND] 'T2.43_Elect_G' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2024: [FOUND] 'T2.42_Elect_G&N' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2024: [FOUND] 'T2.43_Elect_G' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2025: [FOUND] 'T2.42_Elect_G&N' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2025: [FOUND] 'T2.43_Elect_G' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "\n",
            "--- Finalizing & Saving Electricity ---\n",
            "    (Cleaned 7 rows having <= 1 data value)\n",
            "    (Dropped 5 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_Electricity_All_G_NG.csv' (1658 rows)\n",
            "    (Cleaned 6 rows having <= 1 data value)\n",
            "    (Dropped 5 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_Electricity_Govt.csv' (1660 rows)\n",
            "\n",
            "=== All Tasks Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# ==========================================\n",
        "# 0. Setup: Block Warnings\n",
        "# ==========================================\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. Cleaning & Helper Functions\n",
        "# ==========================================\n",
        "\n",
        "def is_valid_text(value):\n",
        "    \"\"\"Checks if the value is Alphabetic or Alphanumeric.\"\"\"\n",
        "    s_val = str(value).strip()\n",
        "    if not s_val:\n",
        "        return False\n",
        "    clean_val = s_val.replace(\" \", \"\")\n",
        "    if clean_val.isalnum():\n",
        "        return True\n",
        "    if re.search(r'[a-zA-Z]', s_val):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_merged_cells(df, header_rows=15):\n",
        "    \"\"\"\n",
        "    Handles merged columns/rows in the header/label area.\n",
        "    Duplicates text horizontally and vertically for merged cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    limit = min(header_rows, len(df))\n",
        "    subset = df.iloc[:limit].copy()\n",
        "\n",
        "    # Forward fill horizontally and vertically\n",
        "    subset = subset.ffill(axis=1)\n",
        "    subset = subset.ffill(axis=0)\n",
        "\n",
        "    df.iloc[:limit] = subset\n",
        "    return df\n",
        "\n",
        "def process_council_sheet(df):\n",
        "    \"\"\"\n",
        "    Applies specific cleaning steps:\n",
        "    1. Populate structural columns downwards.\n",
        "    2. Remove 'Grand' and 'Total' rows.\n",
        "    (Sparsity and Row checks are now moved to the final stage)\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Identify Region Column\n",
        "    region_col = None\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if \"region\" in val or \"mkoa\" in val:\n",
        "                region_col = col\n",
        "                break\n",
        "        if region_col is not None:\n",
        "            break\n",
        "\n",
        "    if region_col is None and not df.empty:\n",
        "        region_col = df.columns[0]\n",
        "\n",
        "    # Populate Columns Downwards (Unmerge Vertical for structural cols)\n",
        "    cols_to_fill = list(df.columns[:3])\n",
        "    if region_col is not None and region_col not in cols_to_fill:\n",
        "        cols_to_fill.append(region_col)\n",
        "\n",
        "    for col in cols_to_fill:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].replace({0: None, '0': None})\n",
        "            df[col] = df[col].ffill()\n",
        "\n",
        "    # \"Grand\" Logic\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        grand_mask = df[region_col].astype(str).str.contains(\"Grand\", case=False, na=False)\n",
        "        if grand_mask.any():\n",
        "            cutoff_idx = grand_mask.idxmax()\n",
        "            df = df.loc[:cutoff_idx-1]\n",
        "\n",
        "    # \"Total\" Logic (Region)\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        total_mask = df[region_col].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "        df = df[~total_mask]\n",
        "\n",
        "    # \"Total\" Logic (Council)\n",
        "    council_col = None\n",
        "    council_keywords = ['council', 'halmashauri', 'district', 'lga', 'wilaya', 'municipal', 'town council']\n",
        "\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        for col in df.columns:\n",
        "            val = str(row[col]).lower()\n",
        "            if any(kw in val for kw in council_keywords):\n",
        "                council_col = col\n",
        "                break\n",
        "        if council_col is not None:\n",
        "            break\n",
        "\n",
        "    if council_col is not None and council_col in df.columns:\n",
        "        pat = \"Total|Sub-Total|Sub Total\"\n",
        "        council_total_mask = df[council_col].astype(str).str.contains(pat, case=False, na=False)\n",
        "        df = df[~council_total_mask]\n",
        "\n",
        "    # Final Cleanup: Remove rows with \"Total\" in first few columns\n",
        "    target_indices = [0, 1, 2]\n",
        "    for idx in target_indices:\n",
        "        if idx < len(df.columns):\n",
        "            col_name = df.columns[idx]\n",
        "            mask = df[col_name].astype(str).str.contains(\"Total\", case=False, na=False)\n",
        "            df = df[~mask]\n",
        "\n",
        "    # Duplicate Region Column Check\n",
        "    if region_col is not None and region_col in df.columns:\n",
        "        cols_to_drop = []\n",
        "        for col in df.columns:\n",
        "            if col == region_col: continue\n",
        "            if df[col].equals(df[region_col]):\n",
        "                cols_to_drop.append(col)\n",
        "        if cols_to_drop:\n",
        "            df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    return df\n",
        "\n",
        "def row_has_numeric(series):\n",
        "    \"\"\"Returns True if the row contains any numeric value.\"\"\"\n",
        "    for val in series:\n",
        "        if isinstance(val, (int, float)) and not isinstance(val, bool):\n",
        "            return True\n",
        "        if isinstance(val, str):\n",
        "            s = val.strip().replace(',', '')\n",
        "            if s.replace('.', '', 1).isdigit():\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def perform_final_cleanup(df):\n",
        "    \"\"\"\n",
        "    Executes the final requested operations:\n",
        "    1. Delete rows with only 1 cell of value (excluding the Source_Year column).\n",
        "    2. Delete columns with >15% empty cells.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # --- 1. ROW CLEANUP ---\n",
        "    # We check non-null count on all columns EXCEPT 'Source_Year'\n",
        "    # If a row has <= 1 valid data cell, we drop it.\n",
        "    cols_to_check = [c for c in df.columns if c != 'Source_Year']\n",
        "\n",
        "    # Calculate non-nulls row-wise for data columns\n",
        "    # We treat empty strings '' as Null here just in case\n",
        "    temp_df = df[cols_to_check].replace('', None)\n",
        "    row_counts = temp_df.notna().sum(axis=1)\n",
        "\n",
        "    # Keep rows where we have MORE than 1 data value\n",
        "    initial_rows = len(df)\n",
        "    df = df[row_counts > 1]\n",
        "    dropped_rows = initial_rows - len(df)\n",
        "    if dropped_rows > 0:\n",
        "        print(f\"    (Cleaned {dropped_rows} rows having <= 1 data value)\")\n",
        "\n",
        "    # --- 2. COLUMN SPARSITY (15% Threshold) ---\n",
        "    # Remove columns which have MORE than 15% empty cells\n",
        "    threshold = 0.15\n",
        "    initial_cols = len(df.columns)\n",
        "\n",
        "    # Calculate null percentage\n",
        "    # We treat 0 and '0' as valid values here? Usually yes, 0 is data.\n",
        "    # But often empty strings are loaded as objects. Let's stick to standard NaNs/None.\n",
        "    # If you consider '0' as empty, uncomment the replacement line below.\n",
        "    # df_check = df.replace({0: None, '0': None, '': None})\n",
        "\n",
        "    missing_pct = df.isna().mean()\n",
        "    cols_to_keep = missing_pct[missing_pct <= threshold].index\n",
        "\n",
        "    df = df[cols_to_keep]\n",
        "    dropped_cols = initial_cols - len(df.columns)\n",
        "    if dropped_cols > 0:\n",
        "        print(f\"    (Dropped {dropped_cols} columns with >15% empty cells)\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. Main Extraction and Combination Logic\n",
        "# ==========================================\n",
        "\n",
        "def extract_and_combine_all():\n",
        "    base_dir = \"/content/drive/MyDrive/BEST\"\n",
        "\n",
        "    # --- DEFINITION: Data Categories and Mappings ---\n",
        "\n",
        "    # 1. Laboratories\n",
        "    lab_mapping = {\n",
        "        2016: [\"3.26Lab\", \"3.27LabGov\"],\n",
        "        2017: [\"3.36LabRegCoun\", \"3.37LabGovtRegCoun\"],\n",
        "        2018: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2019: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2020: [\"3.37Lab\", \"3.38LabGov\"],\n",
        "        2021: [\"T3.37Lab\", \"T3.38LabGov\"],\n",
        "        2022: [\"T3.38Lab\", \"T3.39LabGov\"],\n",
        "        2023: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2024: [\"T3.39LabG&NG\", \"T3.40LabG\"],\n",
        "        2025: [\"T3.40LabG&NG\", \"T3.41LabG\"]\n",
        "    }\n",
        "\n",
        "    # 2. ICT Equipment\n",
        "    ict_mapping = {\n",
        "        2017: [\"T3.42ICTAllRegCoun\", \"T3.43ICTGovRegCoun\"],\n",
        "        2018: [\"T2.42_ICT_G&N\", \"T2.43_ICT_G\"],\n",
        "        2019: [\"Table170\", \"Table169\"],\n",
        "        2020: [\"Table147\", \"Table148\"],\n",
        "        2021: [\"Table155\", \"Table156\"],\n",
        "        2022: [\"T2.43_ICT_G&N\", \"T2.44_ICT_G\"],\n",
        "        2023: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2024: [\"T2.44_ICT_G&N\", \"T2.45_ICT_G\"],\n",
        "        2025: [\"T3.46ICT\", \"T3.47ICT_Gov\"]\n",
        "    }\n",
        "\n",
        "    # 3. Electricity\n",
        "    elec_mapping = {\n",
        "        2017: [\"T3.40SchElecAllRegCoun\", \"T3.41SchElecGovRegCoun\"],\n",
        "        2018: [\"T2.44_Elect_G&N\", \"T2.45_Elect_G\"],\n",
        "        2019: [\"Table165\", \"Table167\"],\n",
        "        2020: [\"Table145\", \"Table146\"],\n",
        "        2021: [\"Table152\", \"Table153\"],\n",
        "        2022: [\"T2.41_Elect_G&N\", \"T2.42_Elect_G\"],\n",
        "        2023: [\"T2.42_Elect_G&N\", \"T2.43_Elect_G\"],\n",
        "        2024: [\"T2.42_Elect_G&N\", \"T2.43_Elect_G\"],\n",
        "        2025: [\"T2.42_Elect_G&N\", \"T2.43_Elect_G\"]\n",
        "    }\n",
        "\n",
        "    tasks = [\n",
        "        (\"Laboratories\", lab_mapping, \"Combined_Laboratories_All_G_NG.csv\", \"Combined_Laboratories_Govt.csv\"),\n",
        "        (\"ICT_Equipment\", ict_mapping, \"Combined_ICT_All_G_NG.csv\", \"Combined_ICT_Govt.csv\"),\n",
        "        (\"Electricity\", elec_mapping, \"Combined_Electricity_All_G_NG.csv\", \"Combined_Electricity_Govt.csv\")\n",
        "    ]\n",
        "\n",
        "    for category_name, mapping, left_out, right_out in tasks:\n",
        "        print(f\"\\n=======================================================\")\n",
        "        print(f\" PROCESSING CATEGORY: {category_name}\")\n",
        "        print(f\"=======================================================\")\n",
        "\n",
        "        left_dfs = []\n",
        "        right_dfs = []\n",
        "\n",
        "        processed_first_file = False\n",
        "\n",
        "        for year, sheets in sorted(mapping.items()):\n",
        "            filename = f\"BEST {year}.xlsx\"\n",
        "            file_path = os.path.join(base_dir, filename)\n",
        "\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"Year {year}: File not found ({filename})\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                xls = pd.ExcelFile(file_path)\n",
        "                available_sheets = xls.sheet_names\n",
        "\n",
        "                # Normalize sheet names for robust lookup (ignore spaces)\n",
        "                normalized_lookup = {s.replace(\" \", \"\"): s for s in available_sheets}\n",
        "\n",
        "                # Helper to process a single sheet\n",
        "                def process_sheet_data(target_name_clean, is_first_time):\n",
        "                    if target_name_clean in normalized_lookup:\n",
        "                        real_sheet_name = normalized_lookup[target_name_clean]\n",
        "\n",
        "                        # Load & Clean\n",
        "                        df = pd.read_excel(xls, sheet_name=real_sheet_name, header=None)\n",
        "                        df = normalize_merged_cells(df)\n",
        "                        df = process_council_sheet(df)\n",
        "\n",
        "                        # --- SMART ROW DELETION (Before adding Year) ---\n",
        "                        status_suffix = \"\"\n",
        "                        if not is_first_time:\n",
        "                            check_limit = min(4, len(df))\n",
        "                            top_slice = df.iloc[:check_limit]\n",
        "                            rest_slice = df.iloc[check_limit:]\n",
        "\n",
        "                            rows_to_keep = []\n",
        "                            for idx in range(len(top_slice)):\n",
        "                                row_data = top_slice.iloc[idx]\n",
        "                                if row_has_numeric(row_data):\n",
        "                                    rows_to_keep.append(top_slice.iloc[[idx]])\n",
        "\n",
        "                            if rows_to_keep:\n",
        "                                df = pd.concat(rows_to_keep + [rest_slice])\n",
        "                                dropped_count = check_limit - len(rows_to_keep)\n",
        "                                status_suffix = f\"(Dropped {dropped_count} header rows, kept {len(rows_to_keep)} numeric rows)\"\n",
        "                            else:\n",
        "                                df = rest_slice\n",
        "                                status_suffix = f\"(Dropped top {check_limit} header rows)\"\n",
        "                        else:\n",
        "                            status_suffix = \"(First file: All rows kept)\"\n",
        "\n",
        "                        # --- ADD YEAR COLUMN ---\n",
        "                        df.insert(0, 'Source_Year', year)\n",
        "\n",
        "                        print(f\"  {year}: [FOUND] '{real_sheet_name}' {status_suffix}\")\n",
        "                        return df\n",
        "                    else:\n",
        "                        print(f\"  {year}: [MISSING] '{target_name_clean}'\")\n",
        "                        return None\n",
        "\n",
        "                # --- EXTRACT LEFT ---\n",
        "                df_left = process_sheet_data(sheets[0], not processed_first_file)\n",
        "                if df_left is not None:\n",
        "                    left_dfs.append(df_left)\n",
        "\n",
        "                # --- EXTRACT RIGHT ---\n",
        "                if len(sheets) > 1:\n",
        "                    df_right = process_sheet_data(sheets[1], not processed_first_file)\n",
        "                    if df_right is not None:\n",
        "                        right_dfs.append(df_right)\n",
        "\n",
        "                # Mark success\n",
        "                if df_left is not None or (len(sheets) > 1 and df_right is not None):\n",
        "                    processed_first_file = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  {year}: [ERROR] Processing file: {e}\")\n",
        "\n",
        "        # --- SAVE FILES FOR THIS CATEGORY ---\n",
        "        print(f\"\\n--- Finalizing & Saving {category_name} ---\")\n",
        "\n",
        "        if left_dfs:\n",
        "            combined_left = pd.concat(left_dfs, ignore_index=True)\n",
        "            # PERFORM FINAL CLEANUP\n",
        "            combined_left = perform_final_cleanup(combined_left)\n",
        "            combined_left.to_csv(left_out, index=False, header=False)\n",
        "            print(f\"  -> Saved '{left_out}' ({len(combined_left)} rows)\")\n",
        "        else:\n",
        "            print(f\"  -> No data for '{left_out}'\")\n",
        "\n",
        "        if right_dfs:\n",
        "            combined_right = pd.concat(right_dfs, ignore_index=True)\n",
        "            # PERFORM FINAL CLEANUP\n",
        "            combined_right = perform_final_cleanup(combined_right)\n",
        "            combined_right.to_csv(right_out, index=False, header=False)\n",
        "            print(f\"  -> Saved '{right_out}' ({len(combined_right)} rows)\")\n",
        "\n",
        "    print(\"\\n=== All Tasks Complete ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_and_combine_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f17ad34-fcfc-416d-ebee-f5e7bc91a729",
        "id": "a3klvnzcD-MV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================================\n",
            " PROCESSING CATEGORY: Laboratories\n",
            "=======================================================\n",
            "  2016: [FOUND] '3.26Lab' (First file: All rows kept)\n",
            "  2016: [FOUND] '3.27LabGov' (First file: All rows kept)\n",
            "  2017: [FOUND] '3.36LabRegCoun' (Dropped top 4 header rows)\n",
            "  2017: [FOUND] '3.37LabGovtRegCoun' (Dropped top 4 header rows)\n",
            "  2018: [FOUND] '3.37Lab' (Dropped top 4 header rows)\n",
            "  2018: [FOUND] '3.38LabGov' (Dropped top 4 header rows)\n",
            "  2019: [FOUND] '3.37Lab' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2019: [FOUND] '3.38LabGov' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2020: [FOUND] '3.37Lab' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2020: [FOUND] '3.38LabGov' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2021: [FOUND] 'T3.37Lab' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2021: [FOUND] 'T3.38LabGov' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2022: [FOUND] 'T3.38Lab' (Dropped top 4 header rows)\n",
            "  2022: [FOUND] 'T3.39LabGov' (Dropped top 4 header rows)\n",
            "  2023: [FOUND] 'T3.39LabG&NG' (Dropped top 4 header rows)\n",
            "  2023: [FOUND] 'T3.40LabG' (Dropped top 4 header rows)\n",
            "  2024: [FOUND] 'T3.39LabG&NG' (Dropped top 4 header rows)\n",
            "  2024: [FOUND] 'T3.40LabG' (Dropped top 4 header rows)\n",
            "  2025: [FOUND] 'T3.40LabG&NG' (Dropped top 4 header rows)\n",
            "  2025: [FOUND] 'T3.41LabG' (Dropped top 4 header rows)\n",
            "\n",
            "--- Finalizing & Saving Laboratories ---\n",
            "    (Cleaned 6 rows having <= 1 data value)\n",
            "    (Dropped 5 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_Laboratories_All_G_NG.csv' (1840 rows)\n",
            "    (Cleaned 6 rows having <= 1 data value)\n",
            "    (Dropped 4 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_Laboratories_Govt.csv' (1840 rows)\n",
            "\n",
            "=======================================================\n",
            " PROCESSING CATEGORY: ICT_Equipment\n",
            "=======================================================\n",
            "  2017: [FOUND] 'T3.42ICTAllRegCoun' (First file: All rows kept)\n",
            "  2017: [FOUND] 'T3.43ICTGovRegCoun' (First file: All rows kept)\n",
            "  2018: [FOUND] 'T2.42_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2018: [FOUND] 'T2.43_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2019: [FOUND] 'Table170' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2019: [FOUND] 'Table169' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2020: [FOUND] 'Table147' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2020: [FOUND] 'Table148' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2021: [FOUND] 'Table155' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2021: [FOUND] 'Table156' (Dropped 1 header rows, kept 3 numeric rows)\n",
            "  2022: [FOUND] 'T2.43_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2022: [FOUND] 'T2.44_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2023: [FOUND] 'T2.44_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2023: [FOUND] 'T2.45_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2024: [FOUND] 'T2.44_ICT_G&N' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2024: [FOUND] 'T2.45_ICT_G' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2025: [FOUND] 'T3.46ICT' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "  2025: [FOUND] 'T3.47ICT_Gov' (Dropped 3 header rows, kept 1 numeric rows)\n",
            "\n",
            "--- Finalizing & Saving ICT_Equipment ---\n",
            "    (Cleaned 14 rows having <= 1 data value)\n",
            "    (Dropped 4 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_ICT_All_G_NG.csv' (1658 rows)\n",
            "    (Cleaned 14 rows having <= 1 data value)\n",
            "    (Dropped 4 columns with >15% empty cells)\n",
            "  -> Saved 'Combined_ICT_Govt.csv' (1658 rows)\n",
            "\n",
            "=======================================================\n",
            " PROCESSING CATEGORY: Electricity\n",
            "=======================================================\n",
            "  2017: [FOUND] 'T3.40SchElecAllRegCoun' (First file: All rows kept)\n",
            "  2017: [FOUND] 'T3.41SchElecGovRegCoun' (First file: All rows kept)\n",
            "  2018: [FOUND] 'T2.44_Elect_G&N' (Dropped top 4 header rows)\n",
            "  2018: [FOUND] 'T2.45_Elect_G' (Dropped top 4 header rows)\n",
            "  2019: [FOUND] 'Table165' (Dropped 0 header rows, kept 4 numeric rows)\n",
            "  2019: [FOUND] 'Table167' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2020: [FOUND] 'Table145' (Dropped 0 header rows, kept 4 numeric rows)\n",
            "  2020: [FOUND] 'Table146' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2021: [FOUND] 'Table152' (Dropped 0 header rows, kept 4 numeric rows)\n",
            "  2021: [FOUND] 'Table153' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2022: [FOUND] 'T2.41_Elect_G&N' (Dropped 2 header rows, kept 2 numeric rows)\n",
            "  2022: [FOUND] 'T2.42_Elect_G' (Dropped 2 header rows, kept 2 numeric rows)\n"
          ]
        }
      ]
    }
  ]
}